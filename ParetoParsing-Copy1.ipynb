{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from parse_logs import parse_log, comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predefined defaults are:\n",
      " * mlr_default := make_tuple(0.01, 30., 1., 20.)\n"
     ]
    }
   ],
   "source": [
    "df, expressions_by_length, generations_by_task = parse_log('runs/rpart.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 115 expressions of length 0. Most frequent: mlr_default (115 times)\n",
      " Found 171 expressions of length 1. Most frequent: make_tuple(0.00390625, 16.0, 10.0, 32.0) (49 times)\n",
      " Found 260 expressions of length 2. Most frequent: make_tuple(truediv(0.00390625, m), 32.0, 10.0, 32.0) (34 times)\n",
      " Found 213 expressions of length 3. Most frequent: make_tuple(mul(mul(0.00390625, mcp), mcp), 32.0, 9.0, 32.0) (3 times)\n",
      " Found 151 expressions of length 4. Most frequent: make_tuple(mul(mul(0.00390625, mcp), mcp), 32.0, 9.0, truediv(9.0, xvar)) (2 times)\n",
      " Found 107 expressions of length 5. Most frequent: make_tuple(min(if_gt(mul(0.3519769920459628, m), xvar, rc, 10.0), 0.00390625), mul(m, 10.0), 10.0, 32.0) (1 times)\n",
      " Found  65 expressions of length 6. Most frequent: make_tuple(mul(mcp, mul(add(mcp, add(mcp, mcp)), truediv(16.0, n))), n, 9.0, 16.0) (1 times)\n",
      " Found  38 expressions of length 7. Most frequent: make_tuple(mul(mul(truediv(32.0, n), mcp), mcp), mul(9.0, m), sub(mul(mcp, 16.0), m), 16.0) (1 times)\n",
      " Found  19 expressions of length 8. Most frequent: make_tuple(mul(mcp, mul(add(mcp, add(mcp, mcp)), truediv(16.0, truediv(n, mcp)))), n, mul(mcp, 16.0), 9.0) (1 times)\n",
      " Found  13 expressions of length 9. Most frequent: make_tuple(truediv(truediv(mul(mcp, add(32.0, add(0.29646451337325874, 10.0))), sub(m, pow(mcp, mcp))), n), 32.0, truediv(16.0, m), 10.0) (1 times)\n",
      " Found  16 expressions of length 10. Most frequent: make_tuple(mul(add(mkd, mcp), mul(mcp, mul(mcp, 0.00390625))), n, mul(add(poly_gt(mcp, mcp), mul(10.0, truediv(mcp, 0.8861632659702997))), xvar), 10.0) (1 times)\n",
      " Found   6 expressions of length 11. Most frequent: make_tuple(mul(add(mkd, mcp), mul(mcp, mul(mcp, 0.00390625))), n, mul(add(poly_gt(0.0025232508535664167, mcp), add(xvar, mul(10.0, truediv(mcp, 0.8861632659702997)))), xvar), 10.0) (1 times)\n",
      " Found   5 expressions of length 12. Most frequent: make_tuple(truediv(truediv(mul(mcp, add(32.0, add(32.0, 10.0))), m), max(pow(p, xvar), n)), 32.0, truediv(truediv(mul(mcp, add(16.0, 32.0)), 2.0), m), 16.0) (1 times)\n",
      " Found   3 expressions of length 13. Most frequent: make_tuple(mul(add(mcp, add(rc, add(mcp, sub(mcp, mkd)))), mul(add(mcp, mcp), truediv(7.0, n))), n, sub(mul(mcp, pow(16.0, mcp)), poly_gt(mcp, rc)), 9.0) (1 times)\n",
      " Found   1 expressions of length 14. Most frequent: make_tuple(mul(mul(mul(truediv(0.00390625, m), mcp), mcp), add(mcp, add(mcp, mul(sub(mcp, rc), truediv(mcp, 0.13995707946475688))))), 32.0, add(truediv(mcp, 0.13995707946475688), truediv(sub(mcp, rc), 0.13995707946475688)), 16.0) (1 times)\n",
      " Found   1 expressions of length 15. Most frequent: make_tuple(mul(mul(mul(mul(0.00390625, mcp), mul(mcp, mcp)), mcp), add(mcp, add(mcp, mul(sub(mcp, rc), truediv(mcp, 0.13995707946475688))))), 32.0, add(truediv(mcp, 0.13995707946475688), mul(sub(mcp, rc), 9.0)), 16.0) (1 times)\n",
      " Found   2 expressions of length 16. Most frequent: make_tuple(mul(mul(mul(0.00390625, mul(mcp, mcp)), mul(mcp, mcp)), add(mcp, add(mcp, mul(sub(mcp, rc), truediv(mcp, 0.13995707946475688))))), 32.0, add(truediv(mcp, 0.13995707946475688), mul(sub(mcp, rc), truediv(9.0, xvar))), 16.0) (1 times)\n",
      " Found   1 expressions of length 17. Most frequent: make_tuple(mul(mul(mul(0.00390625, mul(mcp, mcp)), mul(mcp, mcp)), add(mcp, add(mul(mcp, mcp), mul(sub(mcp, rc), truediv(mcp, 0.13995707946475688))))), 32.0, add(truediv(mcp, 0.13995707946475688), mul(sub(xvar, rc), truediv(mcp, 0.13995707946475688))), 16.0) (1 times)\n",
      " Found   1 expressions of length 18. Most frequent: make_tuple(mul(mul(mul(0.00390625, mul(mcp, mcp)), mul(mcp, mcp)), add(mcp, add(mul(mcp, mul(mcp, mcp)), mul(sub(mcp, rc), truediv(mcp, 0.13995707946475688))))), 32.0, add(truediv(mcp, 0.13995707946475688), mul(sub(xvar, rc), truediv(mcp, 0.13995707946475688))), 16.0) (1 times)\n"
     ]
    }
   ],
   "source": [
    "for length, expressions in sorted(expressions_by_length.items()):\n",
    "    m = max(set(expressions), key=expressions.count)\n",
    "    print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Found `N` expressions of length `L`\" here means across all the tasks' pareto fronts `N` solutions have length `L`.\n",
    "Pareto fronts may contain duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c0268e3048>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(generations_by_task, name=\"generations\").hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(generations_by_task, name=\"generations\").median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above plot shows the histogram of the number of generations across tasks (binsize=10).\n",
    "Note that if something ran for less than 200 generations, it found its optimum 20 generations earlier and early stopping terminated search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison, df_out = comparisons(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the scores and note which solution leads to the best out of sample score per task. A solution wins **alone** if all other solutions have worse performance. It wins **shared** if at least one other solution has the same score, but no solution has a better score. **either** is the sum of alone and shared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But tallying wins does not say much about the robustness of the symbolic defaults. We can also compare the average or median distance from the top performer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlr_default</th>\n",
       "      <th>score-1</th>\n",
       "      <th>score-2</th>\n",
       "      <th>score-3</th>\n",
       "      <th>score-best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>either</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mlr_default  score-1  score-2  score-3  score-best\n",
       "alone            21        9       12       14          22\n",
       "shared            0        2       23       27          32\n",
       "either           21       11       35       41          54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_score-1        0.073415\n",
       "d_score-2        0.043295\n",
       "d_score-3        0.035179\n",
       "d_score-best     0.027800\n",
       "d_mlr_default    0.124273\n",
       "d_max            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cols = [c for c in df_out.columns if c.startswith('d_')]\n",
    "df_out[d_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_score-1        0.0368\n",
       "d_score-2        0.0042\n",
       "d_score-3        0.0033\n",
       "d_score-best     0.0001\n",
       "d_mlr_default    0.0720\n",
       "d_max            0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[d_cols].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at in-sample performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score-best    76\n",
       "score-3       26\n",
       "score-2       13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample = df.index.map(lambda idx: idx[1] == \"in-sample\")\n",
    "df.loc[in_sample].idxmax(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`idxmax` reports the first column that has a max score of the row. So we see that never is the \"score-1\" solution the best in-sample. It is divided somewhat evenly between score-2, score-3 and scores for greater lengths. In 15 of 106 cases, it does not find the solution \"symbolic best\", which would have had better in-sample performance for that task (for other tasks we don't know if it was considered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversing column order, we confirms there are no ties between any found solutions and benchmark ones (in-sample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score-best    115\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[in_sample][reversed(df.columns)].idxmax(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task    sample-type\n",
       "3       in-sample      score-best\n",
       "6       in-sample      score-best\n",
       "11      in-sample      score-best\n",
       "12      in-sample      score-best\n",
       "14      in-sample      score-best\n",
       "                          ...    \n",
       "168911  in-sample      score-best\n",
       "168912  in-sample      score-best\n",
       "189928  in-sample      score-best\n",
       "190411  in-sample      score-best\n",
       "190412  in-sample      score-best\n",
       "Length: 115, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[in_sample][reversed(df.columns)].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
