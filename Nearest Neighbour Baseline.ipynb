{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"./src/\")\n",
    "from problem import Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to determine the best configuration for each task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_configurations(experiment_data):\n",
    "    best_configurations = experiment_data.sort_values(by=\"target\", ascending=False)\\\n",
    "                                         .groupby(\"task_id\", as_index=False)\\\n",
    "                                         .head(1)\n",
    "    best_configurations.set_index('task_id', inplace=True)\n",
    "    return best_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And scale the meta-data so that the neighbour distance isn't dominated by e.g. `n` or `p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(column):\n",
    "    return (column - min(column)) / (max(column) - min(column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally be able to look up the closest datasets based on the metadata, and return the best recorded configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_distance(row_one, row_two):\n",
    "    return sum(abs(row_one - row_two))\n",
    "\n",
    "def find_nearest_neighbour(task, metadata, distance='L1'):\n",
    "    task_row = metadata.loc[task]\n",
    "    distances = metadata[metadata.index != task].apply(lambda r: L1_distance(r, task_row), axis=1)\n",
    "    return distances.idxmin()\n",
    "    \n",
    "def find_best_experiment_by_nn(task, metadata, experimentdata):\n",
    "    closest_task = find_nearest_neighbour(task, metadata, distance='L1')\n",
    "    return experimentdata.loc[closest_task]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Nearest Neighbour for svm\n",
      "Finding Nearest Neighbour for rf\n",
      "Finding Nearest Neighbour for glmnet\n",
      "Finding Nearest Neighbour for rpart\n",
      "Finding Nearest Neighbour for xgboost\n",
      "Finding Nearest Neighbour for knn\n"
     ]
    }
   ],
   "source": [
    "for algorithm in [\"svm\", \"rf\", \"glmnet\", \"rpart\", \"xgboost\", \"knn\"]:\n",
    "    print(f\"Finding Nearest Neighbour for {algorithm}\")\n",
    "    problem = Problem(f\"mlr_{algorithm}\")\n",
    "    normalized_metadata = problem.metadata.apply(min_max_scaler, axis=0)\n",
    "    best_configurations = get_best_configurations(problem.data)\n",
    "    filtered_metadata = normalized_metadata[normalized_metadata.index.isin(best_configurations.index)]\n",
    "    \n",
    "    hyperparameters = [\n",
    "        c for c in best_configurations.columns\n",
    "        if not c in ['dataset', 'learner', 'perf.mmce', 'target', 'traintime', 'predicttime']\n",
    "    ]\n",
    "\n",
    "    recommended_configurations = dict()\n",
    "    for task in best_configurations.index:\n",
    "        best_experiment = find_best_experiment_by_nn(task, filtered_metadata, best_configurations)\n",
    "        configuration = best_experiment[hyperparameters]\n",
    "        recommended_configurations[task] = configuration\n",
    "    \n",
    "    pd.DataFrame.from_dict(recommended_configurations, orient='index').to_csv(f\"{algorithm}_nearest_neighbors.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15,\n",
       " 29,\n",
       " 2079,\n",
       " 3021,\n",
       " 3493,\n",
       " 3903,\n",
       " 3907,\n",
       " 3918,\n",
       " 3945,\n",
       " 9978,\n",
       " 14971,\n",
       " 146818,\n",
       " 146819,\n",
       " 168912,\n",
       " 190412}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(normalized_metadata.index) - set(best_configurations.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(best_configurations.index) - set(normalized_metadata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
