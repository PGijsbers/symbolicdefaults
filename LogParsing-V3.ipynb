{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runlog:\n",
    "    \"\"\"\n",
    "    Read logs for a given problem across several searches\n",
    "    \"\"\"\n",
    "    def __init__(self, problem: str, searches: List, benchmarks=None, ignore=None):\n",
    "        self.problem = problem\n",
    "        self.searches = searches\n",
    "        self.benchmarks = benchmarks\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        df = read_run_logs(problem=self.problem, search=self.searches[0], target=\"evaluations\")\n",
    "        for search in self.searches[1:]:\n",
    "            df = df.append(read_run_logs(problem=self.problem, search=search, target=\"evaluations\"))\n",
    "        return df\n",
    "\n",
    "    def pick_final_expression(self, method = \"best\", **kwargs):\n",
    "        \"\"\"\n",
    "        Pick final expression on \"in\" data\n",
    "        :method: either \"relative\", \"shortest\" or \"best\"\n",
    "        \"\"\"\n",
    "        df = self.data.copy()\n",
    "        df = df[df['expression'].str.contains(',')]\n",
    "        df = df[df.endresult]\n",
    "        df = df.pivot_table(index=[\"run\", \"task\", \"gen\", \"length\", \"problem\", \"search\", \"expression\"], columns=\"inout\", values=\"score\")\n",
    "        df = df.reset_index()\n",
    "        if method == \"shortest\":\n",
    "            out = df[df.groupby(\"run\")['length'].transform(min) == df['length']]\n",
    "        elif method == \"relative\":\n",
    "            out = df.loc[[pick_relative(group, **kwargs) for name, group in df.groupby('run')]]\n",
    "        else:\n",
    "            out = df[df.groupby(\"run\")['in'].transform(max) == df['in']]\n",
    "        return out\n",
    "    \n",
    "    def get_benchmark_performances(self):\n",
    "        \"\"\"\n",
    "        Load benchmark performances\n",
    "        \"\"\"\n",
    "        df = self.data[self.data['expression'].isin(self.benchmarks)]\n",
    "        df = df.pivot_table(index=[\"run\", \"task\",\"problem\", \"search\", \"expression\"], columns=\"inout\", values=\"score\")\n",
    "        df = df.reset_index()\n",
    "        df = df[[\"task\", \"problem\", \"expression\", \"in\", \"out\"]]\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        return(df)\n",
    "\n",
    "    \n",
    "def pick_relative(x, eps=0.01, max_steps=1):\n",
    "    \"\"\"\n",
    "    Pick by relative improvement; \n",
    "    Consider only at most `max_steps` longer, if better by 'eps', break if not\n",
    "    \"\"\"\n",
    "    x = x.copy()\n",
    "    if len(x) == 1:\n",
    "        return(x.index.values[0])\n",
    "    \n",
    "    use_ix, length, score = None, 0, 0\n",
    "    for ix, rw in x.iterrows():\n",
    "        if rw['length'] - length > max_steps:\n",
    "            break  # candidates are too big\n",
    "        if rw['in'] - score < eps:\n",
    "            continue  # not enough increase\n",
    "        use_ix, length, score = ix, rw['length'], rw['in']        \n",
    "    return use_ix\n",
    "\n",
    "def read_run_logs(problem:str, search: str, target: str):\n",
    "    \"\"\"\n",
    "    Read all log-files for a given problem x search combination\n",
    "    \"\"\"\n",
    "    log_dir = f\"runs/results/{problem}_{search}/\"\n",
    "    dirs = [os.path.join(log_dir, f) for f in os.listdir(log_dir)]\n",
    "    df = pd.read_csv(f\"{dirs[0]}/{target}.csv\", sep=\";\",nrows=0)\n",
    "    for dir in dirs: \n",
    "        df = df.append(pd.read_csv(f\"{dir}/{target}.csv\", sep=\";\"))\n",
    "    df['problem'] = problem\n",
    "    df['search'] = search\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inout</th>\n",
       "      <th>run</th>\n",
       "      <th>task</th>\n",
       "      <th>gen</th>\n",
       "      <th>length</th>\n",
       "      <th>problem</th>\n",
       "      <th>search</th>\n",
       "      <th>expression</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006c75a-b024-4603-a851-36cd910df2c5</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(m, truediv(mkd, xvar))</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001654f3-3af9-49db-ac5b-ac2ac9a6c94a</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>random_search</td>\n",
       "      <td>make_tuple(p, mkd)</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00838759-f02d-4368-80f4-8cc073dc6664</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>True</td>\n",
       "      <td>make_tuple(1103, 0.0013402821363702943)</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.9262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00be6955-5e8b-4fc0-beb5-a8de29a9cffa</td>\n",
       "      <td>49</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>True</td>\n",
       "      <td>make_tuple(556, 0.001936638978958794)</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00c3b730-6ddf-4132-bfec-a38574c372b1</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(m, truediv(mkd, xvar))</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>ff1e9951-635c-40d8-ac00-33e5f80f8794</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(6, truediv(0.8300272571362725, po))</td>\n",
       "      <td>0.9041</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>ff39074a-f9e1-4f88-9456-1f001c8bcc33</td>\n",
       "      <td>2079</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>True</td>\n",
       "      <td>make_tuple(1234, 0.001341449411796731)</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>ff5e0891-6802-4034-909b-7bb44df3a6a7</td>\n",
       "      <td>58</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(6, truediv(0.8375172317745118, po))</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.9589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>ffcc5d23-f99f-4d1f-8bdb-5cd0ef9f571b</td>\n",
       "      <td>58</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(m, truediv(mkd, xvar))</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.9747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>ffd1ce63-33a5-4c99-a5eb-8c22869d4fdc</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>svm</td>\n",
       "      <td>mupluslambda</td>\n",
       "      <td>make_tuple(m, truediv(mkd, xvar))</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1103 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "inout                                   run  task  gen  length problem  \\\n",
       "1      0006c75a-b024-4603-a851-36cd910df2c5    45   42       2     svm   \n",
       "3      001654f3-3af9-49db-ac5b-ac2ac9a6c94a    58    2       1     svm   \n",
       "6      00838759-f02d-4368-80f4-8cc073dc6664    53   46       1     svm   \n",
       "7      00be6955-5e8b-4fc0-beb5-a8de29a9cffa    49   87       1     svm   \n",
       "9      00c3b730-6ddf-4132-bfec-a38574c372b1    14   33       2     svm   \n",
       "...                                     ...   ...  ...     ...     ...   \n",
       "2659   ff1e9951-635c-40d8-ac00-33e5f80f8794    12  128       2     svm   \n",
       "2664   ff39074a-f9e1-4f88-9456-1f001c8bcc33  2079   74       1     svm   \n",
       "2667   ff5e0891-6802-4034-909b-7bb44df3a6a7    58  124       2     svm   \n",
       "2670   ffcc5d23-f99f-4d1f-8bdb-5cd0ef9f571b    58  169       2     svm   \n",
       "2674   ffd1ce63-33a5-4c99-a5eb-8c22869d4fdc    14   32       2     svm   \n",
       "\n",
       "inout         search                                      expression      in  \\\n",
       "1       mupluslambda               make_tuple(m, truediv(mkd, xvar))  0.9009   \n",
       "3      random_search                              make_tuple(p, mkd)  0.8902   \n",
       "6               True         make_tuple(1103, 0.0013402821363702943)  0.8617   \n",
       "7               True           make_tuple(556, 0.001936638978958794)  0.8603   \n",
       "9       mupluslambda               make_tuple(m, truediv(mkd, xvar))  0.9009   \n",
       "...              ...                                             ...     ...   \n",
       "2659    mupluslambda  make_tuple(6, truediv(0.8300272571362725, po))  0.9041   \n",
       "2664            True          make_tuple(1234, 0.001341449411796731)  0.8613   \n",
       "2667    mupluslambda  make_tuple(6, truediv(0.8375172317745118, po))  0.9045   \n",
       "2670    mupluslambda               make_tuple(m, truediv(mkd, xvar))  0.9011   \n",
       "2674    mupluslambda               make_tuple(m, truediv(mkd, xvar))  0.9009   \n",
       "\n",
       "inout     out  \n",
       "1      0.9969  \n",
       "3      0.9328  \n",
       "6      0.9262  \n",
       "7      0.9525  \n",
       "9      0.9944  \n",
       "...       ...  \n",
       "2659   0.9970  \n",
       "2664   0.9594  \n",
       "2667   0.9589  \n",
       "2670   0.9747  \n",
       "2674   0.9944  \n",
       "\n",
       "[1103 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = [\"sklearn_default\", \"mlr_default\", \"symbolic_best\"]\n",
    "log = Runlog('svm',  [\"mupluslambda\", \"random_search\", \"True\"], benchmarks=benchmarks)\n",
    "\n",
    "df = log.pick_final_expression('relative')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">in</th>\n",
       "      <th colspan=\"2\" halign=\"left\">out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.861279</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.911427</td>\n",
       "      <td>0.95180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_default</th>\n",
       "      <td>0.932348</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.311537</td>\n",
       "      <td>0.16270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mupluslambda</th>\n",
       "      <td>0.899953</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.938239</td>\n",
       "      <td>0.96615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_search</th>\n",
       "      <td>0.890109</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.937037</td>\n",
       "      <td>0.96410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_default</th>\n",
       "      <td>0.932348</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.933270</td>\n",
       "      <td>0.95610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbolic_best</th>\n",
       "      <td>0.932348</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.935559</td>\n",
       "      <td>0.95890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in               out         \n",
       "                     mean  median      mean   median\n",
       "search                                              \n",
       "True             0.861279  0.8613  0.911427  0.95180\n",
       "mlr_default      0.932348  0.9548  0.311537  0.16270\n",
       "mupluslambda     0.899953  0.9011  0.938239  0.96615\n",
       "random_search    0.890109  0.8899  0.937037  0.96410\n",
       "sklearn_default  0.932348  0.9548  0.933270  0.95610\n",
       "symbolic_best    0.932348  0.9548  0.935559  0.95890"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final expression and Benchmark performances \n",
    "cols = [\"task\", \"problem\", \"search\", \"in\", \"out\"]\n",
    "df = log.pick_final_expression('relative')[cols]\n",
    "bdf = log.get_benchmark_performances().rename(columns={\"expression\":\"search\"})[cols]\n",
    "df = df.append(bdf)\n",
    "df.groupby(\"search\")[[\"in\", \"out\"]].agg([np.mean, np.median]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d60776430>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df, x=\"task\", y=\"out\", hue = \"search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"task\", \"problem\", \"search\", \"in\", \"out\"]\n",
    "big_df = pd.DataFrame()\n",
    "for strat in [\"best\", \"shortest\", \"relative\"]:\n",
    "    df = log.pick_final_expression(strat, eps=0.01, max_steps=2)[cols]\n",
    "    bdf = log.get_benchmark_performances().rename(columns={\"expression\":\"search\"})[cols]\n",
    "    df = df.append(bdf)\n",
    "    df = df[df.search.isin([\"mupluslambda\", \"random_search\", \"True\"])]\n",
    "    df[\"strategy\"] = strat\n",
    "    big_df = pd.concat([big_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">in</th>\n",
       "      <th colspan=\"4\" halign=\"left\">out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>search</th>\n",
       "      <th>strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861259</td>\n",
       "      <td>0.86150</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.945227</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.86140</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.86140</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.905138</td>\n",
       "      <td>0.90360</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.91460</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.90170</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.924555</td>\n",
       "      <td>0.91320</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.90170</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.937088</td>\n",
       "      <td>0.91320</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894129</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.943682</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861200</td>\n",
       "      <td>0.86160</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941591</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.86155</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941390</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.86155</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941390</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.990330</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896710</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.990380</td>\n",
       "      <td>0.99110</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899450</td>\n",
       "      <td>0.90040</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.980790</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.8836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861467</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.898592</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.899580</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.899580</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.905036</td>\n",
       "      <td>0.90500</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.912864</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.901130</td>\n",
       "      <td>0.90180</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.904970</td>\n",
       "      <td>0.89660</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.901080</td>\n",
       "      <td>0.90180</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.925510</td>\n",
       "      <td>0.92360</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896160</td>\n",
       "      <td>0.89615</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>0.89890</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.85970</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.99880</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860278</td>\n",
       "      <td>0.85990</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860278</td>\n",
       "      <td>0.85990</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.903540</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.900090</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900420</td>\n",
       "      <td>0.89970</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.892870</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">14</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.904010</td>\n",
       "      <td>0.90355</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.992630</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.901520</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900275</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896487</td>\n",
       "      <td>0.90020</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.994487</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861083</td>\n",
       "      <td>0.86120</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976617</td>\n",
       "      <td>0.97820</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860810</td>\n",
       "      <td>0.86105</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976580</td>\n",
       "      <td>0.97810</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860810</td>\n",
       "      <td>0.86105</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976580</td>\n",
       "      <td>0.97810</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.904446</td>\n",
       "      <td>0.90380</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.977862</td>\n",
       "      <td>0.98360</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.898060</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.977380</td>\n",
       "      <td>0.97970</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.961900</td>\n",
       "      <td>0.96190</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899710</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.978590</td>\n",
       "      <td>0.98615</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.89515</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.975390</td>\n",
       "      <td>0.97175</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.961900</td>\n",
       "      <td>0.96190</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.85980</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991093</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.901556</td>\n",
       "      <td>0.90350</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.997933</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998056</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900244</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894600</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998056</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">18</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860593</td>\n",
       "      <td>0.86010</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.966093</td>\n",
       "      <td>0.96220</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860650</td>\n",
       "      <td>0.86065</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.96565</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860650</td>\n",
       "      <td>0.86065</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.96565</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.902210</td>\n",
       "      <td>0.90110</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.970420</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.899200</td>\n",
       "      <td>0.90110</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.968960</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.90060</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.970470</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.968470</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   in                                out  \\\n",
       "                                 mean   median     max     min      mean   \n",
       "task search        strategy                                                \n",
       "3    True          best      0.861259  0.86150  0.8615  0.8603  0.945227   \n",
       "                   relative  0.861242  0.86140  0.8615  0.8603  0.946300   \n",
       "                   shortest  0.861242  0.86140  0.8615  0.8603  0.946300   \n",
       "     mupluslambda  best      0.905138  0.90360  0.9153  0.9017  0.924071   \n",
       "                   relative  0.900360  0.90170  0.9047  0.8899  0.924555   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964100   \n",
       "     random_search best      0.900494  0.90170  0.9049  0.8948  0.937088   \n",
       "                   relative  0.894129  0.88990  0.9028  0.8899  0.943682   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964100   \n",
       "6    True          best      0.861200  0.86160  0.8616  0.8602  0.941591   \n",
       "                   relative  0.861280  0.86155  0.8616  0.8602  0.941390   \n",
       "                   shortest  0.861280  0.86155  0.8616  0.8602  0.941390   \n",
       "     mupluslambda  best      0.902000  0.90090  0.9085  0.8980  0.990330   \n",
       "                   relative  0.896710  0.90090  0.9042  0.8896  0.990380   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.989200   \n",
       "     random_search best      0.899450  0.90040  0.9020  0.8948  0.980790   \n",
       "                   relative  0.894040  0.88960  0.9009  0.8896  0.990060   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.989200   \n",
       "11   True          best      0.861467  0.86180  0.8619  0.8607  0.898592   \n",
       "                   relative  0.861500  0.86180  0.8619  0.8607  0.899580   \n",
       "                   shortest  0.861500  0.86180  0.8619  0.8607  0.899580   \n",
       "     mupluslambda  best      0.905036  0.90500  0.9109  0.8992  0.912864   \n",
       "                   relative  0.901130  0.90180  0.9044  0.8905  0.904970   \n",
       "                   shortest  0.890500  0.89050  0.8905  0.8905  0.901200   \n",
       "     random_search best      0.901080  0.90180  0.9031  0.8986  0.925510   \n",
       "                   relative  0.896160  0.89615  0.9019  0.8905  0.898900   \n",
       "                   shortest  0.890500  0.89050  0.8905  0.8905  0.901200   \n",
       "12   True          best      0.860162  0.85970  0.8610  0.8597  0.998700   \n",
       "                   relative  0.860278  0.85990  0.8610  0.8597  0.998678   \n",
       "                   shortest  0.860278  0.85990  0.8610  0.8597  0.998678   \n",
       "     mupluslambda  best      0.903540  0.90090  0.9169  0.8989  0.997460   \n",
       "                   relative  0.900090  0.90090  0.9042  0.8895  0.997600   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.999000   \n",
       "     random_search best      0.900420  0.89970  0.9038  0.8968  0.996910   \n",
       "                   relative  0.892870  0.88950  0.9009  0.8895  0.998650   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.999000   \n",
       "14   True          best      0.860420  0.86040  0.8611  0.8598  0.992800   \n",
       "                   relative  0.860390  0.86040  0.8611  0.8597  0.992800   \n",
       "                   shortest  0.860390  0.86040  0.8611  0.8597  0.992800   \n",
       "     mupluslambda  best      0.904010  0.90355  0.9089  0.9009  0.992630   \n",
       "                   relative  0.901520  0.90090  0.9042  0.9005  0.992760   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.995900   \n",
       "     random_search best      0.900275  0.90090  0.9021  0.8960  0.991000   \n",
       "                   relative  0.896487  0.90020  0.9009  0.8896  0.994487   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.995900   \n",
       "15   True          best      0.861083  0.86120  0.8612  0.8601  0.976617   \n",
       "                   relative  0.860810  0.86105  0.8612  0.8601  0.976580   \n",
       "                   shortest  0.860810  0.86105  0.8612  0.8601  0.976580   \n",
       "     mupluslambda  best      0.904446  0.90380  0.9099  0.9009  0.977862   \n",
       "                   relative  0.898060  0.90090  0.9033  0.8899  0.977380   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.961900   \n",
       "     random_search best      0.899710  0.89985  0.9033  0.8971  0.978590   \n",
       "                   relative  0.895590  0.89515  0.9033  0.8899  0.975390   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.961900   \n",
       "16   True          best      0.860360  0.85980  0.8611  0.8597  0.991093   \n",
       "                   relative  0.860420  0.86040  0.8611  0.8597  0.991170   \n",
       "                   shortest  0.860420  0.86040  0.8611  0.8597  0.991170   \n",
       "     mupluslambda  best      0.901556  0.90350  0.9044  0.8947  0.997933   \n",
       "                   relative  0.899000  0.90090  0.9040  0.8895  0.998056   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.998100   \n",
       "     random_search best      0.900244  0.90090  0.9030  0.8963  0.998244   \n",
       "                   relative  0.894600  0.88950  0.9012  0.8895  0.998056   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.998100   \n",
       "18   True          best      0.860593  0.86010  0.8613  0.8601  0.966093   \n",
       "                   relative  0.860650  0.86065  0.8613  0.8600  0.966620   \n",
       "                   shortest  0.860650  0.86065  0.8613  0.8600  0.966620   \n",
       "     mupluslambda  best      0.902210  0.90110  0.9085  0.8996  0.970420   \n",
       "                   relative  0.899200  0.90110  0.9045  0.8899  0.968960   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964200   \n",
       "     random_search best      0.899820  0.90060  0.9035  0.8958  0.970470   \n",
       "                   relative  0.894450  0.88990  0.9018  0.8899  0.968470   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964200   \n",
       "\n",
       "                                                      \n",
       "                              median     max     min  \n",
       "task search        strategy                           \n",
       "3    True          best      0.94910  0.9526  0.9293  \n",
       "                   relative  0.94910  0.9526  0.9293  \n",
       "                   shortest  0.94910  0.9526  0.9293  \n",
       "     mupluslambda  best      0.91460  0.9908  0.8888  \n",
       "                   relative  0.91320  0.9641  0.9020  \n",
       "                   shortest  0.96410  0.9641  0.9641  \n",
       "     random_search best      0.91320  0.9960  0.8715  \n",
       "                   relative  0.96410  0.9641  0.8715  \n",
       "                   shortest  0.96410  0.9641  0.9641  \n",
       "6    True          best      0.94140  0.9436  0.9369  \n",
       "                   relative  0.94140  0.9436  0.9369  \n",
       "                   shortest  0.94140  0.9436  0.9369  \n",
       "     mupluslambda  best      0.99120  0.9927  0.9846  \n",
       "                   relative  0.99110  0.9912  0.9892  \n",
       "                   shortest  0.98920  0.9892  0.9892  \n",
       "     random_search best      0.99120  0.9958  0.8836  \n",
       "                   relative  0.98920  0.9918  0.9892  \n",
       "                   shortest  0.98920  0.9892  0.9892  \n",
       "11   True          best      0.89480  0.9085  0.8925  \n",
       "                   relative  0.89480  0.9085  0.8925  \n",
       "                   shortest  0.89480  0.9085  0.8925  \n",
       "     mupluslambda  best      0.90120  0.9507  0.8966  \n",
       "                   relative  0.89660  0.9364  0.8966  \n",
       "                   shortest  0.90120  0.9012  0.9012  \n",
       "     random_search best      0.92360  0.9635  0.8966  \n",
       "                   relative  0.89890  0.9012  0.8966  \n",
       "                   shortest  0.90120  0.9012  0.9012  \n",
       "12   True          best      0.99880  0.9989  0.9983  \n",
       "                   relative  0.99870  0.9989  0.9985  \n",
       "                   shortest  0.99870  0.9989  0.9985  \n",
       "     mupluslambda  best      0.99750  0.9991  0.9960  \n",
       "                   relative  0.99750  0.9990  0.9970  \n",
       "                   shortest  0.99900  0.9990  0.9990  \n",
       "     random_search best      0.99650  0.9988  0.9963  \n",
       "                   relative  0.99900  0.9990  0.9975  \n",
       "                   shortest  0.99900  0.9990  0.9990  \n",
       "14   True          best      0.99305  0.9945  0.9906  \n",
       "                   relative  0.99305  0.9945  0.9906  \n",
       "                   shortest  0.99305  0.9945  0.9906  \n",
       "     mupluslambda  best      0.99440  0.9955  0.9860  \n",
       "                   relative  0.99440  0.9944  0.9862  \n",
       "                   shortest  0.99590  0.9959  0.9959  \n",
       "     random_search best      0.99200  0.9944  0.9838  \n",
       "                   relative  0.99440  0.9959  0.9906  \n",
       "                   shortest  0.99590  0.9959  0.9959  \n",
       "15   True          best      0.97820  0.9782  0.9732  \n",
       "                   relative  0.97810  0.9787  0.9732  \n",
       "                   shortest  0.97810  0.9787  0.9732  \n",
       "     mupluslambda  best      0.98360  0.9907  0.9385  \n",
       "                   relative  0.97970  0.9907  0.9619  \n",
       "                   shortest  0.96190  0.9619  0.9619  \n",
       "     random_search best      0.98615  0.9921  0.9575  \n",
       "                   relative  0.97175  0.9907  0.9619  \n",
       "                   shortest  0.96190  0.9619  0.9619  \n",
       "16   True          best      0.99270  0.9927  0.9883  \n",
       "                   relative  0.99120  0.9927  0.9894  \n",
       "                   shortest  0.99120  0.9927  0.9894  \n",
       "     mupluslambda  best      0.99780  0.9985  0.9976  \n",
       "                   relative  0.99780  0.9988  0.9978  \n",
       "                   shortest  0.99810  0.9981  0.9981  \n",
       "     random_search best      0.99850  0.9989  0.9977  \n",
       "                   relative  0.99810  0.9986  0.9978  \n",
       "                   shortest  0.99810  0.9981  0.9981  \n",
       "18   True          best      0.96220  0.9718  0.9609  \n",
       "                   relative  0.96565  0.9719  0.9609  \n",
       "                   shortest  0.96565  0.9719  0.9609  \n",
       "     mupluslambda  best      0.97090  0.9745  0.9653  \n",
       "                   relative  0.97090  0.9709  0.9642  \n",
       "                   shortest  0.96420  0.9642  0.9642  \n",
       "     random_search best      0.97090  0.9868  0.9624  \n",
       "                   relative  0.96420  0.9868  0.9642  \n",
       "                   shortest  0.96420  0.9642  0.9642  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(big_df.groupby([\"task\", \"search\",  \"strategy\"])[[\"in\", \"out\"]].agg([np.mean, np.median, max, min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19f9cf66588>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=big_df[big_df.search == \"mupluslambda\"], x=\"task\", y=\"out\", hue=\"strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We have experiment data for a set of algorithms and meta-data for the datasets on which the experiments took place.\n",
    "We use symbolic regression to find an expression for symbolic default values that give good performance across tasks.\n",
    "Symbolic regression is performed with leave-one-task-out, which means for each algorithm we have multiple searches for a symbolic default, and their performance is recorded for both in-sample (the optimization surface of all-but-one tasks) and out-of-sample (the left out task) performance. Performance here is solely based on surrogate model predictions, no additional experiments have been performed (yet).\n",
    "\n",
    "In our search, we use NSGA-II selection to perform multi-objective optimization: find the expression with the best performance, while using the fewest number of operators (e.g. `divide`, `multiply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "**Length** of an expression denotes the number of operators in it. A symbolic value is *not* considered an operation.\n",
    "Consider the following SVM defaults for cost and gamma:\n",
    " - `make_tuple`(m, mkd) is length 1.\n",
    " - `make_tuple`(m, `truediv`(mkd, xvar)) is length 2.\n",
    " - `make_tuple`(16., `truediv`(mkd, xvar)) is length 2.\n",
    "\n",
    "The **final** solution refers to the symbolic default with the highest in-sample score for a task (regardless of its length). This means for each task there is *at least* one final solution, but there may be more and they are not of a specific length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline** solutions are typically the default hyperparameter settings of mlr, scikit-learn, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the logs, because some logs are incomplete we have to explicitly give the name of the baselines (this will be fixed for future runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we analyze the random forest\n",
    "alg = 'rf'\n",
    "\n",
    "import os\n",
    "baselines = dict(\n",
    "    glmnet=[\"mlr_default\", \"sklearn_default\"],\n",
    "    kerasff=[\"initial_values\"],\n",
    "    knn=[\"mlr_default\"],\n",
    "    rf=[\"mlr_default\"],\n",
    "    rpart=[\"mlr_default\"],\n",
    "    svm=[\"sklearn_scale\", \"symbolic_best\", \"skearn_default\", \"mlr_default\" , \"const\"],\n",
    ")\n",
    "dir_ = \"runs/running\"\n",
    "for file in os.listdir(dir_):\n",
    "    if file.endswith('.log') and alg in file and ('_0.log' in file or '_1.log' in file):\n",
    "        print(file)\n",
    "        baseline = []\n",
    "        for method, bls in baselines.items():\n",
    "            if method in file:\n",
    "                baseline = bls\n",
    "        traces[file[:-4]] = Trace(os.path.join(dir_, file), benchmarks=baseline, ignore=[\"const\", \"symbolic_v2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "As described before, for each problem we find a symbolic default leaving one task out.\n",
    "We are interested to see how fast the symbolic regression converges across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median number of generations across tasks by problem:\")\n",
    "for log, trace in traces.items():\n",
    "    print(f\"{log: <15} {trace.generations_by_task.median().astype(int):3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {k :v for (k,v) in traces.items() if k not in [\"mlr_glmnet_lisa_ints_0\", \"mlr_glmnet_lisa_ints_1\", \"mlr_glmnet_lisa_ints_2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(traces) / 4), 4, sharey=True, figsize=(16, 9))\n",
    "for ax, (log, trace) in zip(axes.flatten(), traces.items()):\n",
    "    traces[log].generations_by_task.hist(bins=20, ax=ax)\n",
    "    ax.set_title(f\"{log} ({len(trace.generations_by_task)} tasks)\")\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('generations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a histogram counting the number of generations until stopping. These results were obtained with default setting of early stopping if no improvement was made after 20 generations, with a 200 generation maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing optimization traces\n",
    "The traces contain the full optimization traces inside the trace's **progdf** trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2'].progdf)\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2i'].progdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Expressions\n",
    "For a given problem, we have a Pareto front of solutions for search (=each left out task).\n",
    "This Pareto front may contain \"twins\", multiple solutions which performance equally well and have the same length.\n",
    "Given that the response surface does not differ *that* much when leaving any particular task out, we hope that the symbolic expressions we find are reasonably consistent across searches.\n",
    "To have some indication of how consistent the results are, for each problem we find the most frequent solutions of length 1, 2 and 3. We also note the number of hyperparameters for which we aim to find a symbolic default, as we expect this to be correlated to how consistent the solutions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_count = pd.DataFrame(np.zeros((5, len(traces))), columns=list(traces), index=[1, 2, 3, \"#tasks\", \"params\"])\n",
    "for log, trace in traces.items():  \n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            if length == 1:\n",
    "                expr_count.loc[\"#tasks\"][log] = len(trace.scores) / 2\n",
    "                expr_count.loc[\"params\"][log] = m.count(',') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the found expressions per problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f'{alg}' # run_one #f\"mlr_knn_lisa_gaussian\" # run_one\n",
    "for log, trace in traces.items():\n",
    "    print(log)\n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            print(f\"Most frequent length {length} solution in Pareto front ({expressions.count(m)} times in {len(trace.scores) // 2} tasks):\\n     {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Quality\n",
    "The expressions we find also need to be good.\n",
    "Here we compare the following 'strategies':\n",
    " - length-*n*: always pick the best expression of length *n*\n",
    " - *final*: always pick the best expression, regardless of length\n",
    " - *baseline(s)*: compare it to baselines we defined\n",
    " \n",
    "We want to know (all based on out-of-sample performance):\n",
    " - which strategy gives the best solution most often?\n",
    " - which strategy experiences the least mean regret?\n",
    " - which strategy experiences the least median regret?\n",
    " \n",
    "As mentioned before, there can be \"twins\" in the Pareto front, which means multiple solutions with equal length have equal in-sample performance.\n",
    "In this case we average the out-of-sample score of those twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of wins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table records the number of times a strategy led to the symbolic expression with the best out-of-sample performance (multiple strategies can be the best each task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    out_comparisons = out_comparisons.append(trace.comparison.loc['either'].rename(log))\n",
    "out_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret\n",
    "Here we look at the regret for a method compared to the best known performance on the dataset from the random search experiments. Per definition the best score in random search is 1 (normalized score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median regret:\n",
    "The following table records the median regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only evaluate logs where all tasks in subset have completed\n",
    "\n",
    "full_tasks = [x[0] for x in traces[f\"mlr_{alg}_mupluslambda_0\"].scores.index]\n",
    "subset = set(full_tasks[:20])\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = {}\n",
    "for log, trace in traces.items():\n",
    "    if (subset.issubset(set([x[0] for x in trace.scores.index]))):\n",
    "        idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] in subset)\n",
    "        medians[log] = [(1 - trace.scores[idx].final).median()]\n",
    "        \n",
    "for bl in baselines[alg]:\n",
    "    medians[bl] = [(1 - traces[f\"mlr_{alg}_mupluslambda_0\"].scores[idx][bl]).median()]\n",
    "pd.DataFrame.from_dict(medians,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for log, trace in traces.items():\n",
    "    if (subset.issubset(set([x[0] for x in trace.scores.index]))):\n",
    "        idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] in subset)\n",
    "        means[log] = [(1 - trace.scores[idx].final).mean()]\n",
    "    \n",
    "for bl in baselines[alg]:\n",
    "    means[bl] = [(1 - traces[f\"mlr_{alg}_mupluslambda_0\"].scores[idx][bl]).median()]\n",
    "pd.DataFrame.from_dict(means,orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results averaged over replications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means\n",
    "pd.DataFrame.from_dict(means,orient='index').groupby(lambda x: ''.join(i for i in x if not i.isdigit())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians\n",
    "pd.DataFrame.from_dict(medians,orient='index').groupby(lambda x: ''.join(i for i in x if not i.isdigit())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Sometimes out-of-sample performance of a baseline may still be better than that of our solution.\n",
    "However, in-sample performance of our own solutions should always be better than any baseline.\n",
    "If that is not the case, this would indicate our search does not explore the space well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    in_sample_comparisons = in_sample_comparisons.append(trace.in_comparison.loc['either'].rename(log))\n",
    "in_sample_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = traces['mlr_rf_mupluslambda_2']\n",
    "rs = traces['mlr_rf_random_search_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to random search \n",
    "The following provides an overview over scores for different iterations of random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsdf = pd.read_csv(\"data/mlr_\"+alg+\"_baselines.csv\", index_col=0)\n",
    "rsdf.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "End of notebook - just sketchpad below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trsdf = rsdf.transpose()\n",
    "trsdf.index.name = \"task\"\n",
    "trsdf.index = pd.Index([int(float(x)) for x in trsdf.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = ml.scores.loc[ml.scores.index.map(lambda idx: idx[1] == \"out-sample\")]\n",
    "df.index = pd.Index(df.index.map(lambda idx: idx[0]))\n",
    "df = df.join(trsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,df.median().sort_values().index]\n",
    "p = sns.boxplot(data=df.melt(), y = \"value\", x = \"variable\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45)\n",
    "plt.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ END OF RELEVANT PARTS #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"rf\"\n",
    "run_one = f\"mlr_{alg}_mupluslambda_0\"\n",
    "minimum = dict(knn=100, svm=100, glmnet=100, rpart=60, rf=25)\n",
    "final_scores = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    # Filter out runs with >100 tasks completed:\n",
    "    if len(trace.scores) / 2 > minimum[alg]:\n",
    "        out_sampfirst_n_tasksle = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\")\n",
    "        log_oos = trace.scores.loc[out_sample].final.rename(log)\n",
    "        final_scores = final_scores.append(log_oos)\n",
    "        if log == run_one:\n",
    "            # contains benchmark scores\n",
    "            for b in trace.baseline:\n",
    "                baseline_score = trace.scores.loc[out_sample][b].rename(b)\n",
    "                final_scores = final_scores.append(baseline_score)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out incomplete tasks:\n",
    "final = final_scores.loc[:, ~final_scores.isna().any()]\n",
    "df = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one=\"mlr_svm_lisa\"\n",
    "run_two=\"svm_warm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[[run_one, run_two]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alone = {k: 0 for k in df.index.values}\n",
    "shared = {k: 0 for k in df.index.values}\n",
    "\n",
    "for _, out in df.T.iterrows():\n",
    "    best = out[out == out.max()].index.values\n",
    "    if len(best) == 1:\n",
    "        alone[best[0]] += 1\n",
    "    else:\n",
    "        for winner in best:\n",
    "            shared[winner] += 1\n",
    "\n",
    "alone = {k: alone[k] for k in sorted(alone)}\n",
    "shared = {k: shared[k] for k in sorted(shared)}\n",
    "either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.T.copy()\n",
    "df_out['max'] = df_out.max(axis=1)\n",
    "for col in df_out:\n",
    "    df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "d_cols = [c for c in df_out.columns if c.startswith('d_') and 'max' not in c]\n",
    "df_out[d_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[d_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (df.loc[run_one] - df.loc[run_two]).hist(bins=[(f / 40 - 1) for f in range(81)])\n",
    "ax.set_title(f\"Symbolic - Constant | median: {(df.loc[run_one] - df.loc[run_two]).median():.3f}, mean: {(df.loc[run_one] - df.loc[run_two]).mean():.3f}, {df.shape[1]} tasks\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsdf.columns = [(round(float(x)), 'out-sample')  for x in rsdf.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rsdf.append(final_scores)\n",
    "df.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.transpose().melt(var_name=\"method\", value_name=\"performance\")\n",
    "ax = sns.boxplot(x='method', y='performance', data = pdf)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean regret:\n",
    "The following table records the mean regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame([])\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.mean().rename(log)\n",
    "    means = means.append(m)\n",
    "means[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\"svm\"]:\n",
    "    for search in [\"mupluslambda\", \"random_search\", \"True\"]:\n",
    "        problem_search_dir = os.path.join(\"runs\", f\"{problem}_{search}\")   \n",
    "        for rundir in os.listdir(problem_search_dir):\n",
    "            eval_file = os.path.join(problem_search_dir, rundir, \"evaluations.csv\")\n",
    "            eval_file_new = os.path.join(problem_search_dir, rundir, \"new_evaluations.csv\")\n",
    "            with open(eval_file) as old, open(eval_file_new, 'w') as new:\n",
    "                for line in old.readlines():\n",
    "                    content = line.split(',')\n",
    "                    cs, expr_parts = content[:7], content[7:]\n",
    "                    newsep = ';'.join(cs + [','.join(expr_parts)])\n",
    "                    new.write(newsep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
