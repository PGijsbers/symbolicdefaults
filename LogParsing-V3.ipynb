{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runlog:\n",
    "    \"\"\"\n",
    "    Read logs for a given problem across several searches\n",
    "    \"\"\"\n",
    "    def __init__(self, problem: str, searches: List, benchmarks=None, ignore=None):\n",
    "        self.problem = problem\n",
    "        self.searches = searches\n",
    "        self.benchmarks = benchmarks\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        df = read_run_logs(problem=self.problem, search=self.searches[0], target=\"new_evaluations\")\n",
    "        for search in self.searches[1:]:\n",
    "            df = df.append(read_run_logs(problem=self.problem, search=search, target=\"new_evaluations\"))\n",
    "        return df\n",
    "\n",
    "    def pick_final_expression(self, method = \"best\", **kwargs):\n",
    "        \"\"\"\n",
    "        Pick final expression on \"in\" data\n",
    "        :method: either \"relative\", \"shortest\" or \"best\"\n",
    "        \"\"\"\n",
    "        df = self.data.copy()\n",
    "        df = df[df['expression'].str.contains(',')]\n",
    "        df = df[df.endresult]\n",
    "        df = df.pivot_table(index=[\"run\", \"task\", \"gen\", \"length\", \"problem\", \"search\", \"expression\"], columns=\"inout\", values=\"score\")\n",
    "        df = df.reset_index()\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if method == \"shortest\":\n",
    "            out = df[df.groupby(\"run\")['length'].transform(min) == df['length']]\n",
    "        elif method == \"relative\":\n",
    "            out = df.loc[[pick_relative(group, **kwargs) for name, group in df.groupby('run')]]\n",
    "        else:\n",
    "            out = df[df.groupby(\"run\")['in'].transform(max) == df['in']]\n",
    "        return out\n",
    "    \n",
    "    def get_benchmark_performances(self):\n",
    "        \"\"\"\n",
    "        Load benchmark performances\n",
    "        \"\"\"\n",
    "        df = self.data[self.data['expression'].isin(self.benchmarks)]\n",
    "        df = df.pivot_table(index=[\"run\", \"task\",\"problem\", \"search\", \"expression\"], columns=\"inout\", values=\"score\")\n",
    "        df = df.reset_index()\n",
    "        df = df[[\"task\", \"problem\", \"expression\", \"in\", \"out\"]]\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        return(df)\n",
    "        \n",
    "def pick_relative(x, eps=0.01, max_steps=1):\n",
    "    \"\"\"\n",
    "    Pick by relative improvement; \n",
    "    Consider only at most `max_steps` longer, if better by 'eps', break if not\n",
    "    \"\"\"\n",
    "    x = x.copy()\n",
    "    if len(x) == 1:\n",
    "        return(x.index.values[0])\n",
    "    \n",
    "    use_ix, length, score = None, 0, 0\n",
    "    for ix, rw in x.iterrows():\n",
    "        if rw['length'] - length > max_steps:\n",
    "            break  # candidates are too big\n",
    "        if rw['in'] - score < eps:\n",
    "            continue  # not enough increase\n",
    "        use_ix, length, score = ix, rw['length'], rw['in']        \n",
    "#     x['relative_improvement'] = x['in'] - x['in'].shift(1, fill_value=0)\n",
    "#     for ix, rw in x.iterrows():\n",
    "#         if (rw['relative_improvement'] > eps):\n",
    "#             use_ix = ix\n",
    "#         else:\n",
    "#             break\n",
    "    return use_ix\n",
    "\n",
    "def read_run_logs(problem:str, search: str, target: str):\n",
    "    \"\"\"\n",
    "    Read all log-files for a given problem x search combination\n",
    "    \"\"\"\n",
    "    log_dir = f\"svm_results/{problem}_{search}/\"\n",
    "    dirs = [os.path.join(log_dir, f) for f in os.listdir(log_dir)]\n",
    "    df = pd.read_csv(f\"{dirs[0]}/{target}.csv\", sep=\";\",nrows=0)\n",
    "    for dir in dirs: \n",
    "        df = df.append(pd.read_csv(f\"{dir}/{target}.csv\", sep=\";\"))\n",
    "    df['problem'] = problem\n",
    "    df['search'] = search\n",
    "    df['search']\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inout</th>\n",
       "      <th>run</th>\n",
       "      <th>task</th>\n",
       "      <th>gen</th>\n",
       "      <th>length</th>\n",
       "      <th>problem</th>\n",
       "      <th>search</th>\n",
       "      <th>expression</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>fd34135f-3fce-447f-a6ad-3787af8ea910</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>True</td>\n",
       "      <td>make_tuple(1104, 0.0013406724766291032)</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.9923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "      <td>Consant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "inout                                   run     task      gen   length  \\\n",
       "0                                   Consant  Consant  Consant  Consant   \n",
       "3                                   Consant  Consant  Consant  Consant   \n",
       "9                                   Consant  Consant  Consant  Consant   \n",
       "14                                  Consant  Consant  Consant  Consant   \n",
       "18                                  Consant  Consant  Consant  Consant   \n",
       "..                                      ...      ...      ...      ...   \n",
       "643                                 Consant  Consant  Consant  Consant   \n",
       "646    fd34135f-3fce-447f-a6ad-3787af8ea910       14       40        1   \n",
       "648                                 Consant  Consant  Consant  Consant   \n",
       "653                                 Consant  Consant  Consant  Consant   \n",
       "656                                 Consant  Consant  Consant  Consant   \n",
       "\n",
       "inout  problem   search                               expression       in  \\\n",
       "0      Consant  Consant                                  Consant  Consant   \n",
       "3      Consant  Consant                                  Consant  Consant   \n",
       "9      Consant  Consant                                  Consant  Consant   \n",
       "14     Consant  Consant                                  Consant  Consant   \n",
       "18     Consant  Consant                                  Consant  Consant   \n",
       "..         ...      ...                                      ...      ...   \n",
       "643    Consant  Consant                                  Consant  Consant   \n",
       "646        svm     True  make_tuple(1104, 0.0013406724766291032)    0.861   \n",
       "648    Consant  Consant                                  Consant  Consant   \n",
       "653    Consant  Consant                                  Consant  Consant   \n",
       "656    Consant  Consant                                  Consant  Consant   \n",
       "\n",
       "inout      out  \n",
       "0      Consant  \n",
       "3      Consant  \n",
       "9      Consant  \n",
       "14     Consant  \n",
       "18     Consant  \n",
       "..         ...  \n",
       "643    Consant  \n",
       "646     0.9923  \n",
       "648    Consant  \n",
       "653    Consant  \n",
       "656    Consant  \n",
       "\n",
       "[261 rows x 9 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = [\"sklearn_default\", \"mlr_default\", \"symbolic_best\"]\n",
    "log = Runlog('svm',  [\"mupluslambda\", \"random_search\", \"True\"], benchmarks=benchmarks)\n",
    "\n",
    "df = log.pick_final_expression('relative')\n",
    "df.where(df[\"search\"] == \"True\", \"Consant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">in</th>\n",
       "      <th colspan=\"2\" halign=\"left\">out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.86110</td>\n",
       "      <td>0.961923</td>\n",
       "      <td>0.96565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_default</th>\n",
       "      <td>0.965774</td>\n",
       "      <td>0.97905</td>\n",
       "      <td>0.359338</td>\n",
       "      <td>0.07950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mupluslambda</th>\n",
       "      <td>0.899610</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.963979</td>\n",
       "      <td>0.97090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_search</th>\n",
       "      <td>0.894698</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.967806</td>\n",
       "      <td>0.98420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_default</th>\n",
       "      <td>0.965774</td>\n",
       "      <td>0.97905</td>\n",
       "      <td>0.946495</td>\n",
       "      <td>0.95015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbolic_best</th>\n",
       "      <td>0.965774</td>\n",
       "      <td>0.97905</td>\n",
       "      <td>0.977860</td>\n",
       "      <td>0.98160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       in                out         \n",
       "                     mean   median      mean   median\n",
       "search                                               \n",
       "True             0.860870  0.86110  0.961923  0.96565\n",
       "mlr_default      0.965774  0.97905  0.359338  0.07950\n",
       "mupluslambda     0.899610  0.90090  0.963979  0.97090\n",
       "random_search    0.894698  0.88990  0.967806  0.98420\n",
       "sklearn_default  0.965774  0.97905  0.946495  0.95015\n",
       "symbolic_best    0.965774  0.97905  0.977860  0.98160"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final expression and Benchmark performances \n",
    "cols = [\"task\", \"problem\", \"search\", \"in\", \"out\"]\n",
    "df = log.pick_final_expression('relative')[cols]\n",
    "bdf = log.get_benchmark_performances().rename(columns={\"expression\":\"search\"})[cols]\n",
    "df = df.append(bdf)\n",
    "df.groupby(\"search\")[[\"in\", \"out\"]].agg([np.mean, np.median]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d635c8190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df, x=\"task\", y=\"out\", hue = \"search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"task\", \"problem\", \"search\", \"in\", \"out\"]\n",
    "big_df = pd.DataFrame()\n",
    "for strat in [\"best\", \"shortest\", \"relative\"]:\n",
    "    df = log.pick_final_expression(strat, eps=0.01, max_steps=2)[cols]\n",
    "    bdf = log.get_benchmark_performances().rename(columns={\"expression\":\"search\"})[cols]\n",
    "    df = df.append(bdf)\n",
    "    df = df[df.search.isin([\"mupluslambda\", \"random_search\", \"True\"])]\n",
    "    df[\"strategy\"] = strat\n",
    "    big_df = pd.concat([big_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">in</th>\n",
       "      <th colspan=\"4\" halign=\"left\">out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>search</th>\n",
       "      <th>strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861259</td>\n",
       "      <td>0.86150</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.945227</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.86140</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.86140</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.94910</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.905138</td>\n",
       "      <td>0.90360</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.91460</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.900360</td>\n",
       "      <td>0.90170</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.924555</td>\n",
       "      <td>0.91320</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.90170</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.937088</td>\n",
       "      <td>0.91320</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894129</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.943682</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964100</td>\n",
       "      <td>0.96410</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861200</td>\n",
       "      <td>0.86160</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941591</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.86155</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941390</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861280</td>\n",
       "      <td>0.86155</td>\n",
       "      <td>0.8616</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.941390</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.990330</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896710</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.990380</td>\n",
       "      <td>0.99110</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899450</td>\n",
       "      <td>0.90040</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.980790</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.8836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861467</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.898592</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.899580</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.86180</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.899580</td>\n",
       "      <td>0.89480</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.905036</td>\n",
       "      <td>0.90500</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.912864</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.901130</td>\n",
       "      <td>0.90180</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.904970</td>\n",
       "      <td>0.89660</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.901080</td>\n",
       "      <td>0.90180</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.925510</td>\n",
       "      <td>0.92360</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896160</td>\n",
       "      <td>0.89615</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>0.89890</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.890500</td>\n",
       "      <td>0.89050</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.8905</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.90120</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.85970</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.99880</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860278</td>\n",
       "      <td>0.85990</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860278</td>\n",
       "      <td>0.85990</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.903540</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.900090</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900420</td>\n",
       "      <td>0.89970</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.892870</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">14</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.99305</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.904010</td>\n",
       "      <td>0.90355</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.992630</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.901520</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.992760</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900275</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.896487</td>\n",
       "      <td>0.90020</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.994487</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.861083</td>\n",
       "      <td>0.86120</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976617</td>\n",
       "      <td>0.97820</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860810</td>\n",
       "      <td>0.86105</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976580</td>\n",
       "      <td>0.97810</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860810</td>\n",
       "      <td>0.86105</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.976580</td>\n",
       "      <td>0.97810</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.904446</td>\n",
       "      <td>0.90380</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.977862</td>\n",
       "      <td>0.98360</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.898060</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.977380</td>\n",
       "      <td>0.97970</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.961900</td>\n",
       "      <td>0.96190</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899710</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>0.978590</td>\n",
       "      <td>0.98615</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.89515</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.975390</td>\n",
       "      <td>0.97175</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.961900</td>\n",
       "      <td>0.96190</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.85980</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991093</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.86040</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.901556</td>\n",
       "      <td>0.90350</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.997933</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998056</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.900244</td>\n",
       "      <td>0.90090</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894600</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998056</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.88950</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">18</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>best</th>\n",
       "      <td>0.860593</td>\n",
       "      <td>0.86010</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.966093</td>\n",
       "      <td>0.96220</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.860650</td>\n",
       "      <td>0.86065</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.96565</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.860650</td>\n",
       "      <td>0.86065</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.96565</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mupluslambda</th>\n",
       "      <th>best</th>\n",
       "      <td>0.902210</td>\n",
       "      <td>0.90110</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.970420</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.899200</td>\n",
       "      <td>0.90110</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.968960</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random_search</th>\n",
       "      <th>best</th>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.90060</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.970470</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0.894450</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.968470</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortest</th>\n",
       "      <td>0.889900</td>\n",
       "      <td>0.88990</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.964200</td>\n",
       "      <td>0.96420</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   in                                out  \\\n",
       "                                 mean   median     max     min      mean   \n",
       "task search        strategy                                                \n",
       "3    True          best      0.861259  0.86150  0.8615  0.8603  0.945227   \n",
       "                   relative  0.861242  0.86140  0.8615  0.8603  0.946300   \n",
       "                   shortest  0.861242  0.86140  0.8615  0.8603  0.946300   \n",
       "     mupluslambda  best      0.905138  0.90360  0.9153  0.9017  0.924071   \n",
       "                   relative  0.900360  0.90170  0.9047  0.8899  0.924555   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964100   \n",
       "     random_search best      0.900494  0.90170  0.9049  0.8948  0.937088   \n",
       "                   relative  0.894129  0.88990  0.9028  0.8899  0.943682   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964100   \n",
       "6    True          best      0.861200  0.86160  0.8616  0.8602  0.941591   \n",
       "                   relative  0.861280  0.86155  0.8616  0.8602  0.941390   \n",
       "                   shortest  0.861280  0.86155  0.8616  0.8602  0.941390   \n",
       "     mupluslambda  best      0.902000  0.90090  0.9085  0.8980  0.990330   \n",
       "                   relative  0.896710  0.90090  0.9042  0.8896  0.990380   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.989200   \n",
       "     random_search best      0.899450  0.90040  0.9020  0.8948  0.980790   \n",
       "                   relative  0.894040  0.88960  0.9009  0.8896  0.990060   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.989200   \n",
       "11   True          best      0.861467  0.86180  0.8619  0.8607  0.898592   \n",
       "                   relative  0.861500  0.86180  0.8619  0.8607  0.899580   \n",
       "                   shortest  0.861500  0.86180  0.8619  0.8607  0.899580   \n",
       "     mupluslambda  best      0.905036  0.90500  0.9109  0.8992  0.912864   \n",
       "                   relative  0.901130  0.90180  0.9044  0.8905  0.904970   \n",
       "                   shortest  0.890500  0.89050  0.8905  0.8905  0.901200   \n",
       "     random_search best      0.901080  0.90180  0.9031  0.8986  0.925510   \n",
       "                   relative  0.896160  0.89615  0.9019  0.8905  0.898900   \n",
       "                   shortest  0.890500  0.89050  0.8905  0.8905  0.901200   \n",
       "12   True          best      0.860162  0.85970  0.8610  0.8597  0.998700   \n",
       "                   relative  0.860278  0.85990  0.8610  0.8597  0.998678   \n",
       "                   shortest  0.860278  0.85990  0.8610  0.8597  0.998678   \n",
       "     mupluslambda  best      0.903540  0.90090  0.9169  0.8989  0.997460   \n",
       "                   relative  0.900090  0.90090  0.9042  0.8895  0.997600   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.999000   \n",
       "     random_search best      0.900420  0.89970  0.9038  0.8968  0.996910   \n",
       "                   relative  0.892870  0.88950  0.9009  0.8895  0.998650   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.999000   \n",
       "14   True          best      0.860420  0.86040  0.8611  0.8598  0.992800   \n",
       "                   relative  0.860390  0.86040  0.8611  0.8597  0.992800   \n",
       "                   shortest  0.860390  0.86040  0.8611  0.8597  0.992800   \n",
       "     mupluslambda  best      0.904010  0.90355  0.9089  0.9009  0.992630   \n",
       "                   relative  0.901520  0.90090  0.9042  0.9005  0.992760   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.995900   \n",
       "     random_search best      0.900275  0.90090  0.9021  0.8960  0.991000   \n",
       "                   relative  0.896487  0.90020  0.9009  0.8896  0.994487   \n",
       "                   shortest  0.889600  0.88960  0.8896  0.8896  0.995900   \n",
       "15   True          best      0.861083  0.86120  0.8612  0.8601  0.976617   \n",
       "                   relative  0.860810  0.86105  0.8612  0.8601  0.976580   \n",
       "                   shortest  0.860810  0.86105  0.8612  0.8601  0.976580   \n",
       "     mupluslambda  best      0.904446  0.90380  0.9099  0.9009  0.977862   \n",
       "                   relative  0.898060  0.90090  0.9033  0.8899  0.977380   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.961900   \n",
       "     random_search best      0.899710  0.89985  0.9033  0.8971  0.978590   \n",
       "                   relative  0.895590  0.89515  0.9033  0.8899  0.975390   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.961900   \n",
       "16   True          best      0.860360  0.85980  0.8611  0.8597  0.991093   \n",
       "                   relative  0.860420  0.86040  0.8611  0.8597  0.991170   \n",
       "                   shortest  0.860420  0.86040  0.8611  0.8597  0.991170   \n",
       "     mupluslambda  best      0.901556  0.90350  0.9044  0.8947  0.997933   \n",
       "                   relative  0.899000  0.90090  0.9040  0.8895  0.998056   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.998100   \n",
       "     random_search best      0.900244  0.90090  0.9030  0.8963  0.998244   \n",
       "                   relative  0.894600  0.88950  0.9012  0.8895  0.998056   \n",
       "                   shortest  0.889500  0.88950  0.8895  0.8895  0.998100   \n",
       "18   True          best      0.860593  0.86010  0.8613  0.8601  0.966093   \n",
       "                   relative  0.860650  0.86065  0.8613  0.8600  0.966620   \n",
       "                   shortest  0.860650  0.86065  0.8613  0.8600  0.966620   \n",
       "     mupluslambda  best      0.902210  0.90110  0.9085  0.8996  0.970420   \n",
       "                   relative  0.899200  0.90110  0.9045  0.8899  0.968960   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964200   \n",
       "     random_search best      0.899820  0.90060  0.9035  0.8958  0.970470   \n",
       "                   relative  0.894450  0.88990  0.9018  0.8899  0.968470   \n",
       "                   shortest  0.889900  0.88990  0.8899  0.8899  0.964200   \n",
       "\n",
       "                                                      \n",
       "                              median     max     min  \n",
       "task search        strategy                           \n",
       "3    True          best      0.94910  0.9526  0.9293  \n",
       "                   relative  0.94910  0.9526  0.9293  \n",
       "                   shortest  0.94910  0.9526  0.9293  \n",
       "     mupluslambda  best      0.91460  0.9908  0.8888  \n",
       "                   relative  0.91320  0.9641  0.9020  \n",
       "                   shortest  0.96410  0.9641  0.9641  \n",
       "     random_search best      0.91320  0.9960  0.8715  \n",
       "                   relative  0.96410  0.9641  0.8715  \n",
       "                   shortest  0.96410  0.9641  0.9641  \n",
       "6    True          best      0.94140  0.9436  0.9369  \n",
       "                   relative  0.94140  0.9436  0.9369  \n",
       "                   shortest  0.94140  0.9436  0.9369  \n",
       "     mupluslambda  best      0.99120  0.9927  0.9846  \n",
       "                   relative  0.99110  0.9912  0.9892  \n",
       "                   shortest  0.98920  0.9892  0.9892  \n",
       "     random_search best      0.99120  0.9958  0.8836  \n",
       "                   relative  0.98920  0.9918  0.9892  \n",
       "                   shortest  0.98920  0.9892  0.9892  \n",
       "11   True          best      0.89480  0.9085  0.8925  \n",
       "                   relative  0.89480  0.9085  0.8925  \n",
       "                   shortest  0.89480  0.9085  0.8925  \n",
       "     mupluslambda  best      0.90120  0.9507  0.8966  \n",
       "                   relative  0.89660  0.9364  0.8966  \n",
       "                   shortest  0.90120  0.9012  0.9012  \n",
       "     random_search best      0.92360  0.9635  0.8966  \n",
       "                   relative  0.89890  0.9012  0.8966  \n",
       "                   shortest  0.90120  0.9012  0.9012  \n",
       "12   True          best      0.99880  0.9989  0.9983  \n",
       "                   relative  0.99870  0.9989  0.9985  \n",
       "                   shortest  0.99870  0.9989  0.9985  \n",
       "     mupluslambda  best      0.99750  0.9991  0.9960  \n",
       "                   relative  0.99750  0.9990  0.9970  \n",
       "                   shortest  0.99900  0.9990  0.9990  \n",
       "     random_search best      0.99650  0.9988  0.9963  \n",
       "                   relative  0.99900  0.9990  0.9975  \n",
       "                   shortest  0.99900  0.9990  0.9990  \n",
       "14   True          best      0.99305  0.9945  0.9906  \n",
       "                   relative  0.99305  0.9945  0.9906  \n",
       "                   shortest  0.99305  0.9945  0.9906  \n",
       "     mupluslambda  best      0.99440  0.9955  0.9860  \n",
       "                   relative  0.99440  0.9944  0.9862  \n",
       "                   shortest  0.99590  0.9959  0.9959  \n",
       "     random_search best      0.99200  0.9944  0.9838  \n",
       "                   relative  0.99440  0.9959  0.9906  \n",
       "                   shortest  0.99590  0.9959  0.9959  \n",
       "15   True          best      0.97820  0.9782  0.9732  \n",
       "                   relative  0.97810  0.9787  0.9732  \n",
       "                   shortest  0.97810  0.9787  0.9732  \n",
       "     mupluslambda  best      0.98360  0.9907  0.9385  \n",
       "                   relative  0.97970  0.9907  0.9619  \n",
       "                   shortest  0.96190  0.9619  0.9619  \n",
       "     random_search best      0.98615  0.9921  0.9575  \n",
       "                   relative  0.97175  0.9907  0.9619  \n",
       "                   shortest  0.96190  0.9619  0.9619  \n",
       "16   True          best      0.99270  0.9927  0.9883  \n",
       "                   relative  0.99120  0.9927  0.9894  \n",
       "                   shortest  0.99120  0.9927  0.9894  \n",
       "     mupluslambda  best      0.99780  0.9985  0.9976  \n",
       "                   relative  0.99780  0.9988  0.9978  \n",
       "                   shortest  0.99810  0.9981  0.9981  \n",
       "     random_search best      0.99850  0.9989  0.9977  \n",
       "                   relative  0.99810  0.9986  0.9978  \n",
       "                   shortest  0.99810  0.9981  0.9981  \n",
       "18   True          best      0.96220  0.9718  0.9609  \n",
       "                   relative  0.96565  0.9719  0.9609  \n",
       "                   shortest  0.96565  0.9719  0.9609  \n",
       "     mupluslambda  best      0.97090  0.9745  0.9653  \n",
       "                   relative  0.97090  0.9709  0.9642  \n",
       "                   shortest  0.96420  0.9642  0.9642  \n",
       "     random_search best      0.97090  0.9868  0.9624  \n",
       "                   relative  0.96420  0.9868  0.9642  \n",
       "                   shortest  0.96420  0.9642  0.9642  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(big_df.groupby([\"task\", \"search\",  \"strategy\"])[[\"in\", \"out\"]].agg([np.mean, np.median, max, min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19f9cf66588>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=big_df[big_df.search == \"mupluslambda\"], x=\"task\", y=\"out\", hue=\"strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We have experiment data for a set of algorithms and meta-data for the datasets on which the experiments took place.\n",
    "We use symbolic regression to find an expression for symbolic default values that give good performance across tasks.\n",
    "Symbolic regression is performed with leave-one-task-out, which means for each algorithm we have multiple searches for a symbolic default, and their performance is recorded for both in-sample (the optimization surface of all-but-one tasks) and out-of-sample (the left out task) performance. Performance here is solely based on surrogate model predictions, no additional experiments have been performed (yet).\n",
    "\n",
    "In our search, we use NSGA-II selection to perform multi-objective optimization: find the expression with the best performance, while using the fewest number of operators (e.g. `divide`, `multiply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "**Length** of an expression denotes the number of operators in it. A symbolic value is *not* considered an operation.\n",
    "Consider the following SVM defaults for cost and gamma:\n",
    " - `make_tuple`(m, mkd) is length 1.\n",
    " - `make_tuple`(m, `truediv`(mkd, xvar)) is length 2.\n",
    " - `make_tuple`(16., `truediv`(mkd, xvar)) is length 2.\n",
    "\n",
    "The **final** solution refers to the symbolic default with the highest in-sample score for a task (regardless of its length). This means for each task there is *at least* one final solution, but there may be more and they are not of a specific length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline** solutions are typically the default hyperparameter settings of mlr, scikit-learn, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the logs, because some logs are incomplete we have to explicitly give the name of the baselines (this will be fixed for future runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we analyze the random forest\n",
    "alg = 'rf'\n",
    "\n",
    "import os\n",
    "baselines = dict(\n",
    "    glmnet=[\"mlr_default\", \"sklearn_default\"],\n",
    "    kerasff=[\"initial_values\"],\n",
    "    knn=[\"mlr_default\"],\n",
    "    rf=[\"mlr_default\"],\n",
    "    rpart=[\"mlr_default\"],\n",
    "    svm=[\"sklearn_scale\", \"symbolic_best\", \"skearn_default\", \"mlr_default\" , \"const\"],\n",
    ")\n",
    "dir_ = \"runs/running\"\n",
    "for file in os.listdir(dir_):\n",
    "    if file.endswith('.log') and alg in file and ('_0.log' in file or '_1.log' in file):\n",
    "        print(file)\n",
    "        baseline = []\n",
    "        for method, bls in baselines.items():\n",
    "            if method in file:\n",
    "                baseline = bls\n",
    "        traces[file[:-4]] = Trace(os.path.join(dir_, file), benchmarks=baseline, ignore=[\"const\", \"symbolic_v2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "As described before, for each problem we find a symbolic default leaving one task out.\n",
    "We are interested to see how fast the symbolic regression converges across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median number of generations across tasks by problem:\")\n",
    "for log, trace in traces.items():\n",
    "    print(f\"{log: <15} {trace.generations_by_task.median().astype(int):3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {k :v for (k,v) in traces.items() if k not in [\"mlr_glmnet_lisa_ints_0\", \"mlr_glmnet_lisa_ints_1\", \"mlr_glmnet_lisa_ints_2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(traces) / 4), 4, sharey=True, figsize=(16, 9))\n",
    "for ax, (log, trace) in zip(axes.flatten(), traces.items()):\n",
    "    traces[log].generations_by_task.hist(bins=20, ax=ax)\n",
    "    ax.set_title(f\"{log} ({len(trace.generations_by_task)} tasks)\")\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('generations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a histogram counting the number of generations until stopping. These results were obtained with default setting of early stopping if no improvement was made after 20 generations, with a 200 generation maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing optimization traces\n",
    "The traces contain the full optimization traces inside the trace's **progdf** trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2'].progdf)\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2i'].progdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Expressions\n",
    "For a given problem, we have a Pareto front of solutions for search (=each left out task).\n",
    "This Pareto front may contain \"twins\", multiple solutions which performance equally well and have the same length.\n",
    "Given that the response surface does not differ *that* much when leaving any particular task out, we hope that the symbolic expressions we find are reasonably consistent across searches.\n",
    "To have some indication of how consistent the results are, for each problem we find the most frequent solutions of length 1, 2 and 3. We also note the number of hyperparameters for which we aim to find a symbolic default, as we expect this to be correlated to how consistent the solutions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_count = pd.DataFrame(np.zeros((5, len(traces))), columns=list(traces), index=[1, 2, 3, \"#tasks\", \"params\"])\n",
    "for log, trace in traces.items():  \n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            if length == 1:\n",
    "                expr_count.loc[\"#tasks\"][log] = len(trace.scores) / 2\n",
    "                expr_count.loc[\"params\"][log] = m.count(',') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the found expressions per problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f'{alg}' # run_one #f\"mlr_knn_lisa_gaussian\" # run_one\n",
    "for log, trace in traces.items():\n",
    "    print(log)\n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            print(f\"Most frequent length {length} solution in Pareto front ({expressions.count(m)} times in {len(trace.scores) // 2} tasks):\\n     {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Quality\n",
    "The expressions we find also need to be good.\n",
    "Here we compare the following 'strategies':\n",
    " - length-*n*: always pick the best expression of length *n*\n",
    " - *final*: always pick the best expression, regardless of length\n",
    " - *baseline(s)*: compare it to baselines we defined\n",
    " \n",
    "We want to know (all based on out-of-sample performance):\n",
    " - which strategy gives the best solution most often?\n",
    " - which strategy experiences the least mean regret?\n",
    " - which strategy experiences the least median regret?\n",
    " \n",
    "As mentioned before, there can be \"twins\" in the Pareto front, which means multiple solutions with equal length have equal in-sample performance.\n",
    "In this case we average the out-of-sample score of those twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of wins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table records the number of times a strategy led to the symbolic expression with the best out-of-sample performance (multiple strategies can be the best each task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    out_comparisons = out_comparisons.append(trace.comparison.loc['either'].rename(log))\n",
    "out_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret\n",
    "Here we look at the regret for a method compared to the best known performance on the dataset from the random search experiments. Per definition the best score in random search is 1 (normalized score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median regret:\n",
    "The following table records the median regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only evaluate logs where all tasks in subset have completed\n",
    "\n",
    "full_tasks = [x[0] for x in traces[f\"mlr_{alg}_mupluslambda_0\"].scores.index]\n",
    "subset = set(full_tasks[:20])\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = {}\n",
    "for log, trace in traces.items():\n",
    "    if (subset.issubset(set([x[0] for x in trace.scores.index]))):\n",
    "        idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] in subset)\n",
    "        medians[log] = [(1 - trace.scores[idx].final).median()]\n",
    "        \n",
    "for bl in baselines[alg]:\n",
    "    medians[bl] = [(1 - traces[f\"mlr_{alg}_mupluslambda_0\"].scores[idx][bl]).median()]\n",
    "pd.DataFrame.from_dict(medians,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for log, trace in traces.items():\n",
    "    if (subset.issubset(set([x[0] for x in trace.scores.index]))):\n",
    "        idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] in subset)\n",
    "        means[log] = [(1 - trace.scores[idx].final).mean()]\n",
    "    \n",
    "for bl in baselines[alg]:\n",
    "    means[bl] = [(1 - traces[f\"mlr_{alg}_mupluslambda_0\"].scores[idx][bl]).median()]\n",
    "pd.DataFrame.from_dict(means,orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results averaged over replications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means\n",
    "pd.DataFrame.from_dict(means,orient='index').groupby(lambda x: ''.join(i for i in x if not i.isdigit())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medians\n",
    "pd.DataFrame.from_dict(medians,orient='index').groupby(lambda x: ''.join(i for i in x if not i.isdigit())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Sometimes out-of-sample performance of a baseline may still be better than that of our solution.\n",
    "However, in-sample performance of our own solutions should always be better than any baseline.\n",
    "If that is not the case, this would indicate our search does not explore the space well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    in_sample_comparisons = in_sample_comparisons.append(trace.in_comparison.loc['either'].rename(log))\n",
    "in_sample_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = traces['mlr_rf_mupluslambda_2']\n",
    "rs = traces['mlr_rf_random_search_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to random search \n",
    "The following provides an overview over scores for different iterations of random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsdf = pd.read_csv(\"data/mlr_\"+alg+\"_baselines.csv\", index_col=0)\n",
    "rsdf.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "End of notebook - just sketchpad below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trsdf = rsdf.transpose()\n",
    "trsdf.index.name = \"task\"\n",
    "trsdf.index = pd.Index([int(float(x)) for x in trsdf.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = ml.scores.loc[ml.scores.index.map(lambda idx: idx[1] == \"out-sample\")]\n",
    "df.index = pd.Index(df.index.map(lambda idx: idx[0]))\n",
    "df = df.join(trsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,df.median().sort_values().index]\n",
    "p = sns.boxplot(data=df.melt(), y = \"value\", x = \"variable\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45)\n",
    "plt.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ END OF RELEVANT PARTS #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"rf\"\n",
    "run_one = f\"mlr_{alg}_mupluslambda_0\"\n",
    "minimum = dict(knn=100, svm=100, glmnet=100, rpart=60, rf=25)\n",
    "final_scores = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    # Filter out runs with >100 tasks completed:\n",
    "    if len(trace.scores) / 2 > minimum[alg]:\n",
    "        out_sampfirst_n_tasksle = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\")\n",
    "        log_oos = trace.scores.loc[out_sample].final.rename(log)\n",
    "        final_scores = final_scores.append(log_oos)\n",
    "        if log == run_one:\n",
    "            # contains benchmark scores\n",
    "            for b in trace.baseline:\n",
    "                baseline_score = trace.scores.loc[out_sample][b].rename(b)\n",
    "                final_scores = final_scores.append(baseline_score)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out incomplete tasks:\n",
    "final = final_scores.loc[:, ~final_scores.isna().any()]\n",
    "df = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one=\"mlr_svm_lisa\"\n",
    "run_two=\"svm_warm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[[run_one, run_two]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alone = {k: 0 for k in df.index.values}\n",
    "shared = {k: 0 for k in df.index.values}\n",
    "\n",
    "for _, out in df.T.iterrows():\n",
    "    best = out[out == out.max()].index.values\n",
    "    if len(best) == 1:\n",
    "        alone[best[0]] += 1\n",
    "    else:\n",
    "        for winner in best:\n",
    "            shared[winner] += 1\n",
    "\n",
    "alone = {k: alone[k] for k in sorted(alone)}\n",
    "shared = {k: shared[k] for k in sorted(shared)}\n",
    "either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.T.copy()\n",
    "df_out['max'] = df_out.max(axis=1)\n",
    "for col in df_out:\n",
    "    df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "d_cols = [c for c in df_out.columns if c.startswith('d_') and 'max' not in c]\n",
    "df_out[d_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[d_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (df.loc[run_one] - df.loc[run_two]).hist(bins=[(f / 40 - 1) for f in range(81)])\n",
    "ax.set_title(f\"Symbolic - Constant | median: {(df.loc[run_one] - df.loc[run_two]).median():.3f}, mean: {(df.loc[run_one] - df.loc[run_two]).mean():.3f}, {df.shape[1]} tasks\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsdf.columns = [(round(float(x)), 'out-sample')  for x in rsdf.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rsdf.append(final_scores)\n",
    "df.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.transpose().melt(var_name=\"method\", value_name=\"performance\")\n",
    "ax = sns.boxplot(x='method', y='performance', data = pdf)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean regret:\n",
    "The following table records the mean regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame([])\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.mean().rename(log)\n",
    "    means = means.append(m)\n",
    "means[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\"svm\"]:\n",
    "    for search in [\"mupluslambda\", \"random_search\", \"True\"]:\n",
    "        problem_search_dir = os.path.join(\"runs\", f\"{problem}_{search}\")   \n",
    "        for rundir in os.listdir(problem_search_dir):\n",
    "            eval_file = os.path.join(problem_search_dir, rundir, \"evaluations.csv\")\n",
    "            eval_file_new = os.path.join(problem_search_dir, rundir, \"new_evaluations.csv\")\n",
    "            with open(eval_file) as old, open(eval_file_new, 'w') as new:\n",
    "                for line in old.readlines():\n",
    "                    content = line.split(',')\n",
    "                    cs, expr_parts = content[:7], content[7:]\n",
    "                    newsep = ';'.join(cs + [','.join(expr_parts)])\n",
    "                    new.write(newsep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
