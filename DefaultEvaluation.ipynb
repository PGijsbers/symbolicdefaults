{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of default configurations\n",
    "\n",
    "\n",
    "We have two answer to questions:\n",
    " 1. By which method can we find good Symbolic Defaults? \n",
    " 2. **Can we find good (i.e. better than currently known) symbolic defaults?**\n",
    " \n",
    "This notebook addresses the second question.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general remarks:\n",
    " - does not currently factor in runtime, but this may be especially important for default values. I didn't explicitly measure runtime, but the 'symbolic defaults' in adaboost take much longer (because it significantly increases `n_estimators` and `max_depth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from persistence import load_problem, load_results_for_problem\n",
    "from visualization.output_parser import get_performance_from_console_output, get_performance_from_csv\n",
    "\n",
    "def load_random_search_results(problem_name):\n",
    "    p = load_problem('problems.json', problem_name)\n",
    "    return load_results_for_problem(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After determining good symbolic defaults, we ought to see how they compare to current (scikit-learn) defaults. To this end, we compare three different default configurations (in bold is the name by which they will be referenced henceforth):\n",
    "\n",
    " - The **symbolic_pre** defaults we found from evolutionary optimization, specifically: `C=128, gamma=(mkd / 4)`. \n",
    " This symbolic function uses metafeatures as calculated on the dataset *before* it is preprocessed.\n",
    " - The **symbolic_post** defaults we found from evolutionary optimization, specifically: `C=64, gamma=mkd`.\n",
    "     This symbolic function uses metafeatures as calculated on the dataset *after* it has been preprocessed.\n",
    " - The scikit-learn **0.20** defaults, specifically: `C=1., gamma=(1 / n_features)`\n",
    " - The scikit-learn >= **0.22** defaults, specifically: `C=1., gamma=(1 / (n_features * X.var()))`\n",
    " \n",
    "Note that actually all of these defaults are symbolic.\n",
    "\n",
    "A second important detail to note is that these settings are not tried by themselves.\n",
    "A (fairly standard) preprocessing pipeline is applied:\n",
    " - **Imputation**: using the mean for numeric features, and the most frequent value for categorical features.\n",
    " - **Transformation**: numeric features are scaled to N(0, 1), categorical features are one-hot encoded.\n",
    " - **Feature Selection**: all constant features are removed.\n",
    " \n",
    "After these steps, the SVC is invoked on the preprocessed data with the given values for `C` and `gamma`.\n",
    "\n",
    "Note: for the scikit-learn defaults, currently the metafeatures of the preprocessed data are used (e.g. `n_features` is determined after one-hot encoding, for instance). For the *symbolic* method `mkd` is determined on the original, (largely) unprocessed dataset (samples with NaN values are ignored)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a.1  Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The grid search result from Jan.\n",
    "svc_results = load_random_search_results('svc_rbf')\n",
    "\n",
    "# results currently still stored in log. should be aggregated to single file..\n",
    "# \"data/results/pipeline_c128mkd4.txt\"\n",
    "symb_default_performances = get_performance_from_csv(\"data/results/ppp_svc_rbf_C32_Gmkd.txt\")\n",
    "old_default_performances = get_performance_from_csv(\"data/results/ppp_svc_rbf_default.txt\")\n",
    "new_default_performances = get_performance_from_csv(\"data/results/ppp_svc_rbf_default_Gscale.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a.2 Comparing Results\n",
    "We compare results by number of times one's average cross-validation performance is better (first three columns) and by their loss as compared to the best found result in the original set of experiments ('loss' column).\n",
    "\n",
    "**note:** The 'loss' column is calculated over all executed tasks with the default, because of work-in-progress/earlier cut-off with time constaints, currently the amount of tasks evaluated per method differs, so you find the amount of tasks for which the defaults have been evaluated in the 'N' column. The total loss is *not* normalized for the amount of completed tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic outperformed best on task 12 by -1.1102230246251565e-16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbolic</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.22</th>\n",
       "      <th>loss</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Symbolic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.882626</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.107663</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.493432</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Symbolic  0.20  0.22      loss     N\n",
       "Symbolic       0.0  67.0  65.0  1.882626  92.0\n",
       "0.20          19.0   0.0   3.0  4.107663  92.0\n",
       "0.22          21.0  26.0   0.0  3.493432  92.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "methods = ['Symbolic', '0.20', '0.22']\n",
    "df = pd.DataFrame(np.zeros(shape=(len(methods), len(methods)+2)), columns = methods + ['loss', 'N'])\n",
    "df.index = methods\n",
    "\n",
    "# Calculate 'wins'\n",
    "performances = list(zip(methods, [symb_default_performances, old_default_performances, new_default_performances]))\n",
    "for (method, performance) in performances:\n",
    "    for (method2, performance2) in performances:\n",
    "        one_over_two = (performance.avg - performance2.avg) > 0\n",
    "        df.loc[method][method2] = sum(one_over_two)\n",
    "\n",
    "# Calculate loss        \n",
    "for (method, performance) in performances:\n",
    "    loss_sum = 0\n",
    "    for i, row in performance.iterrows():\n",
    "        best_score = svc_results[svc_results.task_id == row.name].predictive_accuracy.max()\n",
    "        loss = best_score - row.avg\n",
    "        if loss < 0:\n",
    "            print('{} outperformed best on task {} by {}'.format(method, row.name, loss))\n",
    "        loss_sum += loss\n",
    "    df.loc[method]['loss'] = loss_sum\n",
    "    df.loc[method]['N'] = len(performance)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads as *Symbolic* won over the *0.20* default 67 times, while the *0.20* default was better than *Symbolic* on 19 tasks. *Symbolic* obtained a loss of 1.74 over the best known result of each task (or slightly under 0.02 accuracy, on average).\n",
    "\n",
    "We see that *Symbolic* (i.e. `C=128, gamma=mkd/4`) as default outperforms either of the two scikit-learn ones, both in terms of tasks where it achieves higher predictive accuracy, and the loss in accuracy it occurs across tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b SVC Poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The grid search result from Jan.\n",
    "svc_results = load_random_search_results('svc_poly')\n",
    "\n",
    "# results currently still stored in log. should be aggregated to single file..\n",
    "# \"data/results/pipeline_c128mkd4.txt\"\n",
    "symb_default_performances = get_performance_from_csv(\"data/results/ppp_svc_poly_D1_C6_G7.txt\")\n",
    "old_default_performances = get_performance_from_csv(\"data/results/ppp_svc_poly_default.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b.2 Comparing Results\n",
    "We compare results by number of times one's average cross-validation performance is better (first three columns) and by their loss as compared to the best found result in the original set of experiments ('loss' column).\n",
    "\n",
    "**note:** The 'loss' column is calculated over all executed tasks with the default, because of work-in-progress/earlier cut-off with time constaints, currently the amount of tasks evaluated per method differs, so you find the amount of tasks for which the defaults have been evaluated in the 'N' column. The total loss is *not* normalized for the amount of completed tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20 outperformed best on task 9971 by -8.721690845203689e-06\n",
      "0.20 outperformed best on task 9971 by -8.721690845203689e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbolic</th>\n",
       "      <th>0.20</th>\n",
       "      <th>loss</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Symbolic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.004243</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.887059</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Symbolic  0.20       loss     N\n",
       "Symbolic       0.0  12.0  12.004243  92.0\n",
       "0.20          77.0   0.0   3.887059  91.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "methods = ['Symbolic', '0.20']\n",
    "df = pd.DataFrame(np.zeros(shape=(len(methods), len(methods)+2)), columns = methods + ['loss', 'N'])\n",
    "df.index = methods\n",
    "\n",
    "# Calculate 'wins'\n",
    "performances = list(zip(methods, [symb_default_performances, old_default_performances]))\n",
    "for (method, performance) in performances:\n",
    "    for (method2, performance2) in performances:\n",
    "        one_over_two = (performance.avg - performance2.avg) > 0\n",
    "        df.loc[method][method2] = sum(one_over_two)\n",
    "\n",
    "# Calculate loss        \n",
    "for (method, performance) in performances:\n",
    "    loss_sum = 0\n",
    "    for i, row in performance.iterrows():\n",
    "        best_score = svc_results[svc_results.task_id == row.name].predictive_accuracy.max()\n",
    "        loss = best_score - row.avg\n",
    "        if loss < 0:\n",
    "            print('{} outperformed best on task {} by {}'.format(method, row.name, loss))\n",
    "        loss_sum += loss\n",
    "    df.loc[method]['loss'] = loss_sum\n",
    "    df.loc[method]['N'] = len(performance)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the evolutionary optimization, we found that often recommended symbolic defaults:\n",
    " - **learning rate**: 0.75..1.0\n",
    " - **n_estimators**: n\n",
    " - **max_depth**: p\n",
    " \n",
    "However, as also noted due to the values of hyperparameters in the original experiments, it might as well read `n_estimators=500` and `max_depth=10`, the bounds of the original experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not aware of any proposed changes to default values for this algorithm, so the only comparison is to scikit-learn defaults as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The grid search result from Jan.\n",
    "adaboost_results = load_random_search_results('adaboost')\n",
    "\n",
    "# results currently still stored in log. should be aggregated to single file..\n",
    "# \"data/results/pipeline_c128mkd4.txt\"\n",
    "symb_default_performances = get_performance_from_console_output(\"data/results/pipeline_ada_75_500_10.txt\")\n",
    "sklearn_default_performances = get_performance_from_console_output(\"data/results/pipeline_ada_default.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comparing Results\n",
    "We compare results by number of times one's average cross-validation performance is better (first three columns) and by their loss as compared to the best found result in the original set of experiments (last column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic outperformed best on task 53 by -0.0035971316526609565\n",
      "Symbolic outperformed best on task 20 by -0.0015000000000000568\n",
      "Symbolic outperformed best on task 16 by -0.0030000000000001137\n",
      "Symbolic outperformed best on task 14 by -0.0045000000000000595\n",
      "sklearn outperformed best on task 10101 by -0.0013314594594595608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbolic</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>loss</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Symbolic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.900419</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.729290</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Symbolic  sklearn       loss     N\n",
       "Symbolic       0.0     43.0   1.900419  59.0\n",
       "sklearn       14.0      0.0  19.729290  93.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "methods = ['Symbolic', 'sklearn']\n",
    "df = pd.DataFrame(np.zeros(shape=(len(methods), len(methods)+2)), columns = methods + ['loss', 'N'])\n",
    "df.index = methods\n",
    "\n",
    "# Calculate 'wins'\n",
    "performances = list(zip(methods, [symb_default_performances, sklearn_default_performances]))\n",
    "for (method, performance) in performances:\n",
    "    for (method2, performance2) in performances:\n",
    "        one_over_two = (performance.avg - performance2.avg) > 0\n",
    "        df.loc[method][method2] = sum(one_over_two)\n",
    "\n",
    "# Calculate loss        \n",
    "for (method, performance) in performances:\n",
    "    loss_sum = 0\n",
    "    for i, row in performance.iterrows():\n",
    "        best_score = adaboost_results[adaboost_results.task_id == row.name].predictive_accuracy.max()\n",
    "        loss = best_score - row.avg\n",
    "        if loss < 0:\n",
    "            print('{} outperformed best on task {} by {}'.format(method, row.name, loss))\n",
    "        loss_sum += loss\n",
    "    df.loc[method]['loss'] = loss_sum\n",
    "    df.loc[method]['N'] = len(performance)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Symbolic defaults take far longer to train, and I could not reasonably evaluate all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Loading Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The grid search result from Jan.\n",
    "rfc_results = load_random_search_results('randomforest')\n",
    "\n",
    "# results currently still stored in log. should be aggregated to single file..\n",
    "# \"data/results/pipeline_c128mkd4.txt\"\n",
    "symb_default_performances = get_performance_from_csv(\"data/results/ppp_rf_p027.txt\")\n",
    "sklearn_default_performances = get_performance_from_csv(\"data/results/ppp_rfc_default.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Comparing Results\n",
    "We compare results by number of times one's average cross-validation performance is better (first three columns) and by their loss as compared to the best found result in the original set of experiments (last column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic 3543 0.0020000000000000018 0.988 0.986\n",
      "Symbolic 3567 0.0 1.0 1.0\n",
      "Symbolic 125920 0.04999999999999993 0.642 0.5920000000000001\n",
      "Symbolic 125921 0.05800000000000005 0.756 0.698\n",
      "Symbolic 3913 0.024935933236574614 0.856322 0.8313860667634254\n",
      "Symbolic 9980 0.011111037037036975 0.924074 0.912962962962963\n",
      "Symbolic 14968 0.014814777777777732 0.837037 0.8222222222222223\n",
      "Symbolic 3494 0.00907259740259736 0.98917 0.9800974025974026\n",
      "Symbolic 3492 0.0 1.0 1.0\n",
      "Symbolic 9946 0.008748205513784302 0.968366 0.9596177944862156\n",
      "Symbolic 9950 0.017519055656382454 0.910683 0.8931639443436176\n",
      "Symbolic 9971 0.015237874926943284 0.737564 0.7223261250730567\n",
      "Symbolic outperformed best on task 3512 by -0.0033336666666667902\n",
      "Symbolic 3512 -0.0033336666666667902 0.988333 0.9916666666666668\n",
      "Symbolic 3493 0.11316939890710387 1.0 0.8868306010928961\n",
      "Symbolic 11 0.03533681515616982 0.8976 0.8622631848438301\n",
      "Symbolic 3561 0.023851473222124664 0.693452 0.6696005267778753\n",
      "Symbolic 41 0.016025015345268567 0.947291 0.9312659846547314\n",
      "Symbolic 29 0.005796681159420336 0.881159 0.8753623188405797\n",
      "Symbolic 125923 0.0028989565217391045 0.876812 0.8739130434782609\n",
      "Symbolic 15 0.004292836438923198 0.97568 0.9713871635610768\n",
      "Symbolic 2079 0.008306328396890161 0.694293 0.6859866716031099\n",
      "Symbolic 10101 0.05213601801801793 0.794118 0.7419819819819821\n",
      "Symbolic 37 0.027411758031442357 0.783854 0.7564422419685577\n",
      "Symbolic 3560 0.030038215189873457 0.229611 0.19957278481012655\n",
      "Symbolic 3549 0.007125179271708415 0.991677 0.9845518207282916\n",
      "Symbolic 53 0.014226198879551899 0.761229 0.7470028011204481\n",
      "Symbolic outperformed best on task 49 by -6.701754385995962e-06\n",
      "Symbolic 49 -6.701754385995962e-06 0.991649 0.991655701754386\n",
      "Symbolic 3022 0.004039929292929401 0.974747 0.9707070707070706\n",
      "Symbolic 31 0.025000000000000133 0.775 0.7499999999999999\n",
      "Symbolic 9957 0.006602463611859788 0.873934 0.8673315363881402\n",
      "Symbolic 34538 0.0 1.0 1.0\n",
      "Symbolic 9981 0.013888407407407377 0.906481 0.8925925925925926\n",
      "Symbolic 3918 0.005425574938574873 0.940487 0.9350614250614251\n",
      "Symbolic 9970 0.03637835957187385 0.622112 0.5857336404281261\n",
      "Symbolic 10093 0.0007215480799745988 0.994898 0.9941764519200254\n",
      "Symbolic 3902 0.004089087387812995 0.912894 0.908804912612187\n",
      "Symbolic 23 0.05769835171906612 0.570265 0.5125666482809339\n",
      "Symbolic outperformed best on task 3903 by -0.0006276580107790197\n",
      "Symbolic 3903 -0.0006276580107790197 0.90595 0.906577658010779\n",
      "Symbolic 9964 0.0012163647798741906 0.932203 0.9309866352201258\n",
      "Symbolic 9956 0.008738408805031406 0.836773 0.8280345911949686\n",
      "Symbolic 9954 0.008125000000000049 0.849375 0.8412499999999999\n",
      "Symbolic outperformed best on task 9955 by -0.005624999999999991\n",
      "Symbolic 9955 -0.005624999999999991 0.641875 0.6475\n",
      "Symbolic 21 0.009255049469014565 0.979167 0.9699119505309854\n",
      "Symbolic 9967 0.001546391752577203 1.0 0.9984536082474228\n",
      "Symbolic outperformed best on task 22 by -0.0024999999999999467\n",
      "Symbolic 22 -0.0024999999999999467 0.7805 0.7829999999999999\n",
      "Symbolic 20 0.007000000000000006 0.975 0.968\n",
      "Symbolic 18 0.02000000000000013 0.723 0.7029999999999998\n",
      "Symbolic 16 0.008000000000000118 0.964 0.9559999999999998\n",
      "Symbolic 14 0.013999999999999901 0.853 0.8390000000000001\n",
      "Symbolic 12 0.006000000000000005 0.9695 0.9635\n",
      "Symbolic 3917 0.009954617693522905 0.870081 0.8601263823064771\n",
      "Symbolic 9979 0.0 1.0 1.0\n",
      "Symbolic 36 0.00043291774891762724 0.982684 0.9822510822510824\n",
      "Symbolic 3485 0.021185767634854802 0.98172 0.9605342323651452\n",
      "Symbolic 9978 0.00434410970713639 0.947119 0.9427748902928637\n",
      "Symbolic 9976 0.03307715384615373 0.869231 0.8361538461538462\n",
      "Symbolic 45 0.003761830721003223 0.962696 0.9589341692789968\n",
      "Symbolic 3 0.0018802962382444832 0.996558 0.9946777037617556\n",
      "Symbolic 3891 0.01817585309256875 0.949827 0.9316511469074312\n",
      "Symbolic 14966 0.0053333120567375936 0.812317 0.8069836879432624\n",
      "Symbolic 3896 0.007456821912549372 0.855546 0.8480891780874507\n",
      "Symbolic 43 0.006732023672545551 0.956749 0.9500169763274544\n",
      "Symbolic 9914 0.00971415403042275 0.985328 0.9756138459695772\n",
      "Symbolic 58 0.006199999999999983 0.8562 0.85\n",
      "Symbolic 9952 0.004065617238310448 0.913953 0.9098873827616896\n",
      "Symbolic 9960 0.001463612561750205 0.997067 0.9956033874382498\n",
      "Symbolic 125922 0.003272363636363518 0.981636 0.9783636363636364\n",
      "Symbolic 28 0.0012452740213522162 0.982562 0.9813167259786478\n",
      "Symbolic 9985 0.0026172670218115313 0.634031 0.6314137329781885\n",
      "Symbolic 2074 0.0023329175738724395 0.921462 0.9191290824261276\n",
      "Symbolic 24 0.0 1.0 1.0\n",
      "Symbolic outperformed best on task 146607 by -0.0003569377764091053\n",
      "Symbolic 146607 -0.0003569377764091053 0.866317 0.8666739377764091\n",
      "Symbolic 14969 0.03200569192621494 0.705561 0.673555308073785\n",
      "Symbolic 3510 0.0021085361264515656 0.980223 0.9781144638735484\n",
      "Symbolic 14964 0.001860998978400752 0.948718 0.9468570010215992\n",
      "Symbolic 3904 0.002941179171392916 0.8226 0.8196588208286071\n",
      "Symbolic outperformed best on task 32 by -0.0003646314004468465\n",
      "Symbolic 32 -0.0003646314004468465 0.991539 0.9919036314004468\n",
      "Symbolic 34537 0.000632720316169233 0.973496 0.9728632796838308\n",
      "Symbolic 9986 0.000862820992092117 0.994824 0.9939611790079079\n",
      "Symbolic 3889 0.00041647131495647916 0.99472 0.9943035286850436\n",
      "Symbolic 9983 0.009879651535380396 0.943391 0.9335113484646196\n",
      "Symbolic 3899 0.0025739788906959937 0.955291 0.952717021109304\n",
      "Symbolic 3954 0.0013674447949525437 0.88244 0.8810725552050475\n",
      "Symbolic outperformed best on task 6 by -0.0010999999999999899\n",
      "Symbolic 6 -0.0010999999999999899 0.9647 0.9658\n",
      "Symbolic 9977 0.0009861379281084215 0.969766 0.9687798620718916\n",
      "Symbolic 14965 0.0007299204073065724 0.907235 0.9065050795926934\n",
      "Symbolic 219 0.025886599485197892 0.936683 0.9107964005148022\n",
      "Symbolic 9968 0.0 1.0 1.0\n",
      "Symbolic 7592 0.010278087996901553 0.866447 0.8561689120030984\n",
      "Symbolic 3573 0.003813999999999984 0.972914 0.9691\n",
      "Symbolic 146606 0.003630971953085149 0.723376 0.7197450280469149\n",
      "sklearn 3543 0.0039999999999998925 0.988 0.9840000000000001\n",
      "sklearn 3567 0.0 1.0 1.0\n",
      "sklearn 125920 0.04200000000000004 0.642 0.6\n",
      "sklearn 125921 0.050000000000000155 0.756 0.7059999999999998\n",
      "sklearn 3913 0.01724362554426717 0.856322 0.8390783744557329\n",
      "sklearn 9980 0.011111037037036975 0.924074 0.912962962962963\n",
      "sklearn outperformed best on task 14968 by -3.703703699287075e-08\n",
      "sklearn 14968 -3.703703699287075e-08 0.837037 0.837037037037037\n",
      "sklearn 3494 0.00907259740259736 0.98917 0.9800974025974026\n",
      "sklearn 3492 0.0 1.0 1.0\n",
      "sklearn outperformed best on task 9946 by -2.372431077724002e-05\n",
      "sklearn 9946 -2.372431077724002e-05 0.968366 0.9683897243107772\n",
      "sklearn 9950 0.035062915305505093 0.910683 0.8756200846944949\n",
      "sklearn 9971 0.03417416949152541 0.737564 0.7033898305084746\n",
      "sklearn 3512 0.0016663333333334363 0.988333 0.9866666666666666\n",
      "sklearn 3493 0.11155737704918034 1.0 0.8884426229508197\n",
      "sklearn 11 0.06406185355862781 0.8976 0.8335381464413721\n",
      "sklearn 3561 0.0149840456540824 0.693452 0.6784679543459176\n",
      "sklearn 41 0.011634563512361584 0.947291 0.9356564364876384\n",
      "sklearn 29 0.010144507246376833 0.881159 0.8710144927536232\n",
      "sklearn 125923 4.057971013660122e-07 0.876812 0.8768115942028987\n",
      "sklearn 15 0.0071499792960662 0.97568 0.9685300207039338\n",
      "sklearn 2079 0.02176430692336173 0.694293 0.6725286930766383\n",
      "sklearn 10101 0.053469351351351335 0.794118 0.7406486486486487\n",
      "sklearn 37 0.019568285714285705 0.783854 0.7642857142857143\n",
      "sklearn 3560 0.033804037974683565 0.229611 0.19580696202531644\n",
      "sklearn outperformed best on task 3549 by -1.7677871148369384e-05\n",
      "sklearn 3549 -1.7677871148369384e-05 0.991677 0.9916946778711484\n",
      "sklearn 53 0.012993705882352935 0.761229 0.7482352941176471\n",
      "sklearn 49 0.002076631578947219 0.991649 0.9895723684210528\n",
      "sklearn 3022 0.003029828282828384 0.974747 0.9717171717171716\n",
      "sklearn 31 0.019000000000000128 0.775 0.7559999999999999\n",
      "sklearn 9957 0.013233191374663056 0.873934 0.8607008086253369\n",
      "sklearn 34538 0.0 1.0 1.0\n",
      "sklearn outperformed best on task 9981 by -0.020370851851852056\n",
      "sklearn 9981 -0.020370851851852056 0.906481 0.926851851851852\n",
      "sklearn 3918 0.003615583128583122 0.940487 0.9368714168714168\n",
      "sklearn 9970 0.03379740848123558 0.622112 0.5883145915187644\n",
      "sklearn 10093 0.0021866914207130383 0.994898 0.9927113085792869\n",
      "sklearn 3902 0.008198676428908813 0.912894 0.9046953235710912\n",
      "sklearn 23 0.050909419930134314 0.570265 0.5193555800698657\n",
      "sklearn outperformed best on task 3903 by -0.0006358239425119372\n",
      "sklearn 3903 -0.0006358239425119372 0.90595 0.906585823942512\n",
      "sklearn outperformed best on task 9964 by -0.005033635220125787\n",
      "sklearn 9964 -0.005033635220125787 0.932203 0.9372366352201258\n",
      "sklearn 9956 0.0031094779874214495 0.836773 0.8336635220125785\n",
      "sklearn outperformed best on task 9954 by -0.0006249999999999867\n",
      "sklearn 9954 -0.0006249999999999867 0.849375 0.85\n",
      "sklearn outperformed best on task 9955 by -0.0068749999999999645\n",
      "sklearn 9955 -0.0068749999999999645 0.641875 0.6487499999999999\n",
      "sklearn 21 0.013304652910337222 0.979167 0.9658623470896628\n",
      "sklearn 9967 0.006182923605604018 1.0 0.993817076394396\n",
      "sklearn 22 0.000500000000000056 0.7805 0.7799999999999999\n",
      "sklearn 20 0.0020000000000000018 0.975 0.973\n",
      "sklearn 18 0.01749999999999996 0.723 0.7055\n",
      "sklearn 16 0.004999999999999893 0.964 0.9590000000000001\n",
      "sklearn 14 0.017000000000000015 0.853 0.836\n",
      "sklearn 12 0.0024999999999999467 0.9695 0.9670000000000001\n",
      "sklearn 3917 0.006158634845407351 0.870081 0.8639223651545926\n",
      "sklearn 9979 0.0 1.0 1.0\n",
      "sklearn 36 0.0021645194805194334 0.982684 0.9805194805194806\n",
      "sklearn 3485 0.046529820193637605 0.98172 0.9351901798063624\n",
      "sklearn 9978 0.003156782826553628 0.947119 0.9439622171734464\n",
      "sklearn 9976 0.1707694615384615 0.869231 0.6984615384615385\n",
      "sklearn outperformed best on task 45 by -0.001567322884012401\n",
      "sklearn 45 -0.001567322884012401 0.962696 0.9642633228840124\n",
      "sklearn 3 0.005011173981191219 0.996558 0.9915468260188088\n",
      "sklearn 3891 0.011829132231680362 0.949827 0.9379978677683196\n",
      "sklearn 14966 0.0093326028368792 0.812317 0.8029843971631208\n",
      "sklearn 3896 0.01227802426196778 0.855546 0.8432679757380322\n",
      "sklearn 43 0.004123799585022847 0.956749 0.9526252004149771\n",
      "sklearn 9914 0.0028925500744315658 0.985328 0.9824354499255684\n",
      "sklearn 58 0.0028000000000000247 0.8562 0.8533999999999999\n",
      "sklearn 9952 0.003692850756486621 0.913953 0.9102601492435134\n",
      "sklearn 9960 0.0023810437544108387 0.997067 0.9946859562455892\n",
      "sklearn 125922 0.003090545454545568 0.981636 0.9785454545454544\n",
      "sklearn 28 0.0008894021352314763 0.982562 0.9816725978647686\n",
      "sklearn 9985 0.003759185873367432 0.634031 0.6302718141266326\n",
      "sklearn 2074 0.004043648522550569 0.921462 0.9174183514774494\n",
      "sklearn 24 0.0 1.0 1.0\n",
      "sklearn 146607 0.00919174016475488 0.866317 0.8571252598352451\n",
      "sklearn 14969 0.03231138660480981 0.705561 0.6732496133951902\n",
      "sklearn 3510 0.002610846269732847 0.980223 0.9776121537302671\n",
      "sklearn 14964 0.002448370631609187 0.948718 0.9462696293683908\n",
      "sklearn 3904 0.003216492464754528 0.8226 0.8193835075352455\n",
      "sklearn outperformed best on task 32 by -0.0005465323020928947\n",
      "sklearn 32 -0.0005465323020928947 0.991539 0.9920855323020928\n",
      "sklearn 34537 0.00018080439887724342 0.973496 0.9733151956011228\n",
      "sklearn 9986 0.0003595859094176479 0.994824 0.9944644140905824\n",
      "sklearn 3889 0.0027089101227704138 0.99472 0.9920110898772296\n",
      "sklearn 9983 0.009879651535380396 0.943391 0.9335113484646196\n",
      "sklearn 3899 0.0016091003695474226 0.955291 0.9536818996304526\n",
      "sklearn 3954 0.001051987381703423 0.88244 0.8813880126182966\n",
      "sklearn outperformed best on task 6 by -0.0010000000000000009\n",
      "sklearn 6 -0.0010000000000000009 0.9647 0.9657\n",
      "sklearn 9977 0.0012182490558884096 0.969766 0.9685477509441116\n",
      "sklearn 14965 0.0021233733984635794 0.907235 0.9051116266015364\n",
      "sklearn 219 0.025224630345664245 0.936683 0.9114583696543358\n",
      "sklearn 9968 0.0 1.0 1.0\n",
      "sklearn 7592 0.012919327915521306 0.866447 0.8535276720844787\n",
      "sklearn 3573 0.0032282857142855725 0.972914 0.9696857142857144\n",
      "sklearn 146606 0.005956316165221742 0.723376 0.7174196838347783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbolic</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>loss</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Symbolic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.019086</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.143054</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Symbolic  sklearn      loss     N\n",
       "Symbolic       0.0     39.0  1.019086  95.0\n",
       "sklearn       47.0      0.0  1.143054  95.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "methods = ['Symbolic', 'sklearn']\n",
    "df = pd.DataFrame(np.zeros(shape=(len(methods), len(methods)+2)), columns = methods + ['loss', 'N'])\n",
    "df.index = methods\n",
    "\n",
    "# Calculate 'wins'\n",
    "performances = list(zip(methods, [symb_default_performances, sklearn_default_performances]))\n",
    "for (method, performance) in performances:\n",
    "    for (method2, performance2) in performances:\n",
    "        one_over_two = (performance.avg - performance2.avg) > 0\n",
    "        df.loc[method][method2] = sum(one_over_two)\n",
    "\n",
    "# Calculate loss        \n",
    "for (method, performance) in performances:\n",
    "    loss_sum = 0\n",
    "    for i, row in performance.iterrows():\n",
    "        best_score = rfc_results[rfc_results.task_id == row.name].predictive_accuracy.max()\n",
    "        if np.isnan(best_score):\n",
    "            continue\n",
    "        loss = best_score - row.avg\n",
    "        if loss < 0:\n",
    "            print('{} outperformed best on task {} by {}'.format(method, row.name, loss))\n",
    "        print(method, row.name, loss, best_score, row.avg)\n",
    "        loss_sum += loss\n",
    "    df.loc[method]['loss'] = loss_sum\n",
    "    df.loc[method]['N'] = len(performance)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The default of `max_features=0.271` did outperform the default of `sqrt(p)` in terms of loss. However, it is not a clear better default. The default of `sqrt(p)` is still better more often and scales much better with the amount of features in a dataset in terms of runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**note**: Everything below is scratchpad and should be ignored\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
