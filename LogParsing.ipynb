{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Trace:\n",
    "\n",
    "    def __init__(self, filename: str, benchmarks=None):\n",
    "        self.baseline = set(benchmarks) if benchmarks else set()\n",
    "        self.scores, self.expressions, generations_by_task = parse_log(filename, baseline=self.baseline)\n",
    "        self.comparison, self.d_scores = comparisons(self.scores)\n",
    "        self.in_comparison, self.in_d_scores = comparisons(self.scores, sample=\"in-sample\")\n",
    "        self.generations_by_task = pd.Series(generations_by_task, name=\"generations\")\n",
    "\n",
    "    @property\n",
    "    def most_frequent_solutions_by_length(self):\n",
    "        for length, expressions in sorted(self.expressions.items()):\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            yield m, expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "\n",
    "\n",
    "def parse_log(file, with_prefix=False, baseline=None):\n",
    "    with open(file) as fh:\n",
    "        lines = fh.readlines()\n",
    "\n",
    "    p = 'INFO:root:' if with_prefix else ''\n",
    "\n",
    "    definitions = [line for line in lines if ':=' in line]\n",
    "    baseline = baseline if baseline else set()\n",
    "\n",
    "    print(\"The predefined defaults are:\")\n",
    "    for line in definitions:\n",
    "        if ':=' in line:\n",
    "            print(f\" * {line[len(p):-1]}\")\n",
    "            baseline.add(line[len(p):].split(' :=')[0])\n",
    "\n",
    "    task_starts = [i for i, line in enumerate(lines) if \"START_TASK:\" in line]\n",
    "    in_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating in sample:\" in line]\n",
    "    out_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating out-of-sample:\" in line]\n",
    "\n",
    "    def parse_evaluation_line(line) -> Tuple[str, int, float]:\n",
    "        \"\"\" Parse an evaluation line, returning the expression or name, its 'length' and the score.\n",
    "\n",
    "        e.g. INFO:root:[make_tuple(p, mkd)|0.8893]\\n -> 'make_tuple(p, mkd)', 1, 0.8893\n",
    "        Length is 0 for benchmark problems.\n",
    "        \"\"\"\n",
    "        start, pipe, end = line.find('['), line.find('|'), line.find(']')\n",
    "        expression = line[start + 1: pipe]\n",
    "        if ':' in expression:  # For the baseline expressions, record them by name\n",
    "            expression = expression[:expression.find(':')]\n",
    "        expression_length = expression.count('(')\n",
    "        return expression, expression_length, float(line[pipe + 1: end])\n",
    "\n",
    "    tasks = [int(line[:-1].split(\": \")[-1]) for line in lines if \"START_TASK:\" in line]\n",
    "    idx = pd.MultiIndex.from_product([tasks, [\"in-sample\", \"out-sample\"]], names=['task', 'sample-type'])\n",
    "    df = pd.DataFrame(index=idx, columns=[\"length-1\", \"length-2\", \"length-3\", \"final\", *baseline], dtype=float)\n",
    "\n",
    "    expressions_by_length = defaultdict(list)\n",
    "    generations_by_task = {}\n",
    "\n",
    "    for task_start, in_start, out_start, next_task in zip(task_starts, in_sample_starts,\n",
    "                                                          out_sample_starts,\n",
    "                                                          task_starts[1:] + [-len(baseline)*2]):\n",
    "        # start line looks like: INFO:root:START_TASK: 29\\n\n",
    "        task = int(lines[task_start][:-1].split(\": \")[-1])\n",
    "\n",
    "        # Since the in-sample evaluation message follows directly after optimization is done, we use that to record\n",
    "        # the number of generations. We account for the early stopping message if it did not run to 200 generations.\n",
    "        ended_early = 0 if in_start - task_start == 201 else - 1\n",
    "        generations_by_task[task] = in_start - (task_start + 1) - ended_early\n",
    "\n",
    "        # Following the \"INFO:root:Evaluating in sample:\" message, symbolic default performance are printed\n",
    "        # They are formatted as \"INFO:root:[make_tuple(p, mkd)|0.8893]\"\n",
    "        # First is any number of best solutions from the pareto front. The last four are benchmark solutions.\n",
    "        # It is possible that two equally good solutions are printed (i.e. same length and performance).\n",
    "        expr_in_task = set()\n",
    "        max_length = 0\n",
    "\n",
    "        for in_sample_evaluation in lines[in_start + 1: out_start]:\n",
    "            expr, length, score = parse_evaluation_line(in_sample_evaluation)\n",
    "            # Pareto fronts may contain literal duplicates, so we filter those out manually.\n",
    "            # We also do not want to include the baseline solutions (they have ':' in their line)\n",
    "            if expr not in expr_in_task: # and ':' not in expr:\n",
    "                expressions_by_length[length].append(expr)\n",
    "                expr_in_task.add(expr)\n",
    "\n",
    "            if length != 0:\n",
    "                if length < 4:\n",
    "                    # Only report one out-of-sample solution for each length (and all benchmarks), so overwrite is OK.\n",
    "                    df.loc[task, \"in-sample\"][f\"length-{length}\"] = score\n",
    "\n",
    "                # Update best so far score and maximum length\n",
    "                df.loc[task, \"in-sample\"][f\"final\"] = np.nanmax(\n",
    "                    [score, df.loc[task, \"in-sample\"][f\"final\"]])\n",
    "                max_length = max(max_length, length)\n",
    "            else:\n",
    "                df.loc[task, \"in-sample\"][expr] = score\n",
    "\n",
    "            if length > max_length:\n",
    "                max_length = length  # To know for which length \"best\" should score out of sample\n",
    "\n",
    "        # Because two equal solutions can be in the Pareto front,\n",
    "        # we note the average out of sample performance if multiple solutions were found.\n",
    "        # Naturally, the solutions with the best in-sample score were those with the highest length in the Pareto front.\n",
    "\n",
    "        scores_by_length = defaultdict(list)\n",
    "\n",
    "        for out_sample_evaluation in lines[out_start + 1: next_task]:\n",
    "            expr, length, score = parse_evaluation_line(out_sample_evaluation)\n",
    "            if length != 0:\n",
    "                scores_by_length[length].append(score)\n",
    "            else:\n",
    "                df.loc[task, \"out-sample\"][expr] = score\n",
    "\n",
    "        for length, scores in scores_by_length.items():\n",
    "            if length < 4:\n",
    "                df.loc[task, \"out-sample\"][f\"length-{length}\"] = np.mean(scores)\n",
    "            if length == max_length:\n",
    "                df.loc[task, \"out-sample\"][f\"final\"] = np.mean(scores)\n",
    "            if np.mean(scores) == float(\"nan\"):\n",
    "                print('hi')\n",
    "\n",
    "    return df, expressions_by_length, generations_by_task\n",
    "\n",
    "\n",
    "def comparisons(df, sample=\"out-sample\"):\n",
    "    out_sample = df.index.map(lambda idx: idx[1] == sample)\n",
    "\n",
    "    alone = {k: 0 for k in df.iloc[0].index.values}\n",
    "    shared = {k: 0 for k in df.iloc[0].index.values}\n",
    "\n",
    "    for _, out in df.loc[out_sample].iterrows():\n",
    "        best = out[out == out.max()].index.values\n",
    "        if len(best) == 1:\n",
    "            alone[best[0]] += 1\n",
    "        else:\n",
    "            for winner in best:\n",
    "                shared[winner] += 1\n",
    "\n",
    "    alone = {k: alone[k] for k in sorted(alone)}\n",
    "    shared = {k: shared[k] for k in sorted(shared)}\n",
    "    either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "    comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "\n",
    "    df_out = df.loc[out_sample].copy()\n",
    "    df_out['max'] = df_out.max(axis=1)\n",
    "    for col in df_out:\n",
    "        df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "    d_cols = [c for c in df_out.columns if c.startswith('d_')]\n",
    "    df_out[d_cols].mean()\n",
    "    df_out[d_cols].median()\n",
    "\n",
    "    in_sample = df.index.map(lambda idx: idx[1] == \"in-sample\")\n",
    "    df.loc[in_sample].idxmax(axis=1).value_counts()\n",
    "    df.loc[in_sample][reversed(df.columns)].idxmax(axis=1).value_counts()\n",
    "    return comparison, df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We have experiment data for a set of algorithms and meta-data for the datasets on which the experiments took place.\n",
    "We use symbolic regression to find an expression for symbolic default values that give good performance across tasks.\n",
    "Symbolic regression is performed with leave-one-task-out, which means for each algorithm we have multiple searches for a symbolic default, and their performance is recorded for both in-sample (the optimization surface of all-but-one tasks) and out-of-sample (the left out task) performance. Performance here is solely based on surrogate model predictions, no additional experiments have been performed (yet).\n",
    "\n",
    "In our search, we use NSGA-II selection to perform multi-objective optimization: find the expression with the best performance, while using the fewest number of operators (e.g. `divide`, `multiply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "**Length** of an expression denotes the number of operators in it. A symbolic value is *not* considered an operation.\n",
    "Consider the following SVM defaults for cost and gamma:\n",
    " - `make_tuple`(m, mkd) is length 1.\n",
    " - `make_tuple`(m, `truediv`(mkd, xvar)) is length 2.\n",
    " - `make_tuple`(16., `truediv`(mkd, xvar)) is length 2.\n",
    "\n",
    "The **final** solution refers to the symbolic default with the highest in-sample score for a task (regardless of its length). This means for each task there is *at least* one final solution, but there may be more and they are not of a specific length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline** solutions are typically the default hyperparameter settings of mlr, scikit-learn, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the logs, because some logs are incomplete we have to explicitly give the name of the baselines (this will be fixed for future runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predefined defaults are:\n",
      " * mlr_default := make_tuple(1., 0.01)\n",
      " * sklearn_default := make_tuple(1., 1.)\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      " * mlr_default := make_tuple(1., 16., 10., 200.)\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      " * mlr_default := make_tuple(0.01, 30., 1., 20.)\n",
      "The predefined defaults are:\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n",
      "The predefined defaults are:\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "baselines = dict(\n",
    "    glmnet=[\"mlr_default\", \"sklearn_default\"],\n",
    "    kerasff=[\"initial_values\"],\n",
    "    knn=[\"mlr_default\"],\n",
    "    rf=[\"mlr_default\"],\n",
    "    rpart=[\"mlr_default\"],\n",
    "    asvm=[\"sklearn_scale\", \"symbolic_best\", \"symbolic_v2\" , \"const\"],\n",
    ")\n",
    "traces = {}\n",
    "for file in os.listdir('runs'):\n",
    "    if file.endswith('.log'):\n",
    "        baseline = []\n",
    "        for method, bls in baselines.items():\n",
    "            if method in file:\n",
    "                baseline = bls\n",
    "        traces[file[:-4]] = Trace(os.path.join('runs', file), benchmarks=baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "As described before, for each problem we find a symbolic default leaving one task out.\n",
    "We are interested to see how fast the symbolic regression converges across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of generations across tasks by problem:\n",
      "svm_warm         46\n"
     ]
    }
   ],
   "source": [
    "print(\"Median number of generations across tasks by problem:\")\n",
    "for log, trace in traces.items():\n",
    "    print(f\"{log: <15} {trace.generations_by_task.median().astype(int):3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAKACAYAAADn488NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nOzdf7Tld13f+9dbBpCSINDAGALjYItULpFfI3rlghOpAokV/HlBwIi0gXWFwjV31ehdt3J1tTdaI/Zi722xoNAGovKjiYQqlDoB6o+a0ECCkUuAQQMhafiZQQpOeN8/9nfKyTBnZp/J2T8+Zx6PtWbN2fvss7/v73fP+QSffr97V3cHAAAAgHF9zaoHAAAAAOCuEXgAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQe1l5V/V9V9dJVz3FXVNXBqvq7W/yZf1hVFy9qJgAAAHYOgYe1VlUPSPJjSf7VdPseVfWGKZh0Ve0/6vFVVb9YVZ+c/vxSVdVRj3lJVX2kqj5fVTdU1Tdtsu2XVdW/XdCuzeOVSZ5TVQ9c4QwAAAAMQOBhYapq1zY8zY8neWt3f2HDfe9O8pwknzjG4y9I8owkj0ryLUm+N8kLNsz095M8P8l5SU6bvn/bNsy57br7vyX595kFLgAAANiUwLNGquqnq+pjVXV7VX2gqp5cVQ+qqi9U1f03PO4xVXVbVd29qn68qv5TVb28qj5TVR+uqu+Y7v/Lqrq1qs4/wXYfOv3s10y3/3VV3brh+//2yCVSVfW86ayX26dtbYwn+6vqpmk/PpHkN6azYH5neo7bq+q6qvqmqvqZaba/rKrvOc54T0ty1ZEb3f2l7v7V7n53kjuO8fjzk1zS3Td198eSXJJZJMq0fz+X5H/t7j/rmQ9196eOcUyemuRnk/zPVXWoqt47x/6fUVVvmY7lp6rqXUeO6VHP/XemM4ieOd3+qtd9w8MPZBajAAAAYFMCz5qoqocneVGSb+3u05M8JcnB7v54kj9K8oMbHv6jSd7Q3X893f62JO9L8jeTvC7JZUm+NcnfzuxMl1+rqtM223Z3fyTJ55I8ZrrriUkOVdU3T7eflK9EllszO+vlPkmel+TlVfXYDU/39Unun+QbMjubJkn+XpJ/k+R+Sf5Lkt/P7N/eWUl+PtPlV5s4O8kHjvP9o/0PSd674fZ7p/uS5MHTn0dOYekjVfV/HivCdPfvJfmnSX6ru0/r7kdN3zre/l+Y5KYkD0iyO7NA1Bufd3rs25K8uLsv2+x13/AjN2R2NhIAAABsSuBZH3ckuWeSR1TV3bv7YHd/aPre65I8K5m9x0ySZ073HfGR7v6N7r4jyW8leUiSn+/uL3b325J8KbPYczxXJfnOqvr66fYbptsPzSxmvDdJuvvK6ayX7u6rMosVT9zwPF9O8nPTto9cVvWu7v797j6c5HcyCyAXT4HqsiR7q+q+m8x13yS3n2D2jU5L8tkNtz+b5LTpuD14uu97MgtH52R2XJ8/75OfYP//OsmZSb6hu/+6u9/V3RsDzxOTXJHk/O5+y3Tf8V73ZLbvXzfvfAAAAJyaBJ410d03JnlpkpclubWqLquqB03ffkOS/3G6/aTMzgp514Yfv2XD11+Ynu/o+zY9g2dyVZL90/O/M7NLg75z+vOu7v5yklTV06rqj6dLkD6T5NwkZ2x4nv86vXfMRkfPctsUo/77vMeZ79NJTj/B7BsdyixIHXGfJIem0HJkW7/U3Z/p7oOZnT107rxPfoL9/2dJbkzytunyrYuO+vEXJvnD7v6DI3ec4HVPZvv+2QAAAMBxCDxrpLtf193/U2aXN3WSX5zu/0xmZ4r8SGaXZ73+qDNDtsNVmZ1hsn/6+t1JnpBZ4LkqSarqnknemOSXk+zu7vsmeWuSjZ9Std1zvS/JMT/lahPvz50vaXrUdF8yu9TrS5l/xqMvrzru/nf37d19YXd/Y2aXpf3UUe+n88Ike6rq5XfayCav++Sbc+dLzgAAAOCrCDxroqoeXlXfNUWE/5bZ2SYb30T4dZl9mtIP5s6XZ22L7v7gtM3nJHlnd38uszNvfjBfef+de2R2OdF/TXK4qp6W2eVOi/TWzCLTf1dV96yqrz0yU1V97XQJVpK8NrOwctZ0JsyFSX4zSbr7rzK7hO0fVdXpVfXgJP8gyVtybLdkdvnYkd+T4+5/VX1vVf3taZbPZfb6bXwNb0/y1CRPqqqLp5850ev+nZl9khYAAABsSuBZH/dMcnFmH9n9iSQPzOxNeo+4IsnDktzS3Ys6o+OqJJ/s7r/YcLsye2PkdPftSf5hkt/O7NKpH53mWqTXJjm3qu614b4PZBZCzsrsDZu/kNnZL8nskqvfTXJdkuuTXJk7v4nzizK7jOvIm1e/LsmrN9n270x/f7Kq3jPH/j8syX+Ynv+Pkvw/3X1g4xNOZ2N9d5KnVdUv5Div+xSxzk3yms0ODgAAACRJbf+VPrC9quqfJrm1u3911bMsU1W9OMlDuvsfrXoWAAAA1pvAAwAAADA4l2idQqrq/VV16Bh/nr3q2QAAAICT5wweAAAAgMHtWvUA8zjjjDN67969cz3285//fO5973svdqCTZLaTs66zretcydizXXPNNbd19wOWMctW1hZgbNYWYBGsLcAinOzaMkTg2bt3b66++uq5HnvgwIHs379/sQOdJLOdnHWdbV3nSsaerao+uqxZtrK2AGOztgCLYG0BFuFk1xbvwQMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADG5hgaeqHlJVf1BVN1TV+6vqJdP9L6uqj1XVtdOfcxc1AwAAAMCpYNcCn/twkgu7+z1VdXqSa6rq7dP3Xt7dv7zAbQMAAACcMhYWeLr75iQ3T1/fXlU3JDlrUdsDAAAAOFVVdy9+I1V7k7wzySOT/FSSH0/yuSRXZ3aWz6eP8TMXJLkgSXbv3v24yy67bK5t3fqpz+aWL8w/29lnfd38D76LDh06lNNOO21p29sKs23dus6VjD3bOeecc01371vU9jeuLXv27HncRz/60UVtClgjVWVtAbadtQVYhJNdWxYeeKrqtCRXJfkn3f2mqtqd5LYkneQXkpzZ3T9xvOfYt29fX3311XNt7xWXXp5Lrpv/xKSDF58392PvqgMHDmT//v1L295WmG3r1nWuZOzZFv0/lDbaytoCjM3aAiyCtQVYhJNdWxb6KVpVdfckb0xyaXe/KUm6+5buvqO7v5zk15M8fpEzAAAAAOx0i/wUrUryqiQ3dPevbLj/zA0P+/4k1y9qBgAAAIBTwSI/ResJSZ6b5Lqquna672eTPKuqHp3ZJVoHk7xggTMAAAAA7HiL/BStdyepY3zrrYvaJgAAAMCpaKHvwQMAAADA4gk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABjcwgJPVT2kqv6gqm6oqvdX1Uum++9fVW+vqg9Of99vUTMAAAAAnAoWeQbP4SQXdvc3J/n2JD9ZVY9IclGSd3T3w5K8Y7oNAAAAwElaWODp7pu7+z3T17cnuSHJWUmenuQ108Nek+QZi5oBAAAA4FSwaxkbqaq9SR6T5E+S7O7um5NZBKqqB27yMxckuSBJdu/enQMHDsy1rd33Si48+/Dcs837vNvh0KFDS93eVpht69Z1rsRsx7NxbdmzZ8/K5gB2FmsLsAjWFmArFh54quq0JG9M8tLu/lxVzfVz3f3KJK9Mkn379vX+/fvn+rlXXHp5Lrlu/t06+Oz5nnc7HDhwIPPux7KZbevWda7EbMdz9NqyskGAHcXaAiyCtQXYioV+ilZV3T2zuHNpd79puvuWqjpz+v6ZSW5d5AwAAAAAO90iP0WrkrwqyQ3d/SsbvnVFkvOnr89PcvmiZgAAAAA4FSzyEq0nJHlukuuq6trpvp9NcnGS366q5yf5iyQ/vMAZAAAAAHa8hQWe7n53ks3ecOfJi9ouAAAAwKlmoe/BAwAAAMDiCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADC4XaseYNX2XnTl3I89ePF5C5wEAAAA4OQ4gwcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGNzCAk9Vvbqqbq2q6zfc97Kq+lhVXTv9OXdR2wcAAAA4VSzyDJ7fTPLUY9z/8u5+9PTnrQvcPgAAAMApYWGBp7vfmeRTi3p+AAAAAGZ2rWCbL6qqH0tydZILu/vTx3pQVV2Q5IIk2b17dw4cODDXk+++V3Lh2Ye3adQ7m3eGzRw6dOguP8eimG3r1nWuxGzHs3Ft2bNnz8rmAHYWawuwCNYWYCuquxf35FV7k7ylux853d6d5LYkneQXkpzZ3T9xoufZt29fX3311XNt8xWXXp5LrltMtzp48Xl36ecPHDiQ/fv3b88w28xsW7eucyVjz1ZV13T3vmXMspW1BRibtQVYBGsLsAgnu7Ys9VO0uvuW7r6ju7+c5NeTPH6Z2wcAAADYiZYaeKrqzA03vz/J9Zs9FgAAAID5LOw9eKrq9Un2Jzmjqm5K8nNJ9lfVozO7ROtgkhcsavsAAAAAp4qFBZ7uftYx7n7VorYHAAAAcKpa6iVaAAAAAGw/gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGNyuVQ8wkr0XXbmlxx+8+LwFTQIAAADwFc7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGN1fgqap3zHMfAAAAAMu363jfrKqvTfI3kpxRVfdLUtO37pPkQQueDQAAAIA5HDfwJHlBkpdmFnOuyVcCz+eS/IsFzgUAAADAnI4beLr7nyf551X14u5+xZJmAgAAAGALTnQGT5Kku19RVd+RZO/Gn+nu1y5oLgAAAADmNFfgqap/k+RvJbk2yR3T3Z1E4AEAAABYsbkCT5J9SR7R3b3IYQAAAADYurk+Jj3J9Um+fpGDAAAAAHBy5j2D54wkf1ZV/znJF4/c2d3ft5CpAAAAAJjbvIHnZYscAgAAAICTN++naF216EEAAAAAODnzforW7Zl9alaS3CPJ3ZN8vrvvs6jBAAAAAJjPvGfwnL7xdlU9I8njFzIRAAAAAFsy76do3Ul3/7sk37XNswAAAABwEua9ROsHNtz8miT78pVLtgAAAABYoXk/Revvbfj6cJKDSZ6+7dMAAAAAsGXzvgfP8xY9CAAAAAAnZ6734KmqB1fVm6vq1qq6pareWFUPXvRwAAAAAJzYvG+y/BtJrkjyoCRnJfnd6T4AAAAAVmzewPOA7v6N7j48/fnNJA9Y4FwAAAAAzGnewHNbVT2nqu42/XlOkk8ucjAAAAAA5jNv4PmJJD+S5BNJbk7yQ0m88TIAAADAGpj3Y9J/Icn53f3pJKmq+yf55czCDwAAAAArNO8ZPN9yJO4kSXd/KsljFjMSAAAAAFsxb+D5mqq635Eb0xk88579AwAAAMACzRtpLknyh1X1hiSd2fvx/JOFTQUAAADA3OYKPN392qq6Osl3JakkP9Ddf7bQyQAAAACYy9yXWU1BR9QBAAAAWDPzvgcPAAAAAGtK4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxuYYGnql5dVbdW1fUb7rt/Vb29qj44/X2/RW0fAAAA4FSxyDN4fjPJU4+676Ik7+juhyV5x3QbAAAAgLtgYYGnu9+Z5FNH3f30JK+Zvn5NkmcsavsAAAAAp4rq7sU9edXeJG/p7kdOtz/T3ffd8P1Pd/cxL9OqqguSXJAku3fvftxll1021zZv/dRnc8sX7uLgC7L7Xtl0trPP+rrlDnOUQ4cO5bTTTlvpDJtZ19nWda5k7NnOOeeca7p736K2v3Ft2bNnz+M++tGPLmpTwBqpKmsLsO2sLcAinOzasmsRw2yH7n5lklcmyb59+3r//v1z/dwrLr08l1y3nrt14dmHN53t4LP3L3eYoxw4cCDzHuNlW9fZ1nWuxGzHc/TasrJBgB3F2gIsgrUF2Iplf4rWLVV1ZpJMf9+65O0DAAAA7DjLDjxXJDl/+vr8JJcvefsAAAAAO84iPyb99Un+KMnDq+qmqnp+kouTfHdVfTDJd0+3AQAAALgLFvZmNd39rE2+9eRFbRMAAADgVLTsS7QAAAAA2GYCDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwuF2rHoCZvRddubDnPnjxeQt7bgAAAGD1nMEDAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMHtWsVGq+pgktuT3JHkcHfvW8UcAAAAADvBSgLP5Jzuvm2F2wcAAADYEVyiBQAAADC4VZ3B00neVlWd5F919yuPfkBVXZDkgiTZvXt3Dhw4MNcT775XcuHZh7dx1O2zqtnmOXaHDh2a+xgv27rOtq5zJWY7no1ry549e1Y2B7CzWFuARbC2AFuxqsDzhO7+eFU9MMnbq+rPu/udGx8wRZ9XJsm+fft6//79cz3xKy69PJdct8orzzZ34dmHVzLbwWfvP+FjDhw4kHmP8bKt62zrOldituM5em1Z2SDAjmJtARbB2gJsxUou0eruj09/35rkzUkev4o5AAAAAHaCpQeeqrp3VZ1+5Osk35Pk+mXPAQAAALBTrOJapt1J3lxVR7b/uu7+vRXMAQAAALAjLD3wdPeHkzxq2dsFAAAA2Kl8TDoAAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4HategAWb+9FV57wMReefTg/Psfjjnbw4vNOZiQAAABgGzmDBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABrdr1QPAdth70ZULe+6DF5+3sOcGAACA7eAMHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGJzAAwAAADA4gQcAAABgcAIPAAAAwOAEHgAAAIDBCTwAAAAAgxN4AAAAAAYn8AAAAAAMTuABAAAAGNyuVQ/AqWXvRVfO/diDF5+3wEnWw1aOR7LYY+K1AQAAGJczeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHACDwAAAMDgBB4AAACAwQk8AAAAAIMTeAAAAAAGJ/AAAAAADE7gAQAAABicwAMAAAAwOIEHAAAAYHC7Vj0AMJ69F125pccfvPi8BU0CAABA4gweAAAAgOEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDE3gAAAAABifwAAAAAAxO4AEAAAAYnMADAAAAMALaSS4AAA1dSURBVDiBBwAAAGBwAg8AAADA4AQeAAAAgMEJPAAAAACDW0ngqaqnVtUHqurGqrpoFTMAAAAA7BRLDzxVdbck/yLJ05I8IsmzquoRy54DAAAAYKdYxRk8j09yY3d/uLu/lOSyJE9fwRwAAAAAO0J193I3WPVDSZ7a3X9/uv3cJN/W3S866nEXJLlguvnwJB+YcxNnJLltm8bdbmY7Oes627rOlYw92zd09wMWtfGj1pZHJrl+UdtaonV+vbdqp+yL/Vg/D+/u0xf15NaWtbdT9sV+rB9ry9btlNd/p+xHsnP2ZafsR3KSa8sqAs8PJ3nKUYHn8d394m16/qu7e992PNd2M9vJWdfZ1nWuxGzzWqdZ7oqdsh/JztkX+7F+lrkvO+W47ZT9SHbOvtiP9WNt2Tr7sX52yr7slP1ITn5fVnGJ1k1JHrLh9oOTfHwFcwAAAADsCKsIPH+a5GFV9dCqukeSZya5YgVzAAAAAOwIu5a9we4+XFUvSvL7Se6W5NXd/f5t3MQrt/G5tpvZTs66zraucyVmm9c6zXJX7JT9SHbOvtiP9bPMfdkpx22n7Eeyc/bFfqwfa8vW2Y/1s1P2ZafsR3KS+7L09+ABAAAAYHut4hItAAAAALaRwAMAAAAwuKEDT1U9pKr+oKpuqKr3V9VLpvtfVlUfq6prpz/nrmi+g1V13TTD1dN996+qt1fVB6e/77fkmR6+4bhcW1Wfq6qXruqYVdWrq+rWqrp+w32bHqOq+pmqurGqPlBVT1nBbP+sqv68qt5XVW+uqvtO9++tqi9sOH7/cgWzbfoaLuu4bTLXb22Y6WBVXTvdv5RjVlVPnfb7xqq66Bjfr6r6v6fvv6+qHruIObbDHPvy7Gkf3ldVf1hVj1rFnCdyov3Y8Lhvrao7quqHljnfVsyzL1W1f/o3/v6qumrZM85jjn9bX1dVv1tV753243mrmPNEjrUGHfX9bft9t7asH2vL+rG2nNS2rC1rZqesLTtlXUmsLcfV3cP+SXJmksdOX5+e5P9L8ogkL0vyv63BfAeTnHHUfb+U5KLp64uS/OIK57tbkk8k+YZVHbMkT0ry2CTXn+gYTa/te5PcM8lDk3woyd2WPNv3JNk1ff2LG2bbu/FxKzpux3wNl3ncjjXXUd+/JMk/XtYxm/6NfyjJNya5x3QcHnHUY85N8u+TVJJvT/Iny3odF7Av35HkftPXT1vHfZlnPzY87j8meWuSH1r13HfhNblvkj9Lsme6/cBVz32S+/GzG9a7ByT5VJJ7rHr2Y+zLidagbfl9t7as375YW6wtC94Xa8ti9sXaskb7McK6soV9OWXXlqHP4Onum7v7PdPXtye5IclZq53qhJ6e5DXT169J8owVzvLkJB/q7o+uaoDufmdmv3AbbXaMnp7ksu7+Ynd/JMmNSR6/zNm6+23dfXi6+cdJHryo7R/PJsdtM0s7bsebq6oqyY8kef0itr2Jxye5sbs/3N1fSnJZZsdjo6cneW3P/HGS+1bVmUuccV4n3Jfu/sPu/vR0c2X/Pk9gntckSV6c5I1Jbl3mcFs0z778aJI3dfdfJEl3r+P+zLMfneT06ff4tMx+zw9nzcyxNm7X77u1Zf1YW9aPtWXrrC3rZ6esLTtlXUmsLcf9fR868GxUVXuTPCbJn0x3vWg6jenVteTLoDboJG+rqmuq6oLpvt3dfXMyC1RJHrii2ZLkmbnz/7G9Dscs2fwYnZXkLzc87qasNuj9RGZF9YiHVtV/qaqrquqJK5rpWK/huhy3Jya5pbs/uOG+RR+zefZ9XY7PiWx1zufnzv8+18UJ96Oqzkry/UkWeqnjNpjnNfmmJPerqgPTfwt+bGnTzW+e/fi1JN+c5ONJrkvyku7+8nLG21bb9ftubVk/1pb1Y21ZzPNYW5Zrp6wtO2VdSawtx/193xGBp6pOy6yYvrS7P5fk/03yt5I8OsnNmV0WsgpP6O7HZnbK4U9W1ZNWNMdXqap7JPm+JL8z3bUux+x46hj39dKnSFJV/3tmFfjS6a6bMzud8TFJfirJ66rqPksea7PXcF2O27Ny56C4jGM2z76vy/E5kbnnrKpzMvsfSj+90IlOzjz78atJfrq771jCPHfFPPuyK8njkpyX5ClJ/o+q+qZFD7ZF8+zHU5Jcm+RBma0xv7aCNW47bNfvu7Vl/VhbrC2rZG35ataW9bJT1pXE2nLc3/ddCxpkaarq7pnFnUu7+01J0t23bPj+ryd5yypm6+6PT3/fWlVvzux0sluq6szuvnk6vWpVp749Lcl7jhyrdTlmk82O0U1JHrLhcQ/OrMouVVWdn+R7kzy5p4sju/uLSb44fX1NVX0oswp+9bLmOs5ruPLjVlW7kvxAZv/RSLK0YzbPvq/8+Mxprjmr6luS/OskT+vuTy5ptq2YZz/2JblsdlZtzkhyblUd7u5/t5wR5zbvv6/buvvzST5fVe9M8qjM3jNuXcyzH89LcvG05t1YVR9J8neS/OfljLhttuv33dqyfqwt1pZVsrZ8NWvLeq0tO2VdSawtx/19H/oMnumaulcluaG7f2XD/RuvS/v+JMd8V+oFz3bvqjr9yNeZvTnv9UmuSHL+9LDzk1y+7NkmdzqbYh2O2QabHaMrkjyzqu5ZVQ9N8rAs+Ze0qp6a2f934fu6+6823P+Aqrrb9PU3TrN9eMmzbfYarvy4Jfm7Sf68u286cseSjtmfJnlYVT10OmvtmZkdj42uSPJj07vUf3uSzx65RHDNnHBfqmpPkjcleW53r9t/jI844X5090O7e293703yhiT/y5r9j6Qj5vn3dXmSJ1bVrqr6G0m+LbP3i1sn8+zHX2T2vm2pqt1JHp4lr3HbZLt+360t68faYm1ZJWvLV7O2rJedsq4k1pbj/r6PfgbPE5I8N8l1NX30cmbvmP2sqnp0ZqcvHUzyghXMtjvJm6eSuyvJ67r796rqT5P8dlU9P7N/eD+87MGmX9jvzp2Pyy+t4phV1euT7E9yRlXdlOTnklycYxyj7n5/Vf12Zu/ufjjJTy7yVMhNZvuZzD6N6u3Ta/vH3f3CzN4B/eer6nCSO5K8sLvnfRPk7Zpt/7Few2Uet2PN1d2vyle/31OyhGPW3Yer6kVJfj+zd9x/9XQ8Xjh9/19m9mkH52b25tN/lVnxXztz7ss/TvI3///27iXUqiqO4/j354N8VRJRVEhKBWaDGhiVVFADQaIosBrUqIE5EgmrSQ6iQdAkaKBoDm5gJAVlBmVGCNnb9y01KHw0qImkkhaC+m+w94Wb3cs9hXrvtu8HDuzHWuv8zz77rMGf/14HWNHen6eqau5oxTyUHj9HJ/TyWapqX5KNQD9wBlhTVaOZQP+HHr+Tl4C+JN/RlAs/X1WHRy3oYQwzN06Ec/t7d25xbjmfnFucW3BuGTMulrnlYplXwLllxDHbJ0wkSZIkSZLUUZ1+REuSJEmSJEkmeCRJkiRJkjrPBI8kSZIkSVLHmeCRJEmSJEnqOBM8kiRJkiRJHWeCR52TZGn7V+8D+x8mmT6aMUmSJEmSNJr8m3SNOUlCc2+eGeb8QWBuVR2+oIFJkiRJkjRGWcGjniVZnuSHJJ8keSvJsiQ3JNmYZHuSLUlmt237kryW5Msk+5MsHDTOs0m2JulP8mJ7bGaSfUlWADuAGUlWJtmWZM+gdkuAa4HNSTa3xw4mubLdfibJ9+1r6Vljv96OtSnJ5IHxkuxtY1l34a6mJEmSJEnnjhU86kmSucAa4C5gAk0SZhWwAFhcVT8muQN4uaruT9IHTAUeB2YDG6rqxiTzgYXA00CADcArwM/AfmBeVX3dvucVVfVbkvHAp8CSquo/u4JnYB+4HugD7mzH/gZ4EjgC/NT22ZXk7TaetUl+AWZV1ckk06vq6Hm6hJIkSZIknTcTRjsAdcbdwPtV9SdAkg+AScA84J3mqSoALhnUZ337mNXeJFe3x+a3r53t/jTgJpoEz6GB5E7rsSSLaO7Ta4A5QP8IMb5XVSfaGN8F7qFJIh2oql1tu+3AzHa7H3gzyXpgfQ/XQZIkSZKkMccEj3qVIY6NA45W1W3D9Dk5RP/QVPms+tvgyUzgxKD9WcAy4PaqOtJWBE36DzEOFctpYHK7/QBwL/AQsDzJLVV1aoT3kSRJkiRpTHENHvXqc+DBJJOSTKNJjPwBHEjyKDSLIye5dYRxPgaeascgyXVJrhqi3WU0CZ9jbfXPgkHnfgcuHaLPZ8DDSaYkmQo8AmwZLpAk44AZVbUZeA6YTlNRJEmSJElSp1jBo55U1dYkG4DdwCFgG3AMeAJYmeQFYCKwrm0z3DibktwMfNU+1nWcZp2c02e1251kJ7CHZm2eLwadXg18lOTXqrpvUJ8dbaXPt+2hNVW1s60OGsp4YG2Sy2mqf151DR5JkiRJUhe5yLJ6lmRaVR1PMoWmWmZRVe0Y7bgkSZIkSfq/s4JH/8bqJHNo1sJ5w+SOJEmSJEljgxU8kiRJkiRJHeciy5IkSZIkSR1ngkeSJEmSJKnjTPBIkiRJkiR1nAkeSZIkSZKkjjPBI0mSJEmS1HF/AWDTrGf+IuloAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(traces) / 4), 4, sharey=True, figsize=(16, 9))\n",
    "for ax, (log, trace) in zip(axes.flatten(), traces.items()):\n",
    "    traces[log].generations_by_task.hist(bins=20, ax=ax)\n",
    "    ax.set_title(f\"{log} ({len(trace.generations_by_task)} tasks)\")\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('generations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a histogram counting the number of generations until stopping. These results were obtained with default setting of early stopping if no improvement was made after 20 generations, with a 200 generation maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Expressions\n",
    "For a given problem, we have a Pareto front of solutions for search (=each left out task).\n",
    "This Pareto front may contain \"twins\", multiple solutions which performance equally well and have the same length.\n",
    "Given that the response surface does not differ *that* much when leaving any particular task out, we hope that the symbolic expressions we find are reasonably consistent across searches.\n",
    "To have some indication of how consistent the results are, for each problem we find the most frequent solutions of length 1, 2 and 3. We also note the number of hyperparameters for which we aim to find a symbolic default, as we expect this to be correlated to how consistent the solutions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_warm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        svm_warm\n",
       "1          106.0\n",
       "2           85.0\n",
       "3           24.0\n",
       "params       2.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_count = pd.DataFrame(np.zeros((4, len(traces))), columns=list(traces), index=[1, 2, 3, \"params\"])\n",
    "for log, trace in traces.items():  \n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            if length == 1:\n",
    "                expr_count.loc[\"params\"][log] = m.count(',') + 1\n",
    "expr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the found expressions per problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 106 expressions of length 1. Most frequent: make_tuple(p, mkd) (106 times)\n",
      " Found 106 expressions of length 2. Most frequent: make_tuple(m, truediv(mkd, xvar)) (85 times)\n",
      " Found  91 expressions of length 3. Most frequent: make_tuple(7.0, truediv(1.0, mul(p, xvar))) (24 times)\n"
     ]
    }
   ],
   "source": [
    "for length, expressions in sorted(traces[\"svm_warm\"].expressions.items()):\n",
    "    if 0 < length < 4:\n",
    "        m = max(set(expressions), key=expressions.count)\n",
    "        expr_count.loc[length][log] = expressions.count(m)\n",
    "        print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Quality\n",
    "The expressions we find also need to be good.\n",
    "Here we compare the following 'strategies':\n",
    " - length-*n*: always pick the best expression of length *n*\n",
    " - *final*: always pick the best expression, regardless of length\n",
    " - *baseline(s)*: compare it to baselines we defined\n",
    " \n",
    "We want to know (all based on out-of-sample performance):\n",
    " - which strategy gives the best solution most often?\n",
    " - which strategy experiences the least mean regret?\n",
    " - which strategy experiences the least median regret?\n",
    " \n",
    "As mentioned before, there can be \"twins\" in the Pareto front, which means multiple solutions with equal length have equal in-sample performance.\n",
    "In this case we average the out-of-sample score of those twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of wins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table records the number of times a strategy led to the symbolic expression with the best out-of-sample performance (multiple strategies can be the best each task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>sklearn_scale</th>\n",
       "      <th>symbolic_best</th>\n",
       "      <th>symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          const  final  length-1  length-2  length-3  sklearn_scale  \\\n",
       "svm_warm   14.0   11.0      32.0      12.0       9.0           17.0   \n",
       "\n",
       "          symbolic_best  symbolic_v2  \n",
       "svm_warm           26.0         18.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    comparisons = comparisons.append(trace.comparison.loc['either'].rename(log))\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median regret:\n",
    "The following table records the median regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_const</th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_sklearn_scale</th>\n",
       "      <th>d_symbolic_best</th>\n",
       "      <th>d_symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.02645</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.01655</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.01125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          d_const  d_final  d_length-1  d_length-2  d_length-3  \\\n",
       "svm_warm  0.02645   0.0118     0.01285      0.0115      0.0117   \n",
       "\n",
       "          d_sklearn_scale  d_symbolic_best  d_symbolic_v2  \n",
       "svm_warm          0.01655          0.00525        0.01125  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.median().rename(log)\n",
    "    medians = medians.append(m)\n",
    "medians[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean regret:\n",
    "The following table records the mean regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_const</th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_sklearn_scale</th>\n",
       "      <th>d_symbolic_best</th>\n",
       "      <th>d_symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.039659</td>\n",
       "      <td>0.043031</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>0.037292</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>0.047946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           d_const   d_final  d_length-1  d_length-2  d_length-3  \\\n",
       "svm_warm  0.071775  0.039659    0.043031    0.035999    0.037292   \n",
       "\n",
       "          d_sklearn_scale  d_symbolic_best  d_symbolic_v2  \n",
       "svm_warm         0.046048         0.037642       0.047946  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = pd.DataFrame([])\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.mean().rename(log)\n",
    "    means = means.append(m)\n",
    "means[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Sometimes out-of-sample performance of a baseline may still be better than that of our solution.\n",
    "However, in-sample performance of our own solutions should always be better than any baseline.\n",
    "If that is not the case, this would indicate our search does not explore the space well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>sklearn_scale</th>\n",
       "      <th>symbolic_best</th>\n",
       "      <th>symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          const  final  length-1  length-2  length-3  sklearn_scale  \\\n",
       "svm_warm    0.0  106.0       0.0      23.0      43.0            0.0   \n",
       "\n",
       "          symbolic_best  symbolic_v2  \n",
       "svm_warm            0.0          0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    comparisons = comparisons.append(trace.in_comparison.loc['either'].rename(log))\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "End of notebook - just sketchpad below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
