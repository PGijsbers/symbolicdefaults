{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Trace:\n",
    "\n",
    "    def __init__(self, filename: str, benchmarks=None):\n",
    "        self.baseline = set(benchmarks) if benchmarks else set()\n",
    "        self.scores, self.expressions, generations_by_task, self.baseline = parse_log(filename, baseline=self.baseline)\n",
    "        self.comparison, self.d_scores = comparisons(self.scores)\n",
    "        self.in_comparison, self.in_d_scores = comparisons(self.scores, sample=\"in-sample\")\n",
    "        self.generations_by_task = pd.Series(generations_by_task, name=\"generations\")\n",
    "\n",
    "    @property\n",
    "    def most_frequent_solutions_by_length(self):\n",
    "        for length, expressions in sorted(self.expressions.items()):\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            yield m, expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "\n",
    "\n",
    "def parse_log(file, with_prefix=False, baseline=None):\n",
    "    with open(file) as fh:\n",
    "        lines = fh.readlines()\n",
    "\n",
    "    p = 'INFO:root:' if with_prefix else ''\n",
    "\n",
    "    definitions = [line for line in lines if ':=' in line]\n",
    "    baseline = baseline if baseline else set()\n",
    "\n",
    "    print(\"The predefined defaults are:\")\n",
    "    for line in definitions:\n",
    "        if ':=' in line:\n",
    "            print(f\" * {line[len(p):-1]}\")\n",
    "            baseline.add(line[len(p):].split(' :=')[0])\n",
    "\n",
    "    task_starts = [i for i, line in enumerate(lines) if \"START_TASK:\" in line]\n",
    "    in_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating in sample:\" in line]\n",
    "    out_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating out-of-sample:\" in line]\n",
    "\n",
    "    def parse_evaluation_line(line) -> Tuple[str, int, float]:\n",
    "        \"\"\" Parse an evaluation line, returning the expression or name, its 'length' and the score.\n",
    "\n",
    "        e.g. INFO:root:[make_tuple(p, mkd)|0.8893]\\n -> 'make_tuple(p, mkd)', 1, 0.8893\n",
    "        Length is 0 for benchmark problems.\n",
    "        \"\"\"\n",
    "        start, pipe, end = line.find('['), line.find('|'), line.find(']')\n",
    "        expression = line[start + 1: pipe]\n",
    "        if ':' in expression:  # For the baseline expressions, record them by name\n",
    "            expression = expression[:expression.find(':')]\n",
    "        expression_length = expression.count('(')\n",
    "        return expression, expression_length, float(line[pipe + 1: end])\n",
    "\n",
    "    tasks = [int(line[:-1].split(\": \")[-1]) for line in lines if \"START_TASK:\" in line]\n",
    "    idx = pd.MultiIndex.from_product([tasks, [\"in-sample\", \"out-sample\"]], names=['task', 'sample-type'])\n",
    "    df = pd.DataFrame(index=idx, columns=[\"length-1\", \"length-2\", \"length-3\", \"final\", *baseline], dtype=float)\n",
    "\n",
    "    expressions_by_length = defaultdict(list)\n",
    "    generations_by_task = {}\n",
    "\n",
    "    for task_start, in_start, out_start, next_task in zip(task_starts, in_sample_starts,\n",
    "                                                          out_sample_starts,\n",
    "                                                          task_starts[1:] + [-len(baseline)*2]):\n",
    "        # start line looks like: INFO:root:START_TASK: 29\\n\n",
    "        task = int(lines[task_start][:-1].split(\": \")[-1])\n",
    "\n",
    "        # Since the in-sample evaluation message follows directly after optimization is done, we use that to record\n",
    "        # the number of generations. We account for the early stopping message if it did not run to 200 generations.\n",
    "        ended_early = 0 if in_start - task_start == 201 else - 1\n",
    "        generations_by_task[task] = in_start - (task_start + 1) - ended_early\n",
    "\n",
    "        # Following the \"INFO:root:Evaluating in sample:\" message, symbolic default performance are printed\n",
    "        # They are formatted as \"INFO:root:[make_tuple(p, mkd)|0.8893]\"\n",
    "        # First is any number of best solutions from the pareto front. The last four are benchmark solutions.\n",
    "        # It is possible that two equally good solutions are printed (i.e. same length and performance).\n",
    "        expr_in_task = set()\n",
    "        max_length = 0\n",
    "\n",
    "        for in_sample_evaluation in lines[in_start + 1: out_start]:\n",
    "            expr, length, score = parse_evaluation_line(in_sample_evaluation)\n",
    "            # Pareto fronts may contain literal duplicates, so we filter those out manually.\n",
    "            # We also do not want to include the baseline solutions (they have ':' in their line)\n",
    "            if expr not in expr_in_task: # and ':' not in expr:\n",
    "                expressions_by_length[length].append(expr)\n",
    "                expr_in_task.add(expr)\n",
    "\n",
    "            if length != 0:\n",
    "                if length < 4:\n",
    "                    # Only report one out-of-sample solution for each length (and all benchmarks), so overwrite is OK.\n",
    "                    df.loc[task, \"in-sample\"][f\"length-{length}\"] = score\n",
    "\n",
    "                # Update best so far score and maximum length\n",
    "                df.loc[task, \"in-sample\"][f\"final\"] = np.nanmax(\n",
    "                    [score, df.loc[task, \"in-sample\"][f\"final\"]])\n",
    "                max_length = max(max_length, length)\n",
    "            else:\n",
    "                df.loc[task, \"in-sample\"][expr] = score\n",
    "\n",
    "            if length > max_length:\n",
    "                max_length = length  # To know for which length \"best\" should score out of sample\n",
    "\n",
    "        # Because two equal solutions can be in the Pareto front,\n",
    "        # we note the average out of sample performance if multiple solutions were found.\n",
    "        # Naturally, the solutions with the best in-sample score were those with the highest length in the Pareto front.\n",
    "\n",
    "        scores_by_length = defaultdict(list)\n",
    "\n",
    "        for out_sample_evaluation in lines[out_start + 1: next_task]:\n",
    "            expr, length, score = parse_evaluation_line(out_sample_evaluation)\n",
    "            if length != 0:\n",
    "                scores_by_length[length].append(score)\n",
    "            else:\n",
    "                df.loc[task, \"out-sample\"][expr] = score\n",
    "\n",
    "        for length, scores in scores_by_length.items():\n",
    "            if length < 4:\n",
    "                df.loc[task, \"out-sample\"][f\"length-{length}\"] = np.mean(scores)\n",
    "            if length == max_length:\n",
    "                df.loc[task, \"out-sample\"][f\"final\"] = np.mean(scores)\n",
    "            if np.mean(scores) == float(\"nan\"):\n",
    "                print('hi')\n",
    "\n",
    "    return df, expressions_by_length, generations_by_task, baseline\n",
    "\n",
    "\n",
    "def comparisons(df, sample=\"out-sample\"):\n",
    "    out_sample = df.index.map(lambda idx: idx[1] == sample)\n",
    "\n",
    "    alone = {k: 0 for k in df.iloc[0].index.values}\n",
    "    shared = {k: 0 for k in df.iloc[0].index.values}\n",
    "\n",
    "    for _, out in df.loc[out_sample].iterrows():\n",
    "        best = out[out == out.max()].index.values\n",
    "        if len(best) == 1:\n",
    "            alone[best[0]] += 1\n",
    "        else:\n",
    "            for winner in best:\n",
    "                shared[winner] += 1\n",
    "\n",
    "    alone = {k: alone[k] for k in sorted(alone)}\n",
    "    shared = {k: shared[k] for k in sorted(shared)}\n",
    "    either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "    comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "\n",
    "    df_out = df.loc[out_sample].copy()\n",
    "    df_out['max'] = df_out.max(axis=1)\n",
    "    for col in df_out:\n",
    "        df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "    d_cols = [c for c in df_out.columns if c.startswith('d_')]\n",
    "    df_out[d_cols].mean()\n",
    "    df_out[d_cols].median()\n",
    "\n",
    "    in_sample = df.index.map(lambda idx: idx[1] == \"in-sample\")\n",
    "    df.loc[in_sample].idxmax(axis=1).value_counts()\n",
    "    df.loc[in_sample][reversed(df.columns)].idxmax(axis=1).value_counts()\n",
    "    return comparison, df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We have experiment data for a set of algorithms and meta-data for the datasets on which the experiments took place.\n",
    "We use symbolic regression to find an expression for symbolic default values that give good performance across tasks.\n",
    "Symbolic regression is performed with leave-one-task-out, which means for each algorithm we have multiple searches for a symbolic default, and their performance is recorded for both in-sample (the optimization surface of all-but-one tasks) and out-of-sample (the left out task) performance. Performance here is solely based on surrogate model predictions, no additional experiments have been performed (yet).\n",
    "\n",
    "In our search, we use NSGA-II selection to perform multi-objective optimization: find the expression with the best performance, while using the fewest number of operators (e.g. `divide`, `multiply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "**Length** of an expression denotes the number of operators in it. A symbolic value is *not* considered an operation.\n",
    "Consider the following SVM defaults for cost and gamma:\n",
    " - `make_tuple`(m, mkd) is length 1.\n",
    " - `make_tuple`(m, `truediv`(mkd, xvar)) is length 2.\n",
    " - `make_tuple`(16., `truediv`(mkd, xvar)) is length 2.\n",
    "\n",
    "The **final** solution refers to the symbolic default with the highest in-sample score for a task (regardless of its length). This means for each task there is *at least* one final solution, but there may be more and they are not of a specific length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline** solutions are typically the default hyperparameter settings of mlr, scikit-learn, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the logs, because some logs are incomplete we have to explicitly give the name of the baselines (this will be fixed for future runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predefined defaults are:\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      "The predefined defaults are:\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n",
      "The predefined defaults are:\n",
      " * sklearn_scale := make_tuple(1., truediv(1., mul(p, xvar)))\n",
      " * symbolic_best := make_tuple(16., truediv(mkd, xvar))\n",
      " * symbolic_v2 := make_tuple(m, add(mkd, mkd)))\n",
      " * const := make_tuple(812.267350, 0.001361)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "baselines = dict(\n",
    "    glmnet=[\"mlr_default\", \"sklearn_default\"],\n",
    "    kerasff=[\"initial_values\"],\n",
    "    knn=[\"mlr_default\"],\n",
    "    rf=[\"mlr_default\"],\n",
    "    rpart=[\"mlr_default\"],\n",
    "    asvm=[\"sklearn_scale\", \"symbolic_best\", \"symbolic_v2\" , \"const\"],\n",
    ")\n",
    "traces = {}\n",
    "for file in os.listdir('runs'):\n",
    "    if file.endswith('.log') and 'svm' in file:\n",
    "        baseline = []\n",
    "        for method, bls in baselines.items():\n",
    "            if method in file:\n",
    "                baseline = bls\n",
    "        traces[file[:-4]] = Trace(os.path.join('runs', file), benchmarks=baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "As described before, for each problem we find a symbolic default leaving one task out.\n",
    "We are interested to see how fast the symbolic regression converges across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of generations across tasks by problem:\n",
      "mlr_svm_lisa     62\n",
      "svm_cst          46\n",
      "svm_cst_a1       40\n",
      "svm_cst_ngen10_oc  11\n",
      "svm_cst_oc      105\n",
      "svm_warm         46\n",
      "svm_warm_new     30\n"
     ]
    }
   ],
   "source": [
    "print(\"Median number of generations across tasks by problem:\")\n",
    "for log, trace in traces.items():\n",
    "    print(f\"{log: <15} {trace.generations_by_task.median().astype(int):3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(traces) / 4), 4, sharey=True, figsize=(16, 9))\n",
    "for ax, (log, trace) in zip(axes.flatten(), traces.items()):\n",
    "    traces[log].generations_by_task.hist(bins=20, ax=ax)\n",
    "    ax.set_title(f\"{log} ({len(trace.generations_by_task)} tasks)\")\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('generations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a histogram counting the number of generations until stopping. These results were obtained with default setting of early stopping if no improvement was made after 20 generations, with a 200 generation maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Expressions\n",
    "For a given problem, we have a Pareto front of solutions for search (=each left out task).\n",
    "This Pareto front may contain \"twins\", multiple solutions which performance equally well and have the same length.\n",
    "Given that the response surface does not differ *that* much when leaving any particular task out, we hope that the symbolic expressions we find are reasonably consistent across searches.\n",
    "To have some indication of how consistent the results are, for each problem we find the most frequent solutions of length 1, 2 and 3. We also note the number of hyperparameters for which we aim to find a symbolic default, as we expect this to be correlated to how consistent the solutions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <th>svm_cst</th>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <th>svm_cst_ngen10_oc</th>\n",
       "      <th>svm_cst_oc</th>\n",
       "      <th>svm_warm</th>\n",
       "      <th>svm_warm_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mlr_svm_lisa  svm_cst  svm_cst_a1  svm_cst_ngen10_oc  svm_cst_oc  \\\n",
       "1              106.0     88.0        86.0               35.0         5.0   \n",
       "2               58.0      7.0        13.0                8.0         4.0   \n",
       "3                3.0      1.0         2.0                1.0         2.0   \n",
       "params           2.0      2.0         2.0                2.0         2.0   \n",
       "\n",
       "        svm_warm  svm_warm_new  \n",
       "1          106.0           5.0  \n",
       "2           85.0           5.0  \n",
       "3           24.0           2.0  \n",
       "params       2.0           2.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_count = pd.DataFrame(np.zeros((4, len(traces))), columns=list(traces), index=[1, 2, 3, \"params\"])\n",
    "for log, trace in traces.items():  \n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            if length == 1:\n",
    "                expr_count.loc[\"params\"][log] = m.count(',') + 1\n",
    "expr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the found expressions per problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found 103 expressions of length 1. Most frequent: make_tuple(1024, 0.001) (86 times)\n",
      " Found 100 expressions of length 2. Most frequent: make_tuple(add(64, 128), 0.00390625) (13 times)\n",
      " Found  51 expressions of length 3. Most frequent: make_tuple(sub(add(64, 128), 7.0), 0.00390625) (2 times)\n"
     ]
    }
   ],
   "source": [
    "for length, expressions in sorted(traces[\"svm_cst_a1\"].expressions.items()):\n",
    "    if 0 < length < 4:\n",
    "        m = max(set(expressions), key=expressions.count)\n",
    "        expr_count.loc[length][log] = expressions.count(m)\n",
    "        print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Quality\n",
    "The expressions we find also need to be good.\n",
    "Here we compare the following 'strategies':\n",
    " - length-*n*: always pick the best expression of length *n*\n",
    " - *final*: always pick the best expression, regardless of length\n",
    " - *baseline(s)*: compare it to baselines we defined\n",
    " \n",
    "We want to know (all based on out-of-sample performance):\n",
    " - which strategy gives the best solution most often?\n",
    " - which strategy experiences the least mean regret?\n",
    " - which strategy experiences the least median regret?\n",
    " \n",
    "As mentioned before, there can be \"twins\" in the Pareto front, which means multiple solutions with equal length have equal in-sample performance.\n",
    "In this case we average the out-of-sample score of those twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of wins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table records the number of times a strategy led to the symbolic expression with the best out-of-sample performance (multiple strategies can be the best each task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>sklearn_scale</th>\n",
       "      <th>symbolic_best</th>\n",
       "      <th>symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_ngen10_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm_new</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   const  final  length-1  length-2  length-3  sklearn_scale  \\\n",
       "mlr_svm_lisa        14.0   19.0      31.0      15.0      10.0           17.0   \n",
       "svm_cst              NaN   65.0      43.0      57.0      22.0            NaN   \n",
       "svm_cst_a1           NaN   62.0      37.0      56.0      27.0            NaN   \n",
       "svm_cst_ngen10_oc    NaN   28.0      27.0      28.0       3.0            NaN   \n",
       "svm_cst_oc           NaN    3.0       4.0       2.0       2.0            NaN   \n",
       "svm_warm            14.0   11.0      32.0      12.0       9.0           17.0   \n",
       "svm_warm_new         0.0    0.0       2.0       0.0       0.0            0.0   \n",
       "\n",
       "                   symbolic_best  symbolic_v2  \n",
       "mlr_svm_lisa                21.0         19.0  \n",
       "svm_cst                      NaN          NaN  \n",
       "svm_cst_a1                   NaN          NaN  \n",
       "svm_cst_ngen10_oc            NaN          NaN  \n",
       "svm_cst_oc                   NaN          NaN  \n",
       "svm_warm                    26.0         18.0  \n",
       "svm_warm_new                 2.0          1.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    out_comparisons = out_comparisons.append(trace.comparison.loc['either'].rename(log))\n",
    "out_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median regret:\n",
    "The following table records the median regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_const</th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_sklearn_scale</th>\n",
       "      <th>d_symbolic_best</th>\n",
       "      <th>d_symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <td>0.02740</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.01785</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>0.01125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_ngen10_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.02645</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.01655</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.01125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm_new</th>\n",
       "      <td>0.03960</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.00650</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.03130</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   d_const  d_final  d_length-1  d_length-2  d_length-3  \\\n",
       "mlr_svm_lisa       0.02740   0.0072     0.01465      0.0114     0.00600   \n",
       "svm_cst                NaN   0.0000     0.00035      0.0000     0.00000   \n",
       "svm_cst_a1             NaN   0.0000     0.00110      0.0000     0.00000   \n",
       "svm_cst_ngen10_oc      NaN   0.0000     0.00000      0.0000     0.00015   \n",
       "svm_cst_oc             NaN   0.0000     0.00000      0.0013     0.00055   \n",
       "svm_warm           0.02645   0.0118     0.01285      0.0115     0.01170   \n",
       "svm_warm_new       0.03960   0.0015     0.00650      0.0046     0.00140   \n",
       "\n",
       "                   d_sklearn_scale  d_symbolic_best  d_symbolic_v2  \n",
       "mlr_svm_lisa               0.01785          0.00640        0.01125  \n",
       "svm_cst                        NaN              NaN            NaN  \n",
       "svm_cst_a1                     NaN              NaN            NaN  \n",
       "svm_cst_ngen10_oc              NaN              NaN            NaN  \n",
       "svm_cst_oc                     NaN              NaN            NaN  \n",
       "svm_warm                   0.01655          0.00525        0.01125  \n",
       "svm_warm_new               0.03130          0.00020        0.00930  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.median().rename(log)\n",
    "    medians = medians.append(m)\n",
    "medians[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean regret:\n",
    "The following table records the mean regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_const</th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_sklearn_scale</th>\n",
       "      <th>d_symbolic_best</th>\n",
       "      <th>d_symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.037756</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.040095</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.046646</td>\n",
       "      <td>0.038240</td>\n",
       "      <td>0.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_ngen10_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.039659</td>\n",
       "      <td>0.043031</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>0.037292</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>0.037642</td>\n",
       "      <td>0.047946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm_new</th>\n",
       "      <td>0.032060</td>\n",
       "      <td>0.023240</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.040040</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.032960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    d_const   d_final  d_length-1  d_length-2  d_length-3  \\\n",
       "mlr_svm_lisa       0.072373  0.037756    0.043629    0.040095    0.033708   \n",
       "svm_cst                 NaN  0.001913    0.005973    0.002917    0.003038   \n",
       "svm_cst_a1              NaN  0.002152    0.007073    0.002045    0.002470   \n",
       "svm_cst_ngen10_oc       NaN  0.001829    0.008771    0.001874    0.010167   \n",
       "svm_cst_oc              NaN  0.006160    0.000320    0.011260    0.008125   \n",
       "svm_warm           0.071775  0.039659    0.043031    0.035999    0.037292   \n",
       "svm_warm_new       0.032060  0.023240    0.014720    0.026200    0.015433   \n",
       "\n",
       "                   d_sklearn_scale  d_symbolic_best  d_symbolic_v2  \n",
       "mlr_svm_lisa              0.046646         0.038240       0.048544  \n",
       "svm_cst                        NaN              NaN            NaN  \n",
       "svm_cst_a1                     NaN              NaN            NaN  \n",
       "svm_cst_ngen10_oc              NaN              NaN            NaN  \n",
       "svm_cst_oc                     NaN              NaN            NaN  \n",
       "svm_warm                  0.046048         0.037642       0.047946  \n",
       "svm_warm_new              0.040040         0.001440       0.032960  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = pd.DataFrame([])\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.mean().rename(log)\n",
    "    means = means.append(m)\n",
    "means[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Sometimes out-of-sample performance of a baseline may still be better than that of our solution.\n",
    "However, in-sample performance of our own solutions should always be better than any baseline.\n",
    "If that is not the case, this would indicate our search does not explore the space well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>sklearn_scale</th>\n",
       "      <th>symbolic_best</th>\n",
       "      <th>symbolic_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst</th>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_ngen10_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_oc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm_new</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   const  final  length-1  length-2  length-3  sklearn_scale  \\\n",
       "mlr_svm_lisa         0.0   91.0       0.0      45.0      20.0            0.0   \n",
       "svm_cst              NaN  103.0       5.0      60.0      36.0            NaN   \n",
       "svm_cst_a1           NaN  103.0       2.0      54.0      38.0            NaN   \n",
       "svm_cst_ngen10_oc    NaN   35.0       1.0      28.0       3.0            NaN   \n",
       "svm_cst_oc           NaN    5.0       0.0       1.0       2.0            NaN   \n",
       "svm_warm             0.0  106.0       0.0      23.0      43.0            0.0   \n",
       "svm_warm_new         0.0    5.0       0.0       2.0       1.0            0.0   \n",
       "\n",
       "                   symbolic_best  symbolic_v2  \n",
       "mlr_svm_lisa                15.0          0.0  \n",
       "svm_cst                      NaN          NaN  \n",
       "svm_cst_a1                   NaN          NaN  \n",
       "svm_cst_ngen10_oc            NaN          NaN  \n",
       "svm_cst_oc                   NaN          NaN  \n",
       "svm_warm                     0.0          0.0  \n",
       "svm_warm_new                 0.0          0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    in_sample_comparisons = in_sample_comparisons.append(trace.in_comparison.loc['either'].rename(log))\n",
    "in_sample_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "End of notebook - just sketchpad below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(3, out-sample)</th>\n",
       "      <th>(6, out-sample)</th>\n",
       "      <th>(11, out-sample)</th>\n",
       "      <th>(12, out-sample)</th>\n",
       "      <th>(14, out-sample)</th>\n",
       "      <th>(15, out-sample)</th>\n",
       "      <th>(16, out-sample)</th>\n",
       "      <th>(18, out-sample)</th>\n",
       "      <th>(22, out-sample)</th>\n",
       "      <th>(23, out-sample)</th>\n",
       "      <th>...</th>\n",
       "      <th>(168908, out-sample)</th>\n",
       "      <th>(168909, out-sample)</th>\n",
       "      <th>(168910, out-sample)</th>\n",
       "      <th>(168911, out-sample)</th>\n",
       "      <th>(168912, out-sample)</th>\n",
       "      <th>(189924, out-sample)</th>\n",
       "      <th>(189927, out-sample)</th>\n",
       "      <th>(189928, out-sample)</th>\n",
       "      <th>(190411, out-sample)</th>\n",
       "      <th>(190412, out-sample)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst</th>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.8868</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cst_a1</th>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_warm</th>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_scale</th>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbolic_v2</th>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbolic_best</th>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.7339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               (3, out-sample)  (6, out-sample)  (11, out-sample)  \\\n",
       "mlr_svm_lisa            0.9132           0.9912            0.8982   \n",
       "svm_cst                 0.9518           0.9351            0.8868   \n",
       "svm_cst_a1              0.9497           0.9312            0.8902   \n",
       "svm_warm                0.9713           0.9873            0.9128   \n",
       "sklearn_scale           0.9193           0.9681            0.8807   \n",
       "symbolic_v2             0.8774           0.9958            0.9050   \n",
       "symbolic_best           0.9816           0.9893            0.9531   \n",
       "const                   0.9420           0.9355            0.8968   \n",
       "\n",
       "               (12, out-sample)  (14, out-sample)  (15, out-sample)  \\\n",
       "mlr_svm_lisa             0.9975            0.9944            0.9896   \n",
       "svm_cst                  0.9987            0.9921            0.9744   \n",
       "svm_cst_a1               0.9986            0.9898            0.9770   \n",
       "svm_warm                 0.9987            0.9864            0.9805   \n",
       "sklearn_scale            0.9925            0.9647            0.9921   \n",
       "symbolic_v2              0.9958            0.9867            0.9805   \n",
       "symbolic_best            0.9985            0.9958            0.9463   \n",
       "const                    0.9983            0.9926            0.9782   \n",
       "\n",
       "               (16, out-sample)  (18, out-sample)  (22, out-sample)  \\\n",
       "mlr_svm_lisa             0.9976            0.9699            0.9823   \n",
       "svm_cst                  0.9896            0.9721            0.9702   \n",
       "svm_cst_a1               0.9893            0.9711            0.9712   \n",
       "svm_warm                 0.9985            0.9677            0.9814   \n",
       "sklearn_scale            0.9947            0.9356            0.9672   \n",
       "symbolic_v2              0.9985            0.9759            0.9842   \n",
       "symbolic_best            0.9978            0.9727            0.9789   \n",
       "const                    0.9895            0.9705            0.9673   \n",
       "\n",
       "               (23, out-sample)  ...  (168908, out-sample)  \\\n",
       "mlr_svm_lisa             0.9112  ...                0.9469   \n",
       "svm_cst                  0.9195  ...                0.8032   \n",
       "svm_cst_a1               0.9261  ...                0.8033   \n",
       "svm_warm                 0.8612  ...                0.9705   \n",
       "sklearn_scale            0.9476  ...                0.9667   \n",
       "symbolic_v2              0.9287  ...                0.9792   \n",
       "symbolic_best            0.8479  ...                0.9387   \n",
       "const                    0.9161  ...                0.9815   \n",
       "\n",
       "               (168909, out-sample)  (168910, out-sample)  \\\n",
       "mlr_svm_lisa                 0.9775                0.9442   \n",
       "svm_cst                         NaN                0.8896   \n",
       "svm_cst_a1                      NaN                0.8896   \n",
       "svm_warm                     0.9949                0.9917   \n",
       "sklearn_scale                0.9518                0.9599   \n",
       "symbolic_v2                  0.9969                0.9827   \n",
       "symbolic_best                0.9767                0.9659   \n",
       "const                        0.9831                0.9494   \n",
       "\n",
       "               (168911, out-sample)  (168912, out-sample)  \\\n",
       "mlr_svm_lisa                 0.9524                0.9887   \n",
       "svm_cst                      0.9483                   NaN   \n",
       "svm_cst_a1                   0.9434                   NaN   \n",
       "svm_warm                     0.9521                0.9919   \n",
       "sklearn_scale                0.9533                0.9910   \n",
       "symbolic_v2                  0.9335                0.9866   \n",
       "symbolic_best                0.9511                0.9839   \n",
       "const                        0.9475                0.9963   \n",
       "\n",
       "               (189924, out-sample)  (189927, out-sample)  \\\n",
       "mlr_svm_lisa                 0.9854                0.9697   \n",
       "svm_cst                      0.5603                0.9002   \n",
       "svm_cst_a1                   0.5643                0.9345   \n",
       "svm_warm                     0.9854                0.9695   \n",
       "sklearn_scale                0.7663                0.9692   \n",
       "symbolic_v2                  0.5274                0.8911   \n",
       "symbolic_best                0.9862                0.9695   \n",
       "const                        0.5543                0.9355   \n",
       "\n",
       "               (189928, out-sample)  (190411, out-sample)  \\\n",
       "mlr_svm_lisa                 0.9855                0.9359   \n",
       "svm_cst                      0.8489                0.8849   \n",
       "svm_cst_a1                   0.8473                0.8976   \n",
       "svm_warm                     0.9397                0.9085   \n",
       "sklearn_scale                0.8853                0.8788   \n",
       "symbolic_v2                  0.8864                0.8811   \n",
       "symbolic_best                0.9782                0.9301   \n",
       "const                        0.8361                0.8884   \n",
       "\n",
       "               (190412, out-sample)  \n",
       "mlr_svm_lisa                 0.6253  \n",
       "svm_cst                         NaN  \n",
       "svm_cst_a1                      NaN  \n",
       "svm_warm                     0.6689  \n",
       "sklearn_scale                0.4536  \n",
       "symbolic_v2                  0.5789  \n",
       "symbolic_best                0.7339  \n",
       "const                        0.2500  \n",
       "\n",
       "[8 rows x 106 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    # Filter out runs with >100 tasks completed:\n",
    "    if len(trace.scores) / 2 > 100:\n",
    "        out_sample = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\")\n",
    "        log_oos = trace.scores.loc[out_sample].final.rename(log)\n",
    "        final_scores = final_scores.append(log_oos)\n",
    "        if log == \"svm_warm\":\n",
    "            # contains benchmark scores\n",
    "            for b in trace.baseline:\n",
    "                baseline_score = trace.scores.loc[out_sample][b].rename(b)\n",
    "                final_scores = final_scores.append(baseline_score)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out incomplete tasks:\n",
    "final = final_scores.loc[:, ~final_scores.isna().any()]\n",
    "df = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[[\"mlr_svm_lisa\", \"svm_cst\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlr_svm_lisa</th>\n",
       "      <th>svm_cst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>either</th>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mlr_svm_lisa  svm_cst\n",
       "alone             71       30\n",
       "shared             1        1\n",
       "either            72       31"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alone = {k: 0 for k in df.index.values}\n",
    "shared = {k: 0 for k in df.index.values}\n",
    "\n",
    "for _, out in df.T.iterrows():\n",
    "    best = out[out == out.max()].index.values\n",
    "    if len(best) == 1:\n",
    "        alone[best[0]] += 1\n",
    "    else:\n",
    "        for winner in best:\n",
    "            shared[winner] += 1\n",
    "\n",
    "alone = {k: alone[k] for k in sorted(alone)}\n",
    "shared = {k: shared[k] for k in sorted(shared)}\n",
    "either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_mlr_svm_lisa    0.009959\n",
       "d_svm_cst         0.052484\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = df.T.copy()\n",
    "df_out['max'] = df_out.max(axis=1)\n",
    "for col in df_out:\n",
    "    df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "d_cols = [c for c in df_out.columns if c.startswith('d_') and 'max' not in c]\n",
    "df_out[d_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_mlr_svm_lisa    0.0000\n",
       "d_svm_cst         0.0111\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[d_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Difference')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAboElEQVR4nO3dfZRcdZ3n8fcHBGFoSMBAG2Mk68AgSgawW2TAh7QwbMCDPKwPwzI8rLhxzh4848oiWd3j4DqcZV1AZcRREJYISIvKkwGVBxMRRTBhAwkGRSRgQqYjEAKNEUn47h/310nZXd310HWrKvw+r3Pu6fv0u79v36r+9K1bt24pIjAzs3xs1+kCzMysvRz8ZmaZcfCbmWXGwW9mlhkHv5lZZhz8ZmaZcfDbNkvSuZKubrLtlZL+OY2/U9KvWludWfdy8FvLSXqHpJ9J2iDpGUk/lfS2Ttc1noj4SUTsV8a2Je0m6YuSnpA0LOk3aXpaGf2lPrf8U2vR9hZL+kirtmed5+C3lpK0G7AQ+BdgD2AG8FngxU7W1QmSdgTuBN4CzAV2Aw4DngYO6WBpljkHv7XaXwFExLURsTkiNkbEbRHxoKRXp1cAs0dWlrSXpI2S9pQ0R9JqSZ+UtE7SWknHSzpG0q9T20+N6m8nSd+S9Lyk+yUdWLHt/dPR6rOSHpL0vmoFj/RbMT1T0vWSfi/paUlfbnJfnAq8ATghIn4ZES9HxLqI+FxE3FqrxnTkfomkW9Lvd6+kv0zLJOkLaT9tkPSgpAMkzQNOBj6ZXmF8L60/X9KjaTu/lHRCRT+nS7pb0gWS1kt6TNLRadl5wDuBL6ftNbsvrIs4+K3Vfg1slrRA0tGSdh9ZEBEvAoPA31esfxJwR0T8Pk2/FtiJ4pXCZ4DL0vp9FAH0GUlvrGh/HPBtilcX3wRulLSDpB2A7wG3AXsBHwOukTThKR1J21O8YnkcmJXqGGx0JyRHAj+IiOFx+qqnxpMoXjHtDvwGOC/NPwp4F8U/2qnAh4CnI+JS4Brg8xHRExHHpvUfpdh/U9L2rpY0vaKftwO/AqYBnwcul6SI+DTwE+DMtL0zm9wX1kUc/NZSEfEc8A4gKEL795JultSbVlkA/EdJI8+9U4CrKjbxEnBeRLxEEbjTgC9FxPMR8RDwEPDXFesvjYjvpPUvovincWgaeoDzI+JPEfEjikA/qcavcAjwOuDsiHghIv4YEXc3sSsAXgOsnWB5PTVeHxH3RcQmikA/KM1/CdgVeBOgiFgZEeP2FRHfjogn06uObwGP8Oenmx6PiMsiYjPFYzQd6K22Ldv2Ofit5VIInR4RrwcOoAjSL6Zl9wIvAO+W9CZgH+DmiuZPp/AB2Jh+DlUs30gRliN+V9Hvy8Dq1N/rgN+leSMepziCn8hMihDcVOv3TKc+RoY3VFnlaYoAHU89Nf5bxfgfSL97+ifxZeASYEjSpen9lfFqPVXSsnRK6VmKx6XyDeYt/UTEH9Jo5X62VxAHv5UqIh4GrqQImhELKE7fnAJ8JyL+OIkuZo6MpFcRrweeTMPMilcWUJxvX1Nje78D3iDpVbU6Tqc+RoYnqqxyB/DvJe0yziaarXGk/4sjoo/izeO/As4eWVS5nqS9KV59nQm8JiKmAisA1dPP6O3Zts/Bby0l6U2SzpL0+jQ9k+LUxc8rVrsKOIEi/L8xyS77JJ2YgvrjFFcP/RwYeWXxyXTOfw5wLLXP199HcXrmfEm7SNpJ0uFN1nYVxT+S76b9sp2k10j6lKRjJlEjkt4m6e3pfYIXgD8CI6+UhoDK90F2oQjv36e2/4k//0dcy+jt2TbOwW+t9jzFG4X3SnqBIoRXAGeNrBARq4H7KcLoJ5Ps7yaKNzbXU7yCODEiXoqIPwHvA44GngK+ApyaXoGMK51mOpbiFNQTFKeOPtRMYenN7COBh4Hbgeco/rFMA+5ttsZkN4qj+PUUp4eeBi5Iyy4H3pxO69wYEb8ELgTuoQjx2cBPG/hVvgS8P13xc3ED7axLyV/EYp0g6QrgyYj4H52uxSw3Nc9jmrWapFnAicDBna3ELE8+1WNtJelzFKd+/k9EPNbpesxy5FM9ZmaZ8RG/mVlmtolz/NOmTYtZs2Y11faFF15gl13Gu4y6c1xXY1xXY1xXY7q1LphcbUuXLn0qIvYcsyAiun7o6+uLZi1atKjptmVyXY1xXY1xXY3p1roiJlcbsCSqZKpP9ZiZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZWabuGWDWbdavmYDp8+/Zcv0qvPf28FqzOrjI34zs8w4+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuPgNzPLTGnBL2knSfdJekDSQ5I+m+afK2mNpGVpOKasGszMbKwyP8D1IvCeiBiWtANwt6Tvp2VfiIgLSuzbzMzGUVrwp+97HE6TO6QhyurPzMzqoyKfS9q4tD2wFNgHuCQizpF0LnA68BywBDgrItZXaTsPmAfQ29vbNzg42FQNw8PD9PT0NNW2TK6rMd1a17pnNjC0cev07BlTOldMhW7dX66rcZOpbWBgYGlE9I9ZUO0b2Fs9AFOBRcABQC+wPcX7C+cBV9Rq39fX1/S3zE/mG+rL5Loa0611XXz1jbH3OQu3DN2iW/eX62rcZGoDlkSVTG3LVT0R8SywGJgbEUMRsTkiXgYuAw5pRw1mZlYo86qePSVNTeM7A0cCD0uaXrHaCcCKsmowM7OxyryqZzqwIJ3n3w64LiIWSrpK0kEUb/SuAj5aYg1mZjZKmVf1PAgcXGX+KWX1aWZmtfmTu2ZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpaZ0oJf0k6S7pP0gKSHJH02zd9D0u2SHkk/dy+rBjMzG6vMI/4XgfdExIHAQcBcSYcC84E7I2Jf4M40bWZmbVJa8EdhOE3ukIYAjgMWpPkLgOPLqsHMzMZSRJS3cWl7YCmwD3BJRJwj6dmImFqxzvqIGHO6R9I8YB5Ab29v3+DgYFM1DA8P09PT01TbMrmuxnRrXeue2cDQxq3Ts2dM6VwxFbp1f7muxk2mtoGBgaUR0T9mQUSUPgBTgUXAAcCzo5atr9W+r68vmrVo0aKm25bJdTWmW+u6+OobY+9zFm4ZukW37i/X1bjJ1AYsiSqZ2pareiLiWWAxMBcYkjQdIP1c144azMysUOZVPXtKmprGdwaOBB4GbgZOS6udBtxUVg1mZjbWq0rc9nRgQTrPvx1wXUQslHQPcJ2kM4AngA+UWIOZmY1SWvBHxIPAwVXmPw0cUVa/ZmY2MX9y18wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDLj4Dczy4yD38wsMw5+M7PMOPjNzDJTWvBLmilpkaSVkh6S9I9p/rmS1khaloZjyqrBzMzGKu3L1oFNwFkRcb+kXYGlkm5Py74QEReU2LeZmY2jtOCPiLXA2jT+vKSVwIyy+jMzs/ooIsrvRJoF3AUcAHwCOB14DlhC8apgfZU284B5AL29vX2Dg4NN9T08PExPT09TbcvkuhrTrXWte2YDQxu3Ts+eMaVzxVTo1v3luho3mdoGBgaWRkT/mAURUeoA9ABLgRPTdC+wPcX7C+cBV9TaRl9fXzRr0aJFTbctk+tqTLfWdfHVN8be5yzcMnSLbt1frqtxk6kNWBJVMrXUq3ok7QB8F7gmIq5P/2iGImJzRLwMXAYcUmYNZmb258q8qkfA5cDKiLioYv70itVOAFaUVYOZmY1V5lU9hwOnAMslLUvzPgWcJOkgIIBVwEdLrMHMzEYp86qeuwFVWXRrWX2amVlt/uSumVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlmHPxmZplx8JuZZcbBb2aWGQe/mVlm6gp+SYfXM8/MzLpfvUf8/1LnPDMz63IT3o9f0t8AhwF7SvpExaLdKL4318zMtjG1vohlR4ovS38VsGvF/OeA95dVlJmZlWfC4I+IHwM/lnRlRDzepprMzKxE9X714qslXQrMqmwTEe8poygzMytPvcH/beCrwNeBzfU0kDQT+AbwWuBl4NKI+JKkPYBvUfwTWQV8MCLWN1a2mZk1q97g3xQR/9rgtjcBZ0XE/ZJ2BZZKuh04HbgzIs6XNB+YD5zT4LbNzKxJ9V7O+T1J/0XSdEl7jAwTNYiItRFxfxp/HlgJzACOAxak1RYAxzdZu5mZNUERUXsl6bEqsyMi3lhXJ9Is4C7gAOCJiJhasWx9ROxepc08YB5Ab29v3+DgYD1djTE8PExPT09TbcvkuhrTTXUtX7Nhy3jvzjC0ceuy2TOmdKCisbppf1VyXY2bTG0DAwNLI6J/9Py6gn8yJPUAPwbOi4jrJT1bT/BX6u/vjyVLljTV/+LFi5kzZ05TbcvkuhrTTXXNmn/LlvGzZm/iwuVbz5iuOv+9nShpjG7aX5VcV+MmU5ukqsFf1zl+SadWmx8R36jRbgfgu8A1EXF9mj0kaXpErJU0HVhXTw1mZtYa9b65+7aK8Z2AI4D7Ka7aqUqSgMuBlRFxUcWim4HTgPPTz5saKdjMzCanruCPiI9VTkuaAlxVo9nhwCnAcknL0rxPUQT+dZLOAJ4APtBQxWZmNin1HvGP9gdg34lWiIi7AY2z+Igm+zUzs0mq9xz/94CRd4G3B/YHriurKDMzK0+9R/wXVIxvAh6PiNUl1GNmZiWr6wNc6WZtD1PcoXN34E9lFmVmZuWp9xu4PgjcR/FG7AeBeyX5tsxmZtugek/1fBp4W0SsA5C0J3AH8J2yCjMzs3LUe6+e7UZCP3m6gbZmZtZF6j3i/4GkHwLXpukPAbeWU5KZmZWp1nfu7gP0RsTZkk4E3kFxbf49wDVtqM/MzFqs1umaLwLPA0TE9RHxiYj4rxRH+18suzgzM2u9WsE/KyIeHD0zIpZQfIOWmZltY2oF/04TLNu5lYWYmVl71Ar+X0j6z6NnphusLS2nJDMzK1Otq3o+Dtwg6WS2Bn0/sCNwQpmFmZlZOSYM/ogYAg6TNEDxtYkAt0TEj0qvzMzMSlHv/fgXAYtKrsXMzNrAn741M8uMg9/MLDMOfjOzzDj4zcwyU1rwS7pC0jpJKyrmnStpjaRlaTimrP7NzKy6Mo/4rwTmVpn/hYg4KA2+w6eZWZuVFvwRcRfwTFnbNzOz5igiytu4NAtYGBEHpOlzgdOB54AlwFkRsX6ctvOAeQC9vb19g4ODTdUwPDxMT09PU23L5Loa0011LV+zYct4784wtHHrstkzpnSgorG6aX9Vcl2Nm0xtAwMDSyOif/T8dgd/L/AUEMDngOkR8eFa2+nv748lS5Y0VcPixYuZM2dOU23L5Loa0011zZp/y5bxs2Zv4sLlWz8Huer893aipDG6aX9Vcl2Nm0xtkqoGf1uv6omIoYjYHBEvA5cBh7SzfzMza3PwS5peMXkCsGK8dc3MrBz1fuduwyRdC8wBpklaDfwTMEfSQRSnelYBHy2rfzMzq6604I+Ik6rMvrys/szMrD7+5K6ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWYc/GZmmXHwm5llprTgl3SFpHWSVlTM20PS7ZIeST93L6t/MzOrrswj/iuBuaPmzQfujIh9gTvTtJmZtVFpwR8RdwHPjJp9HLAgjS8Aji+rfzMzq04RUd7GpVnAwog4IE0/GxFTK5avj4iqp3skzQPmAfT29vYNDg42VcPw8DA9PT1NtS2T62pMN9W1fM2GLeO9O8PQxq3LZs+Y0oGKxuqm/VXJdTVuMrUNDAwsjYj+0fNfNemqShIRlwKXAvT398ecOXOa2s7ixYtptm2ZXFdjuqmu0+ffsmX8rNmbuHD51j+jVSfP6UBFY3XT/qrkuhpXRm3tvqpnSNJ0gPRzXZv7NzPLXruD/2bgtDR+GnBTm/s3M8temZdzXgvcA+wnabWkM4Dzgb+V9Ajwt2nazMzaqLRz/BFx0jiLjiirTzMzq82f3DUzy4yD38wsMw5+M7PMOPjNzDLj4Dczy0zXfnLXbFs0q+JTvQCrzn9vhyoxG5+P+M3MMuPgNzPLjIPfzCwzDn4zs8w4+M3MMuOresxK5Kt8rBv5iN/MLDMOfjOzzDj4zcwy4+A3M8uMg9/MLDMOfjOzzDj4zcwy05Hr+CWtAp4HNgObIqK/E3WYmeWokx/gGoiIpzrYv5lZlnyqx8wsM4qI9ncqPQasBwL4WkRcWmWdecA8gN7e3r7BwcGm+hoeHqanp2cS1ZbDdTWmm+pavmbDlvHenWFoY/1tZ8+YUtd2a61bSzftr0quq3GTqW1gYGBptVPpnQr+10XEk5L2Am4HPhYRd423fn9/fyxZsqSpvhYvXsycOXOaK7RErqsx3VRX5f13zpq9iQuX13/GdKJ79bTyvj7dtL8qua7GTaY2SVWDvyOneiLiyfRzHXADcEgn6jAzy1Hbg1/SLpJ2HRkHjgJWtLsOM7NcdeKqnl7gBkkj/X8zIn7QgTrMzLLU9uCPiN8CB7a7X7NmjT73vq1s22w8vpzTzCwzDn4zs8w4+M3MMuPgNzPLjIPfzCwznbxJm1nbVF49M5lPxHZSKz/Za3nzEb+ZWWYc/GZmmXHwm5llxsFvZpYZB7+ZWWZ8VY/ZKNvq/XMq675y7i4drMS6nY/4zcwy4+A3M8uMg9/MLDMOfjOzzPjNXXtF2FZuZ9DIG8eTeZN5+ZoNnD5B+1bun21l35dpW9sHPuI3M8uMg9/MLDMdCX5JcyX9StJvJM3vRA1mZrlqe/BL2h64BDgaeDNwkqQ3t7sOM7NcdeKI/xDgNxHx24j4EzAIHNeBOszMsqSIaG+H0vuBuRHxkTR9CvD2iDhz1HrzgHlpcj/gV012OQ14qsm2ZXJdjXFdjXFdjenWumByte0dEXuOntmJyzlVZd6Y/z4RcSlw6aQ7k5ZERP9kt9Nqrqsxrqsxrqsx3VoXlFNbJ071rAZmVky/HniyA3WYmWWpE8H/C2BfSf9O0o7A3wE3d6AOM7Mstf1UT0RsknQm8ENge+CKiHioxC4nfbqoJK6rMa6rMa6rMd1aF5RQW9vf3DUzs87yJ3fNzDLj4Dczy8wrIvglfUDSQ5JeljTuZU/j3SpC0h6Sbpf0SPq5e4vqqrldSftJWlYxPCfp42nZuZLWVCw7pl11pfVWSVqe+l7SaPsy6pI0U9IiSSvTY/6PFctaur9q3VpEhYvT8gclvbXetiXXdXKq50FJP5N0YMWyqo9pm+qaI2lDxePzmXrbllzX2RU1rZC0WdIeaVkp+0vSFZLWSVoxzvJyn1sRsc0PwP4UH/JaDPSPs872wKPAG4EdgQeAN6dlnwfmp/H5wP9uUV0NbTfV+G8UH7oAOBf4byXsr7rqAlYB0yb7e7WyLmA68NY0vivw64rHsWX7a6LnS8U6xwDfp/hsyqHAvfW2Lbmuw4Dd0/jRI3VN9Ji2qa45wMJm2pZZ16j1jwV+1Ib99S7grcCKcZaX+tx6RRzxR8TKiKj1yd6JbhVxHLAgjS8Ajm9RaY1u9wjg0Yh4vEX9j2eyv2/H9ldErI2I+9P488BKYEaL+q9Uz61FjgO+EYWfA1MlTa+zbWl1RcTPImJ9mvw5xWdlyjaZ37mj+2uUk4BrW9T3uCLiLuCZCVYp9bn1igj+Os0AflcxvZqtgdEbEWuhCBZgrxb12eh2/46xT7oz00u9K1p1SqWBugK4TdJSFbfQaLR9WXUBIGkWcDBwb8XsVu2viZ4vtdapp22ZdVU6g+LIccR4j2m76vobSQ9I+r6ktzTYtsy6kPQXwFzguxWzy9pftZT63NpmvoFL0h3Aa6ss+nRE3FTPJqrMm/S1rBPV1eB2dgTeB/z3itn/CnyOos7PARcCH25jXYdHxJOS9gJul/RwOlJpWgv3Vw/FH+jHI+K5NLvp/VWtiyrzRj9fxlunlOdajT7HrigNUAT/Oypmt/wxbaCu+ylOYw6n919uBPats22ZdY04FvhpRFQeiZe1v2op9bm1zQR/RBw5yU1MdKuIIUnTI2Jtejm1rhV1SWpku0cD90fEUMW2t4xLugxY2M66IuLJ9HOdpBsoXmbeRYf3l6QdKEL/moi4vmLbTe+vKuq5tch46+xYR9sy60LSXwNfB46OiKdH5k/wmJZeV8U/aCLiVklfkTStnrZl1lVhzCvuEvdXLaU+t3I61TPRrSJuBk5L46cB9byCqEcj2x1zbjGF34gTgKpXAJRRl6RdJO06Mg4cVdF/x/aXJAGXAysj4qJRy1q5v+q5tcjNwKnpCoxDgQ3pFFWZtyWpuW1JbwCuB06JiF9XzJ/oMW1HXa9Njx+SDqHIn6fraVtmXameKcC7qXjOlby/ain3udXqd6s7MVD8ka8GXgSGgB+m+a8Dbq1Y7xiKq0AepThFNDL/NcCdwCPp5x4tqqvqdqvU9RcUfwBTRrW/ClgOPJge3OntqoviqoEH0vBQt+wvitMWkfbJsjQcU8b+qvZ8Af4B+Ic0LoovFXo09ds/UdsWPt9r1fV1YH3F/llS6zFtU11npn4foHjT+bBu2F9p+nRgcFS70vYXxUHeWuAliuw6o53PLd+ywcwsMzmd6jEzMxz8ZmbZcfCbmWXGwW9mlhkHv5lZZhz89oql4i6Ly1TcxfMBSZ+QtF1a1i/p4jT+akl3pHU/JOmdqc0ySTt39rcwaz1fzmmvWJKGI6Inje8FfJPiI/n/NGq9QynuBPruNP1Virsh/t86+xHF39LLLf0FzEriI37LQkSsA+ZR3MRNKu4NvzD9Q7gaOCgd4X8U+CDwGUnXwJb7tf9Cxc3fPpvmzVLxnQBfobgHzcwa612WXkXcNvIqQtI+6ZXGA5Lul/SX4/Vn1koOfstGRPyW4jm/V8W8dcBHgJ9ExEER8TWKT/2eHREnSzqK4kZihwAHAX2S3pWa70dx69yD0/h46+0LXBIRbwGeBf5Dmn9Nmn8gxT3019boz6wltpmbtJm1SLW7G07kqDT8vzTdQxHMTwCPR3Gv9FrrPRYRy9L8pcCsdA+YGRFxA0BE/BEgBX+17bTjxmCWCQe/ZUPSG4HNFHf93L/eZsD/Sq8EKrc1C3ihzvVerJi1GdiZ8f8BVd2OWSv5VI9lQdKewFeBL0djVzT8EPiwivv/I2lGel+g2fWALbcoXi3p+LT+q1V8EUhD2zFrho/47ZVsZ0nLgB2ATRR377xo4iZ/LiJuk7Q/cE+6o/Aw8PcUR+4NrzfKKcDXJP1Pirs0fmCC7dT9nQdmtfhyTjOzzPhUj5lZZhz8ZmaZcfCbmWXGwW9mlhkHv5lZZhz8ZmaZcfCbmWXm/wP4u6ZUGLCWOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = (df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]).hist(bins=[(f / 40 - 1) for f in range(81)])\n",
    "ax.set_title(\"Symbolic - Constant\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
