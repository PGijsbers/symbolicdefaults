{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "final_pick = \"max\"  # \"one\" (for test purposes), \"max\", \"relative\"\n",
    "\n",
    "\n",
    "class Trace:\n",
    "\n",
    "    def __init__(self, filename: str, benchmarks=None, ignore=None, parse_progress=True):\n",
    "        self.baseline = set(benchmarks) if benchmarks else set()\n",
    "        self.scores, self.expressions, generations_by_task, self.baseline, self.progdf = parse_log(filename, baseline=self.baseline,ignore=ignore,parse_progress=parse_progress)\n",
    "        self.comparison, self.d_scores = comparisons(self.scores)\n",
    "        self.in_comparison, self.in_d_scores = comparisons(self.scores, sample=\"in-sample\")\n",
    "        self.generations_by_task = pd.Series(generations_by_task, name=\"generations\")\n",
    "\n",
    "    @property\n",
    "    def most_frequent_solutions_by_length(self):\n",
    "        for length, expressions in sorted(self.expressions.items()):\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            yield m, expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "\n",
    "\n",
    "def parse_log(file, with_prefix=False, baseline=None, ignore=None, parse_progress=True):\n",
    "    with open(file) as fh:\n",
    "        lines = fh.readlines()\n",
    "        \n",
    "    # ignore lines with an expression that is asked to be ignored\n",
    "    lines = [line for line in lines if not any([i in line for i in ignore])]\n",
    "\n",
    "    p = 'INFO:root:' if with_prefix else ''\n",
    "\n",
    "    definitions = [line for line in lines if ':=' in line]\n",
    "    baseline = baseline if baseline else set()\n",
    "    \n",
    "    print(\"The predefined defaults are (may show a repeat):\")\n",
    "    for line in definitions:\n",
    "        if ':=' in line and [i in line for i in ignore]:\n",
    "            print(f\" * {line[len(p):-1]}\")\n",
    "            baseline.add(line[len(p):].split(' :=')[0])\n",
    "\n",
    "    task_starts = [i for i, line in enumerate(lines) if \"START_TASK:\" in line]\n",
    "    in_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating in sample:\" in line]\n",
    "    out_sample_starts = [i for i, line in enumerate(lines) if \"Evaluating out-of-sample:\" in line]\n",
    "\n",
    "    def parse_evaluation_line(line) -> Tuple[str, int, float]:\n",
    "        \"\"\" Parse an evaluation line, returning the expression or name, its 'length' and the score.\n",
    "\n",
    "        e.g. INFO:root:[make_tuple(p, mkd)|0.8893]\\n -> 'make_tuple(p, mkd)', 1, 0.8893\n",
    "        Length is 0 for benchmark problems.\n",
    "        \"\"\"\n",
    "        if line.count('|') == 1:\n",
    "            start, pipe, end = line.find('['), line.find('|'), line.find(']')\n",
    "            expression = line[start+1: pipe]\n",
    "        else:\n",
    "            start, end = line.find('|') + 1, line.find(']')\n",
    "            pipe = line.find('|', start)  \n",
    "            expression = line[start: pipe]          \n",
    "            \n",
    "        if ':' in expression:  # For the baseline expressions, record them by name\n",
    "            expression = expression[:expression.find(':')]\n",
    "        expression_length = expression.count('(')\n",
    "        return expression, expression_length, float(line[pipe + 1: end])\n",
    "    \n",
    "    def parse_progess_lines(task, lines) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parse the log files progress over generations \n",
    "        Lines that evaluate progress start with 'GEN_' followed by Fitness and Size values\n",
    "        \"\"\"\n",
    "        progdf = pd.DataFrame(columns = ['task','gen', 'min', 'avg', 'max'])\n",
    "        for i, line in enumerate(lines):\n",
    "            progdf.loc[len(progdf)] =  [task, i] + [float(x) for x in line[line.find(\"FIT_\")+4:line.find(\"_SIZE\")].split(\"_\")]\n",
    "        return progdf\n",
    "\n",
    "\n",
    "    tasks = [int(line[:-1].split(\": \")[-1]) for line in lines if \"START_TASK:\" in line]\n",
    "    idx = pd.MultiIndex.from_product([tasks, [\"in-sample\", \"out-sample\"]], names=['task', 'sample-type'])\n",
    "    df = pd.DataFrame(index=idx, columns=[\"length-1\", \"length-2\", \"length-3\", \"final\", *baseline], dtype=float)\n",
    "\n",
    "\n",
    "    expressions_by_length = defaultdict(list)\n",
    "    generations_by_task = {}\n",
    "    progdf = pd.DataFrame(columns = ['task','gen', 'min', 'avg', 'max'])\n",
    "\n",
    "    for task_start, next_task in zip(task_starts, task_starts[1:] + [-(len(baseline)*2 + 1)]):\n",
    "        # start line looks like: INFO:root:START_TASK: 29\\n\n",
    "        task = int(lines[task_start][:-1].split(\": \")[-1])\n",
    "        generations_by_task[task] = 0\n",
    "        gen_lines = []\n",
    "        \n",
    "        # Following the \"INFO:root:Evaluating in sample:\" message, symbolic default performance are printed\n",
    "        # They are formatted as \"INFO:root:[make_tuple(p, mkd)|0.8893]\"\n",
    "        # First is any number of best solutions from the pareto front. The last four are benchmark solutions.\n",
    "        # It is possible that two equally good solutions are printed (i.e. same length and performance).\n",
    "        expr_in_task = set()\n",
    "        max_length = 0\n",
    "        last_insample = []\n",
    "        last_outsample = []\n",
    "        \n",
    "        in_sample = True\n",
    "        for line in lines[task_start:next_task]:\n",
    "            if line.startswith('GEN_'):\n",
    "                generations_by_task[task] += 1\n",
    "                gen_lines.append(line)\n",
    "            if \"Evaluating in\" in line:\n",
    "                in_sample = True\n",
    "                if 'BENCHMARK' not in line:\n",
    "                    last_insample = []\n",
    "                    last_outsample = []\n",
    "                    expr_in_task = set()            \n",
    "            if \"Evaluating out-of-sample:\" in line:\n",
    "                in_sample = False\n",
    "            if line.startswith('['):                \n",
    "                expr, length, score = parse_evaluation_line(line)\n",
    "                if expr not in expr_in_task: # and ':' not in expr:\n",
    "                    expr_in_task.add(expr)\n",
    "                if in_sample:\n",
    "                    last_insample.append((expr, length, score))\n",
    "                else:\n",
    "                    last_outsample.append((expr, length, score))    \n",
    "        \n",
    "        for expr in expr_in_task:            \n",
    "            expressions_by_length[expr.count('(')].append(expr)\n",
    "        \n",
    "        # Parse optimization trace (all lines starting with 'GEN_')\n",
    "        if parse_progress:\n",
    "            progdf = progdf.append(parse_progess_lines(task, gen_lines), ignore_index=True)\n",
    "\n",
    "        in_scores_by_length = defaultdict(list)\n",
    "        for expr, length, score in last_insample:\n",
    "            # print(expr, length, score)\n",
    "            if length != 0:\n",
    "                in_scores_by_length[length].append(score)\n",
    "                if length < 4:\n",
    "                    # Only report one out-of-sample solution for each length (and all benchmarks), so overwrite is OK.\n",
    "                    df.loc[task, \"in-sample\"][f\"length-{length}\"] = score\n",
    "\n",
    "                # Update best so far score and maximum length\n",
    "                df.loc[task, \"in-sample\"][f\"final\"] = np.nanmax(\n",
    "                    [score, df.loc[task, \"in-sample\"][f\"final\"]])\n",
    "                max_length = max(max_length, length)\n",
    "            else:\n",
    "                df.loc[task, \"in-sample\"][expr] = score\n",
    "\n",
    "            if length > max_length:\n",
    "                max_length = length  # To know for which length \"best\" should score out of sample\n",
    "\n",
    "        # Because two equal solutions can be in the Pareto front,\n",
    "        # we note the average out of sample performance if multiple solutions were found.\n",
    "        # Naturally, the solutions with the best in-sample score were those with the highest length in the Pareto front.\n",
    "\n",
    "        scores_by_length = defaultdict(list)\n",
    "        for expr, length, score in last_outsample:\n",
    "            if length != 0:\n",
    "                scores_by_length[length].append(score)\n",
    "            else:\n",
    "                df.loc[task, \"out-sample\"][expr] = score\n",
    "\n",
    "        for length, scores in scores_by_length.items():\n",
    "            if length < 4:\n",
    "                df.loc[task, \"out-sample\"][f\"length-{length}\"] = np.mean(scores)\n",
    "            if np.mean(scores) == float(\"nan\"):\n",
    "                print('hi')\n",
    "                \n",
    "        if final_pick == \"max\":\n",
    "            df.loc[task, \"out-sample\"][f\"final\"] = np.mean(scores_by_length[max_length])\n",
    "        if final_pick == \"one\":\n",
    "            df.loc[task, \"out-sample\"][f\"final\"] = np.mean(scores_by_length[1])\n",
    "        if final_pick == \"relative\":\n",
    "            use_length = max(in_scores_by_length)\n",
    "            for i, j in zip(in_scores_by_length, list(in_scores_by_length)[1:]):\n",
    "                rel_improvement = (np.mean(in_scores_by_length[j]) - np.mean(in_scores_by_length[i])) / np.mean(in_scores_by_length[i])\n",
    "                if rel_improvement < 0.01:\n",
    "                    print(f\"length {j} only {rel_improvement} better than {i}.\")\n",
    "                    use_length = i\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"length {j} {rel_improvement} better than {i}.\")\n",
    "            print(f\"Using length {use_length}\")\n",
    "            df.loc[task, \"out-sample\"][f\"final\"] = np.mean(scores_by_length[use_length])\n",
    "\n",
    "    return df, expressions_by_length, generations_by_task, baseline, progdf\n",
    "\n",
    "\n",
    "def comparisons(df, sample=\"out-sample\"):\n",
    "    out_sample = df.index.map(lambda idx: idx[1] == sample)\n",
    "\n",
    "    alone = {k: 0 for k in df.iloc[0].index.values}\n",
    "    shared = {k: 0 for k in df.iloc[0].index.values}\n",
    "\n",
    "    for _, out in df.loc[out_sample].iterrows():\n",
    "        best = out[out == out.max()].index.values\n",
    "        if len(best) == 1:\n",
    "            alone[best[0]] += 1\n",
    "        else:\n",
    "            for winner in best:\n",
    "                shared[winner] += 1\n",
    "\n",
    "    alone = {k: alone[k] for k in sorted(alone)}\n",
    "    shared = {k: shared[k] for k in sorted(shared)}\n",
    "    either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "    comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "\n",
    "    df_out = df.loc[out_sample].copy()\n",
    "    df_out['max'] = df_out.max(axis=1)\n",
    "    for col in df_out:\n",
    "        df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "    d_cols = [c for c in df_out.columns if c.startswith('d_')]\n",
    "    df_out[d_cols].mean()\n",
    "    df_out[d_cols].median()\n",
    "\n",
    "    in_sample = df.index.map(lambda idx: idx[1] == \"in-sample\")\n",
    "    df.loc[in_sample].idxmax(axis=1).value_counts()\n",
    "    df.loc[in_sample][reversed(df.columns)].idxmax(axis=1).value_counts()\n",
    "    return comparison, df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Defaults by 'complexity' of expression\n",
    "In this notebook we take a look at the results of running the script at its default settings, this means:\n",
    " - evaluation across all tasks\n",
    " - recording the pareto front of symbolic defaults after each search\n",
    " - evaluating in-sample and out-of-sample performance of those dynamic defaults, as well as some pre-defined ones\n",
    " \n",
    "**note:** The console cut off results for the first few tasks, so I am rerunning those now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task we will extract:\n",
    " - the number of generations optimization ran for (max=200)\n",
    " - max length expression\n",
    " - in and out of sample performance for length 1, 2 and 3 expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each task save the benchmark results. We also save results for length 1, 2 and 3 solutions as well as the best one found (that may be longer). Specifically we record:\n",
    " - best in_sample performance at length 1, 2, 3\n",
    " - best in_sample performance for any length\n",
    " - average out_sample performance by length for length 1, 2, 3\n",
    " - average out_sample performance for the longest (i.e. best in-sample score) solution(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We have experiment data for a set of algorithms and meta-data for the datasets on which the experiments took place.\n",
    "We use symbolic regression to find an expression for symbolic default values that give good performance across tasks.\n",
    "Symbolic regression is performed with leave-one-task-out, which means for each algorithm we have multiple searches for a symbolic default, and their performance is recorded for both in-sample (the optimization surface of all-but-one tasks) and out-of-sample (the left out task) performance. Performance here is solely based on surrogate model predictions, no additional experiments have been performed (yet).\n",
    "\n",
    "In our search, we use NSGA-II selection to perform multi-objective optimization: find the expression with the best performance, while using the fewest number of operators (e.g. `divide`, `multiply`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "**Length** of an expression denotes the number of operators in it. A symbolic value is *not* considered an operation.\n",
    "Consider the following SVM defaults for cost and gamma:\n",
    " - `make_tuple`(m, mkd) is length 1.\n",
    " - `make_tuple`(m, `truediv`(mkd, xvar)) is length 2.\n",
    " - `make_tuple`(16., `truediv`(mkd, xvar)) is length 2.\n",
    "\n",
    "The **final** solution refers to the symbolic default with the highest in-sample score for a task (regardless of its length). This means for each task there is *at least* one final solution, but there may be more and they are not of a specific length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **baseline** solutions are typically the default hyperparameter settings of mlr, scikit-learn, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read all the logs, because some logs are incomplete we have to explicitly give the name of the baselines (this will be fixed for future runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlr_rf_mupluslambda_0.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_1.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_2.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_3.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_4.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_5.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "O:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlr_rf_mupluslambda_6.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_7.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_8.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_mupluslambda_9.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_0.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlr_rf_random_search_1.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_2.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_3.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_4.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_5.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_6.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_7.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_8.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n",
      "mlr_rf_random_search_9.log\n",
      "The predefined defaults are (may show a repeat):\n",
      " * mlr_default := make_tuple(1., 1., pow(po, 0.5))\n"
     ]
    }
   ],
   "source": [
    "alg = 'rf'\n",
    "run_one = f\"{alg}_gauss24\"\n",
    "run_two = f\"{alg}_cst\"\n",
    "\n",
    "import os\n",
    "baselines = dict(\n",
    "    glmnet=[\"mlr_default\", \"sklearn_default\"],\n",
    "    kerasff=[\"initial_values\"],\n",
    "    knn=[\"mlr_default\"],\n",
    "    rf=[\"mlr_default\"],\n",
    "    rpart=[\"mlr_default\"],\n",
    "    asvm=[\"sklearn_scale\", \"symbolic_best\", \"symbolic_v2\" , \"const\"],\n",
    ")\n",
    "dir_ = \"runs/running\"\n",
    "for file in os.listdir(dir_):\n",
    "    if file.endswith('.log') and alg in file and (\"mupluslambda\" in file or \"random_search\" in file):\n",
    "        print(file)\n",
    "        baseline = []\n",
    "        for method, bls in baselines.items():\n",
    "            if method in file:\n",
    "                baseline = bls\n",
    "        traces[file[:-4]] = Trace(os.path.join(dir_, file), benchmarks=baseline, ignore=[\"const\", \"symbolic_v2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "As described before, for each problem we find a symbolic default leaving one task out.\n",
    "We are interested to see how fast the symbolic regression converges across tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of generations across tasks by problem:\n",
      "mlr_rf_mupluslambda_0  75\n",
      "mlr_rf_mupluslambda_1  85\n",
      "mlr_rf_mupluslambda_2 103\n",
      "mlr_rf_mupluslambda_3 111\n",
      "mlr_rf_mupluslambda_4 105\n",
      "mlr_rf_mupluslambda_5  86\n",
      "mlr_rf_mupluslambda_6  98\n",
      "mlr_rf_mupluslambda_7  83\n",
      "mlr_rf_mupluslambda_8  96\n",
      "mlr_rf_mupluslambda_9  83\n",
      "mlr_rf_random_search_0  37\n",
      "mlr_rf_random_search_1  32\n",
      "mlr_rf_random_search_2  30\n",
      "mlr_rf_random_search_3  30\n",
      "mlr_rf_random_search_4  37\n",
      "mlr_rf_random_search_5  33\n",
      "mlr_rf_random_search_6  30\n",
      "mlr_rf_random_search_7  31\n",
      "mlr_rf_random_search_8  39\n",
      "mlr_rf_random_search_9  37\n"
     ]
    }
   ],
   "source": [
    "print(\"Median number of generations across tasks by problem:\")\n",
    "for log, trace in traces.items():\n",
    "    print(f\"{log: <15} {trace.generations_by_task.median().astype(int):3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {k:v for (k,v) in traces.items() if k not in [\"mlr_glmnet_lisa_ints_0\", \"mlr_glmnet_lisa_ints_1\", \"mlr_glmnet_lisa_ints_2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(traces) / 4), 4, sharey=True, figsize=(16, 9))\n",
    "for ax, (log, trace) in zip(axes.flatten(), traces.items()):\n",
    "    traces[log].generations_by_task.hist(bins=20, ax=ax)\n",
    "    ax.set_title(f\"{log} ({len(trace.generations_by_task)} tasks)\")\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('generations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows a histogram counting the number of generations until stopping. These results were obtained with default setting of early stopping if no improvement was made after 20 generations, with a 200 generation maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing optimization traces\n",
    "The traces contain the full optimization traces inside the trace's **progdf** trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2'].progdf)\n",
    "# sns.lineplot(x='gen', y='max', units='task', estimator=None, data=traces[f'{alg}_gauss24_1eph_d1_2i'].progdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Expressions\n",
    "For a given problem, we have a Pareto front of solutions for search (=each left out task).\n",
    "This Pareto front may contain \"twins\", multiple solutions which performance equally well and have the same length.\n",
    "Given that the response surface does not differ *that* much when leaving any particular task out, we hope that the symbolic expressions we find are reasonably consistent across searches.\n",
    "To have some indication of how consistent the results are, for each problem we find the most frequent solutions of length 1, 2 and 3. We also note the number of hyperparameters for which we aim to find a symbolic default, as we expect this to be correlated to how consistent the solutions are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#tasks</th>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mlr_rf_mupluslambda_0  mlr_rf_mupluslambda_1  mlr_rf_mupluslambda_2  \\\n",
       "1                         2.0                    2.0                    2.0   \n",
       "2                         7.0                    5.0                    3.0   \n",
       "3                        32.0                   26.0                   24.0   \n",
       "#tasks                   92.0                   79.0                   71.0   \n",
       "params                    3.0                    3.0                    3.0   \n",
       "\n",
       "        mlr_rf_mupluslambda_3  mlr_rf_mupluslambda_4  mlr_rf_mupluslambda_5  \\\n",
       "1                         2.0                    6.0                    2.0   \n",
       "2                         2.0                    5.0                    4.0   \n",
       "3                        18.0                   29.0                   26.0   \n",
       "#tasks                   64.0                   74.0                   85.0   \n",
       "params                    3.0                    3.0                    3.0   \n",
       "\n",
       "        mlr_rf_mupluslambda_6  mlr_rf_mupluslambda_7  mlr_rf_mupluslambda_8  \\\n",
       "1                         3.0                    3.0                    2.0   \n",
       "2                         6.0                    3.0                    3.0   \n",
       "3                        21.0                   30.0                   26.0   \n",
       "#tasks                   84.0                   83.0                   79.0   \n",
       "params                    3.0                    3.0                    3.0   \n",
       "\n",
       "        mlr_rf_mupluslambda_9  mlr_rf_random_search_0  mlr_rf_random_search_1  \\\n",
       "1                         2.0                     1.0                     1.0   \n",
       "2                         4.0                     0.0                     0.0   \n",
       "3                        34.0                     0.0                     0.0   \n",
       "#tasks                   83.0                    12.0                    93.0   \n",
       "params                    3.0                     3.0                     3.0   \n",
       "\n",
       "        mlr_rf_random_search_2  mlr_rf_random_search_3  \\\n",
       "1                          1.0                     1.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "#tasks                    18.0                    13.0   \n",
       "params                     3.0                     3.0   \n",
       "\n",
       "        mlr_rf_random_search_4  mlr_rf_random_search_5  \\\n",
       "1                          1.0                     1.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "#tasks                    14.0                    36.0   \n",
       "params                     3.0                     3.0   \n",
       "\n",
       "        mlr_rf_random_search_6  mlr_rf_random_search_7  \\\n",
       "1                          2.0                     1.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "#tasks                    41.0                    73.0   \n",
       "params                     3.0                     3.0   \n",
       "\n",
       "        mlr_rf_random_search_8  mlr_rf_random_search_9  \n",
       "1                          1.0                     1.0  \n",
       "2                          0.0                     0.0  \n",
       "3                          0.0                     0.0  \n",
       "#tasks                    25.0                    29.0  \n",
       "params                     3.0                     3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_count = pd.DataFrame(np.zeros((5, len(traces))), columns=list(traces), index=[1, 2, 3, \"#tasks\", \"params\"])\n",
    "for log, trace in traces.items():  \n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            if length == 1:\n",
    "                expr_count.loc[\"#tasks\"][log] = len(trace.scores) / 2\n",
    "                expr_count.loc[\"params\"][log] = m.count(',') + 1\n",
    "expr_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the found expressions per problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlr_rf_mupluslambda_0\n",
      "Most frequent length 1 solution in Pareto front (2 times in 92 tasks):\n",
      "     make_tuple(p, n, 5)\n",
      "Most frequent length 2 solution in Pareto front (7 times in 92 tasks):\n",
      "     make_tuple(m, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (32 times in 92 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_1\n",
      "Most frequent length 1 solution in Pareto front (2 times in 79 tasks):\n",
      "     make_tuple(n, po, 5)\n",
      "Most frequent length 2 solution in Pareto front (5 times in 79 tasks):\n",
      "     make_tuple(n, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (26 times in 79 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_2\n",
      "Most frequent length 1 solution in Pareto front (2 times in 71 tasks):\n",
      "     make_tuple(n, p, 5)\n",
      "Most frequent length 2 solution in Pareto front (3 times in 71 tasks):\n",
      "     make_tuple(po, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (24 times in 71 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_3\n",
      "Most frequent length 1 solution in Pareto front (2 times in 64 tasks):\n",
      "     make_tuple(m, po, 5)\n",
      "Most frequent length 2 solution in Pareto front (2 times in 64 tasks):\n",
      "     make_tuple(po, expit(xvar), 1)\n",
      "Most frequent length 3 solution in Pareto front (18 times in 64 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_4\n",
      "Most frequent length 1 solution in Pareto front (6 times in 74 tasks):\n",
      "     make_tuple(p, m, 5)\n",
      "Most frequent length 2 solution in Pareto front (5 times in 74 tasks):\n",
      "     make_tuple(p, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (29 times in 74 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_5\n",
      "Most frequent length 1 solution in Pareto front (2 times in 85 tasks):\n",
      "     make_tuple(m, p, 5)\n",
      "Most frequent length 2 solution in Pareto front (4 times in 85 tasks):\n",
      "     make_tuple(m, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (26 times in 85 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_6\n",
      "Most frequent length 1 solution in Pareto front (3 times in 84 tasks):\n",
      "     make_tuple(p, p, 5)\n",
      "Most frequent length 2 solution in Pareto front (6 times in 84 tasks):\n",
      "     make_tuple(m, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (21 times in 84 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_7\n",
      "Most frequent length 1 solution in Pareto front (3 times in 83 tasks):\n",
      "     make_tuple(n, p, 5)\n",
      "Most frequent length 2 solution in Pareto front (3 times in 83 tasks):\n",
      "     make_tuple(p, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (30 times in 83 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_8\n",
      "Most frequent length 1 solution in Pareto front (2 times in 79 tasks):\n",
      "     make_tuple(m, n, 5)\n",
      "Most frequent length 2 solution in Pareto front (3 times in 79 tasks):\n",
      "     make_tuple(n, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (26 times in 79 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_mupluslambda_9\n",
      "Most frequent length 1 solution in Pareto front (2 times in 83 tasks):\n",
      "     make_tuple(po, po, 5)\n",
      "Most frequent length 2 solution in Pareto front (4 times in 83 tasks):\n",
      "     make_tuple(n, expit(xvar), 5)\n",
      "Most frequent length 3 solution in Pareto front (34 times in 83 tasks):\n",
      "     make_tuple(expit(xvar), expit(mcp), 5)\n",
      "mlr_rf_random_search_0\n",
      "Most frequent length 1 solution in Pareto front (1 times in 12 tasks):\n",
      "     make_tuple(0.6381380849875569, po, m)\n",
      "mlr_rf_random_search_1\n",
      "Most frequent length 1 solution in Pareto front (1 times in 93 tasks):\n",
      "     make_tuple(0.49782152895505505, po, 1)\n",
      "mlr_rf_random_search_2\n",
      "Most frequent length 1 solution in Pareto front (1 times in 18 tasks):\n",
      "     make_tuple(0.8273039393706973, p, 9)\n",
      "mlr_rf_random_search_3\n",
      "Most frequent length 1 solution in Pareto front (1 times in 13 tasks):\n",
      "     make_tuple(0.5829928670167747, 11, m)\n",
      "mlr_rf_random_search_4\n",
      "Most frequent length 1 solution in Pareto front (1 times in 14 tasks):\n",
      "     make_tuple(0.40033835016143604, n, 1)\n",
      "mlr_rf_random_search_5\n",
      "Most frequent length 1 solution in Pareto front (1 times in 36 tasks):\n",
      "     make_tuple(0.2934598432632534, po, 2)\n",
      "mlr_rf_random_search_6\n",
      "Most frequent length 1 solution in Pareto front (2 times in 41 tasks):\n",
      "     make_tuple(xvar, po, 2)\n",
      "mlr_rf_random_search_7\n",
      "Most frequent length 1 solution in Pareto front (1 times in 73 tasks):\n",
      "     make_tuple(0.6337497374487984, n, 2)\n",
      "mlr_rf_random_search_8\n",
      "Most frequent length 1 solution in Pareto front (1 times in 25 tasks):\n",
      "     make_tuple(0.42088627503250436, m, 5)\n",
      "mlr_rf_random_search_9\n",
      "Most frequent length 1 solution in Pareto front (1 times in 29 tasks):\n",
      "     make_tuple(0.4301646177356978, n, 8)\n"
     ]
    }
   ],
   "source": [
    "a = f'{alg}' # run_one #f\"mlr_knn_lisa_gaussian\" # run_one\n",
    "for log, trace in traces.items():\n",
    "    print(log)\n",
    "    for length, expressions in sorted(trace.expressions.items()):\n",
    "        if 0 < length < 4:\n",
    "            m = max(set(expressions), key=expressions.count)\n",
    "            expr_count.loc[length][log] = expressions.count(m)\n",
    "            # print(f\" Found {len(expressions):3d} expressions of length {length}. Most frequent: {m} ({expressions.count(m)} times)\")\n",
    "            print(f\"Most frequent length {length} solution in Pareto front ({expressions.count(m)} times in {len(trace.scores) // 2} tasks):\\n     {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Quality\n",
    "The expressions we find also need to be good.\n",
    "Here we compare the following 'strategies':\n",
    " - length-*n*: always pick the best expression of length *n*\n",
    " - *final*: always pick the best expression, regardless of length\n",
    " - *baseline(s)*: compare it to baselines we defined\n",
    " \n",
    "We want to know (all based on out-of-sample performance):\n",
    " - which strategy gives the best solution most often?\n",
    " - which strategy experiences the least mean regret?\n",
    " - which strategy experiences the least median regret?\n",
    " \n",
    "As mentioned before, there can be \"twins\" in the Pareto front, which means multiple solutions with equal length have equal in-sample performance.\n",
    "In this case we average the out-of-sample score of those twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of wins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table records the number of times a strategy led to the symbolic expression with the best out-of-sample performance (multiple strategies can be the best each task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>mlr_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        final  length-1  length-2  length-3  mlr_default\n",
       "mlr_rf_mupluslambda_0    41.0      14.0      25.0      19.0         13.0\n",
       "mlr_rf_mupluslambda_1    32.0       6.0      20.0      24.0         14.0\n",
       "mlr_rf_mupluslambda_2    29.0      10.0      19.0      22.0         11.0\n",
       "mlr_rf_mupluslambda_3    26.0       7.0      13.0      21.0          9.0\n",
       "mlr_rf_mupluslambda_4    25.0      11.0      23.0      22.0          9.0\n",
       "mlr_rf_mupluslambda_5    42.0       7.0      22.0      21.0         14.0\n",
       "mlr_rf_mupluslambda_6    34.0       8.0      25.0      23.0         13.0\n",
       "mlr_rf_mupluslambda_7    32.0      13.0      24.0      15.0         14.0\n",
       "mlr_rf_mupluslambda_8    35.0      10.0      24.0      22.0         11.0\n",
       "mlr_rf_mupluslambda_9    28.0      11.0      25.0      22.0         19.0\n",
       "mlr_rf_random_search_0    8.0       2.0       0.0       0.0          1.0\n",
       "mlr_rf_random_search_1   70.0      15.0       0.0       0.0          9.0\n",
       "mlr_rf_random_search_2   15.0       2.0       0.0       0.0          1.0\n",
       "mlr_rf_random_search_3    9.0       2.0       0.0       0.0          1.0\n",
       "mlr_rf_random_search_4   10.0       2.0       0.0       0.0          1.0\n",
       "mlr_rf_random_search_5   23.0      10.0       0.0       0.0          2.0\n",
       "mlr_rf_random_search_6   28.0      10.0       0.0       0.0          3.0\n",
       "mlr_rf_random_search_7   53.0      15.0       0.0       0.0          7.0\n",
       "mlr_rf_random_search_8   17.0       5.0       0.0       0.0          2.0\n",
       "mlr_rf_random_search_9   19.0       7.0       0.0       0.0          3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    out_comparisons = out_comparisons.append(trace.comparison.loc['either'].rename(log))\n",
    "out_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret\n",
    "Here we look at the regret for a method compared to the best known performance on the dataset from the random search experiments. Per definition the best score in random search is 1 (normalized score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median regret:\n",
    "The following table records the median regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trace' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-0c4d565ae8a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfewest_completions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfewest_completions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Trace' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "fewest_completions = min(traces.values(), key=lambda t: len(t.scores))\n",
    "fewest_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <td>0.0148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <td>0.0127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <td>0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_default</th>\n",
       "      <td>0.0618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "mlr_rf_mupluslambda_0   0.0164\n",
       "mlr_rf_mupluslambda_1   0.0148\n",
       "mlr_rf_mupluslambda_2   0.0134\n",
       "mlr_rf_mupluslambda_3   0.0127\n",
       "mlr_rf_mupluslambda_4   0.0104\n",
       "mlr_rf_mupluslambda_5   0.0117\n",
       "mlr_rf_mupluslambda_6   0.0102\n",
       "mlr_rf_mupluslambda_7   0.0134\n",
       "mlr_rf_mupluslambda_8   0.0140\n",
       "mlr_rf_mupluslambda_9   0.0157\n",
       "mlr_rf_random_search_0  0.0160\n",
       "mlr_rf_random_search_1  0.0124\n",
       "mlr_rf_random_search_2  0.0137\n",
       "mlr_rf_random_search_3  0.0150\n",
       "mlr_rf_random_search_4  0.0152\n",
       "mlr_rf_random_search_5  0.0157\n",
       "mlr_rf_random_search_6  0.0164\n",
       "mlr_rf_random_search_7  0.0166\n",
       "mlr_rf_random_search_8  0.0150\n",
       "mlr_rf_random_search_9  0.0193\n",
       "mlr_default             0.0618"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = {}\n",
    "for log, trace in traces.items():\n",
    "    idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] < 25)\n",
    "    medians[log] = [(1 - trace.scores[idx].final).median()]\n",
    "    \n",
    "medians[\"mlr_default\"] = [(1 - trace.scores[idx].mlr_default).median()]\n",
    "pd.DataFrame.from_dict(medians, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <td>0.038609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <td>0.041309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <td>0.043309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <td>0.039755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <td>0.042491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <td>0.038509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <td>0.038318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <td>0.037836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <td>0.049218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <td>0.042773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <td>0.042518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <td>0.047673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <td>0.043382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <td>0.046718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <td>0.053927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <td>0.048009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <td>0.050091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "      <td>0.046682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_default</th>\n",
       "      <td>0.088991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "mlr_rf_mupluslambda_0   0.038000\n",
       "mlr_rf_mupluslambda_1   0.038609\n",
       "mlr_rf_mupluslambda_2   0.041309\n",
       "mlr_rf_mupluslambda_3   0.043309\n",
       "mlr_rf_mupluslambda_4   0.039755\n",
       "mlr_rf_mupluslambda_5   0.042491\n",
       "mlr_rf_mupluslambda_6   0.038509\n",
       "mlr_rf_mupluslambda_7   0.038318\n",
       "mlr_rf_mupluslambda_8   0.037836\n",
       "mlr_rf_mupluslambda_9   0.038800\n",
       "mlr_rf_random_search_0  0.049218\n",
       "mlr_rf_random_search_1  0.042773\n",
       "mlr_rf_random_search_2  0.042518\n",
       "mlr_rf_random_search_3  0.047673\n",
       "mlr_rf_random_search_4  0.043382\n",
       "mlr_rf_random_search_5  0.046718\n",
       "mlr_rf_random_search_6  0.053927\n",
       "mlr_rf_random_search_7  0.048009\n",
       "mlr_rf_random_search_8  0.050091\n",
       "mlr_rf_random_search_9  0.046682\n",
       "mlr_default             0.088991"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = {}\n",
    "for log, trace in traces.items():\n",
    "    idx = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\" and idx[0] < 25)\n",
    "    means[log] = [(1 - trace.scores[idx].final).mean()]\n",
    "    \n",
    "means[\"mlr_default\"] = [(1 - trace.scores[idx].mlr_default).mean()]\n",
    "pd.DataFrame.from_dict(means, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Sometimes out-of-sample performance of a baseline may still be better than that of our solution.\n",
    "However, in-sample performance of our own solutions should always be better than any baseline.\n",
    "If that is not the case, this would indicate our search does not explore the space well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final</th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>mlr_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        final  length-1  length-2  length-3  mlr_default\n",
       "mlr_rf_mupluslambda_0    92.0       0.0       7.0      15.0          0.0\n",
       "mlr_rf_mupluslambda_1    79.0       0.0       6.0       9.0          0.0\n",
       "mlr_rf_mupluslambda_2    71.0       0.0       3.0      11.0          0.0\n",
       "mlr_rf_mupluslambda_3    64.0       0.0       3.0       9.0          0.0\n",
       "mlr_rf_mupluslambda_4    74.0       0.0       2.0      11.0          0.0\n",
       "mlr_rf_mupluslambda_5    84.0       0.0       6.0      14.0          0.0\n",
       "mlr_rf_mupluslambda_6    84.0       0.0       5.0      11.0          0.0\n",
       "mlr_rf_mupluslambda_7    83.0       0.0       8.0      11.0          0.0\n",
       "mlr_rf_mupluslambda_8    79.0       1.0       3.0      18.0          0.0\n",
       "mlr_rf_mupluslambda_9    83.0       0.0       6.0      15.0          0.0\n",
       "mlr_rf_random_search_0   11.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_1   93.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_2   18.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_3   12.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_4   14.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_5   35.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_6   41.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_7   73.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_8   24.0       0.0       0.0       0.0          0.0\n",
       "mlr_rf_random_search_9   29.0       0.0       0.0       0.0          0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_comparisons = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    in_sample_comparisons = in_sample_comparisons.append(trace.in_comparison.loc['either'].rename(log))\n",
    "in_sample_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlr_rf_mupluslambda_0', 'mlr_rf_mupluslambda_1', 'mlr_rf_mupluslambda_2', 'mlr_rf_mupluslambda_3', 'mlr_rf_mupluslambda_4', 'mlr_rf_mupluslambda_5', 'mlr_rf_mupluslambda_6', 'mlr_rf_mupluslambda_7', 'mlr_rf_mupluslambda_8', 'mlr_rf_mupluslambda_9', 'mlr_rf_random_search_0', 'mlr_rf_random_search_1', 'mlr_rf_random_search_2', 'mlr_rf_random_search_3', 'mlr_rf_random_search_4', 'mlr_rf_random_search_5', 'mlr_rf_random_search_6', 'mlr_rf_random_search_7', 'mlr_rf_random_search_8', 'mlr_rf_random_search_9'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = traces['mlr_rf_mupluslambda_0']\n",
    "rs = traces['mlr_rf_random_search_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>final</th>\n",
       "      <th>mlr_default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>sample-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.8524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.9179</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.9936</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.8527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">22</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>0.8527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">23</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.8455</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9617</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2073</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  length-1  length-2  length-3   final  mlr_default\n",
       "task sample-type                                                   \n",
       "3    in-sample      0.8953    0.9145    0.9183  0.9183       0.8524\n",
       "     out-sample     0.9950    0.9808    0.9917  0.9917       0.9992\n",
       "6    in-sample      0.8699    0.9076    0.9155  0.9179       0.8530\n",
       "     out-sample     0.9319    0.9786    0.9946  0.9786       0.9312\n",
       "11   in-sample      0.8963    0.9156    0.9164  0.9192       0.8540\n",
       "     out-sample     0.8617    0.8755    0.8835  0.8835       0.8103\n",
       "12   in-sample      0.8698    0.9075    0.9182  0.9182       0.8529\n",
       "     out-sample     0.9397    0.9898    0.9899  0.9899       0.9382\n",
       "14   in-sample      0.8697    0.9038    0.9158  0.9183       0.8528\n",
       "     out-sample     0.9579    0.9936    0.9896  0.9946       0.9550\n",
       "15   in-sample      0.8958    0.9146    0.9158  0.9176       0.8530\n",
       "     out-sample     0.9487    0.9618    0.9666  0.9610       0.9233\n",
       "16   in-sample      0.8959    0.9146       NaN  0.9146       0.8530\n",
       "     out-sample     0.9410    0.9836       NaN  0.9836       0.9257\n",
       "18   in-sample      0.8955    0.9139    0.9156  0.9174       0.8527\n",
       "     out-sample     0.9843    0.9816    0.9810  0.9746       0.9640\n",
       "22   in-sample      0.8957    0.9147    0.9159  0.9223       0.8527\n",
       "     out-sample     0.9637    0.9825    0.9859  0.9929       0.9604\n",
       "23   in-sample      0.8721    0.9096    0.9168  0.9201       0.8552\n",
       "     out-sample     0.6721    0.7365    0.8455  0.8316       0.6688\n",
       "24   in-sample      0.8957    0.9145    0.9149  0.9150       0.8528\n",
       "     out-sample     0.9617    1.0000    1.0000  1.0000       0.9450\n",
       "2073 in-sample      0.8959    0.9149    0.9158  0.9195       0.8531\n",
       "     out-sample     0.9369    0.9566    0.9634  0.9651       0.9112\n",
       "2074 in-sample      0.8955    0.9146    0.9166  0.9180       0.8525"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.scores.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>final</th>\n",
       "      <th>mlr_default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>sample-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.8524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">16</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.8527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">22</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.8527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">23</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.8892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2073</th>\n",
       "      <th>in-sample</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-sample</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  length-1  length-2  length-3   final  mlr_default\n",
       "task sample-type                                                   \n",
       "3    in-sample      0.8804       NaN       NaN  0.9076       0.8524\n",
       "     out-sample     0.9980       NaN       NaN  0.9857       0.9992\n",
       "6    in-sample      0.8845       NaN       NaN  0.9078       0.8530\n",
       "     out-sample     0.8469       NaN       NaN  0.9793       0.9312\n",
       "11   in-sample      0.8863       NaN       NaN  0.9089       0.8540\n",
       "     out-sample     0.8583       NaN       NaN  0.8184       0.8103\n",
       "12   in-sample      0.8853       NaN       NaN  0.9110       0.8529\n",
       "     out-sample     0.9610       NaN       NaN  0.9898       0.9382\n",
       "14   in-sample      0.8936       NaN       NaN  0.9127       0.8528\n",
       "     out-sample     0.9531       NaN       NaN  0.9896       0.9550\n",
       "15   in-sample      0.8841       NaN       NaN  0.9085       0.8530\n",
       "     out-sample     0.9430       NaN       NaN  0.9643       0.9233\n",
       "16   in-sample      0.8830       NaN       NaN  0.9120       0.8530\n",
       "     out-sample     0.9366       NaN       NaN  0.9840       0.9257\n",
       "18   in-sample      0.8832       NaN       NaN  0.9086       0.8527\n",
       "     out-sample     0.9744       NaN       NaN  0.9831       0.9640\n",
       "22   in-sample      0.8791       NaN       NaN  0.9093       0.8527\n",
       "     out-sample     0.9651       NaN       NaN  0.9849       0.9604\n",
       "23   in-sample      0.8857       NaN       NaN  0.9149       0.8552\n",
       "     out-sample     0.8125       NaN       NaN  0.7826       0.6688\n",
       "24   in-sample      0.8892       NaN       NaN  0.9074       0.8528\n",
       "     out-sample     0.9673       NaN       NaN  0.9969       0.9450\n",
       "2073 in-sample         NaN       NaN       NaN     NaN          NaN\n",
       "     out-sample        NaN       NaN       NaN     NaN          NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>length-1</th>\n",
       "      <th>length-2</th>\n",
       "      <th>length-3</th>\n",
       "      <th>final</th>\n",
       "      <th>mlr_default</th>\n",
       "      <th>max</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_mlr_default</th>\n",
       "      <th>d_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>sample-type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.6688</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>0.9673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <th>out-sample</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  length-1  length-2  length-3   final  mlr_default     max  \\\n",
       "task sample-type                                                              \n",
       "3    out-sample     0.9980       NaN       NaN  0.9857       0.9992  0.9992   \n",
       "6    out-sample     0.8469       NaN       NaN  0.9793       0.9312  0.9793   \n",
       "11   out-sample     0.8583       NaN       NaN  0.8184       0.8103  0.8583   \n",
       "12   out-sample     0.9610       NaN       NaN  0.9898       0.9382  0.9898   \n",
       "14   out-sample     0.9531       NaN       NaN  0.9896       0.9550  0.9896   \n",
       "15   out-sample     0.9430       NaN       NaN  0.9643       0.9233  0.9643   \n",
       "16   out-sample     0.9366       NaN       NaN  0.9840       0.9257  0.9840   \n",
       "18   out-sample     0.9744       NaN       NaN  0.9831       0.9640  0.9831   \n",
       "22   out-sample     0.9651       NaN       NaN  0.9849       0.9604  0.9849   \n",
       "23   out-sample     0.8125       NaN       NaN  0.7826       0.6688  0.8125   \n",
       "24   out-sample     0.9673       NaN       NaN  0.9969       0.9450  0.9969   \n",
       "2073 out-sample        NaN       NaN       NaN     NaN          NaN     NaN   \n",
       "\n",
       "                  d_length-1  d_length-2  d_length-3  d_final  d_mlr_default  \\\n",
       "task sample-type                                                               \n",
       "3    out-sample       0.0012         NaN         NaN   0.0135         0.0000   \n",
       "6    out-sample       0.1324         NaN         NaN   0.0000         0.0481   \n",
       "11   out-sample       0.0000         NaN         NaN   0.0399         0.0480   \n",
       "12   out-sample       0.0288         NaN         NaN   0.0000         0.0516   \n",
       "14   out-sample       0.0365         NaN         NaN   0.0000         0.0346   \n",
       "15   out-sample       0.0213         NaN         NaN   0.0000         0.0410   \n",
       "16   out-sample       0.0474         NaN         NaN   0.0000         0.0583   \n",
       "18   out-sample       0.0087         NaN         NaN   0.0000         0.0191   \n",
       "22   out-sample       0.0198         NaN         NaN   0.0000         0.0245   \n",
       "23   out-sample       0.0000         NaN         NaN   0.0299         0.1437   \n",
       "24   out-sample       0.0296         NaN         NaN   0.0000         0.0519   \n",
       "2073 out-sample          NaN         NaN         NaN      NaN            NaN   \n",
       "\n",
       "                  d_max  \n",
       "task sample-type         \n",
       "3    out-sample     0.0  \n",
       "6    out-sample     0.0  \n",
       "11   out-sample     0.0  \n",
       "12   out-sample     0.0  \n",
       "14   out-sample     0.0  \n",
       "15   out-sample     0.0  \n",
       "16   out-sample     0.0  \n",
       "18   out-sample     0.0  \n",
       "22   out-sample     0.0  \n",
       "23   out-sample     0.0  \n",
       "24   out-sample     0.0  \n",
       "2073 out-sample     NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.d_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to random search \n",
    "The following provides an overview over scores for different iterations of random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_type\n",
       "oracle    1.000000\n",
       "rs_2      0.678134\n",
       "rs_4      0.797459\n",
       "rs_8      0.884290\n",
       "rs_16     0.930003\n",
       "rs_32     0.953510\n",
       "rs_64     0.966905\n",
       "rs_128    0.977901\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"mlr_svm\"\n",
    "rsdf = pd.read_csv(\"data/\"+name+\"_baselines.csv\", index_col=0)\n",
    "rsdf.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "End of notebook - just sketchpad below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rf'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length-1       False\n",
       "length-2        True\n",
       "length-3        True\n",
       "final          False\n",
       "mlr_default     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.scores.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = \"svm\"\n",
    "run_one = \"mlr_svm_lisa\"\n",
    "minimum = dict(knn=100, svm=100, glmnet=100, rpart=60)\n",
    "final_scores = pd.DataFrame()\n",
    "for log, trace in traces.items():\n",
    "    # Filter out runs with >100 tasks completed:\n",
    "    if len(trace.scores) / 2 > minimum[alg]:\n",
    "        out_sample = trace.scores.index.map(lambda idx: idx[1] == \"out-sample\")\n",
    "        log_oos = trace.scores.loc[out_sample].final.rename(log)\n",
    "        final_scores = final_scores.append(log_oos)\n",
    "        if log == run_one:\n",
    "            # contains benchmark scores\n",
    "            for b in trace.baseline:\n",
    "                baseline_score = trace.scores.loc[out_sample][b].rename(b)\n",
    "                final_scores = final_scores.append(baseline_score)\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out incomplete tasks:\n",
    "final = final_scores.loc[:, ~final_scores.isna().any()]\n",
    "df = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one=\"mlr_svm_lisa\"\n",
    "run_two=\"svm_warm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['mlr_svm_lisa', 'svm_warm'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7dbd280e97b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun_one\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_two\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mO:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1952\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m             \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1595\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[0;32m   1597\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mO:\\Anaconda\\envs\\symbdef\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['mlr_svm_lisa', 'svm_warm'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "df = df.loc[[run_one, run_two]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alone = {k: 0 for k in df.index.values}\n",
    "shared = {k: 0 for k in df.index.values}\n",
    "\n",
    "for _, out in df.T.iterrows():\n",
    "    best = out[out == out.max()].index.values\n",
    "    if len(best) == 1:\n",
    "        alone[best[0]] += 1\n",
    "    else:\n",
    "        for winner in best:\n",
    "            shared[winner] += 1\n",
    "\n",
    "alone = {k: alone[k] for k in sorted(alone)}\n",
    "shared = {k: shared[k] for k in sorted(shared)}\n",
    "either = {k: shared[k] + alone[k] for k in sorted({**alone, **shared})}\n",
    "comparison = pd.DataFrame([alone, shared, either], index=['alone', 'shared', 'either'])\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.T.copy()\n",
    "df_out['max'] = df_out.max(axis=1)\n",
    "for col in df_out:\n",
    "    df_out['d_' + col] = df_out['max'] - df_out[col]\n",
    "d_cols = [c for c in df_out.columns if c.startswith('d_') and 'max' not in c]\n",
    "df_out[d_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[d_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (df.loc[run_one] - df.loc[run_two]).hist(bins=[(f / 40 - 1) for f in range(81)])\n",
    "ax.set_title(f\"Symbolic - Constant | median: {(df.loc[run_one] - df.loc[run_two]).median():.3f}, mean: {(df.loc[run_one] - df.loc[run_two]).mean():.3f}, {df.shape[1]} tasks\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[\"mlr_svm_lisa\"] - df.loc[\"svm_cst\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsdf.columns = [(round(float(x)), 'out-sample')  for x in rsdf.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rsdf.append(final_scores)\n",
    "df.iloc[:,1:].apply(np.mean,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.transpose().melt(var_name=\"method\", value_name=\"performance\")\n",
    "ax = sns.boxplot(x='method', y='performance', data = pdf)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean regret:\n",
    "The following table records the mean regret for a specific strategy compared to picking the best in hindsight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_final</th>\n",
       "      <th>d_length-1</th>\n",
       "      <th>d_length-2</th>\n",
       "      <th>d_length-3</th>\n",
       "      <th>d_mlr_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_0</th>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.014247</td>\n",
       "      <td>0.058411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_1</th>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.064472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_2</th>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.055931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_3</th>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.049202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_4</th>\n",
       "      <td>0.016131</td>\n",
       "      <td>0.050892</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.014053</td>\n",
       "      <td>0.061789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_5</th>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>0.059170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_6</th>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>0.019482</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.063792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_7</th>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.043280</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.060270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_8</th>\n",
       "      <td>0.014550</td>\n",
       "      <td>0.039845</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.067832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_mupluslambda_9</th>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.033307</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.064271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_0</th>\n",
       "      <td>0.007573</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_1</th>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_2</th>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.033117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_3</th>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_4</th>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.024415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_5</th>\n",
       "      <td>0.010406</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_6</th>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_7</th>\n",
       "      <td>0.016170</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_8</th>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlr_rf_random_search_9</th>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         d_final  d_length-1  d_length-2  d_length-3  \\\n",
       "mlr_rf_mupluslambda_0   0.013933    0.029902    0.010628    0.014247   \n",
       "mlr_rf_mupluslambda_1   0.008670    0.047190    0.016870    0.013175   \n",
       "mlr_rf_mupluslambda_2   0.022906    0.033299    0.016063    0.027273   \n",
       "mlr_rf_mupluslambda_3   0.012478    0.037078    0.014622    0.015216   \n",
       "mlr_rf_mupluslambda_4   0.016131    0.050892    0.017968    0.014053   \n",
       "mlr_rf_mupluslambda_5   0.009529    0.043040    0.016358    0.011363   \n",
       "mlr_rf_mupluslambda_6   0.010135    0.043105    0.019482    0.015928   \n",
       "mlr_rf_mupluslambda_7   0.013692    0.043280    0.011275    0.011811   \n",
       "mlr_rf_mupluslambda_8   0.014550    0.039845    0.015468    0.016192   \n",
       "mlr_rf_mupluslambda_9   0.013627    0.033307    0.013841    0.013992   \n",
       "mlr_rf_random_search_0  0.007573    0.029609         NaN         NaN   \n",
       "mlr_rf_random_search_1  0.012926    0.040959         NaN         NaN   \n",
       "mlr_rf_random_search_2  0.002056    0.033117         NaN         NaN   \n",
       "mlr_rf_random_search_3  0.012817    0.025492         NaN         NaN   \n",
       "mlr_rf_random_search_4  0.002738    0.024415         NaN         NaN   \n",
       "mlr_rf_random_search_5  0.010406    0.026117         NaN         NaN   \n",
       "mlr_rf_random_search_6  0.010705    0.024376         NaN         NaN   \n",
       "mlr_rf_random_search_7  0.016170    0.042774         NaN         NaN   \n",
       "mlr_rf_random_search_8  0.006304    0.021296         NaN         NaN   \n",
       "mlr_rf_random_search_9  0.009828    0.024710         NaN         NaN   \n",
       "\n",
       "                        d_mlr_default  \n",
       "mlr_rf_mupluslambda_0        0.058411  \n",
       "mlr_rf_mupluslambda_1        0.064472  \n",
       "mlr_rf_mupluslambda_2        0.055931  \n",
       "mlr_rf_mupluslambda_3        0.049202  \n",
       "mlr_rf_mupluslambda_4        0.061789  \n",
       "mlr_rf_mupluslambda_5        0.059170  \n",
       "mlr_rf_mupluslambda_6        0.063792  \n",
       "mlr_rf_mupluslambda_7        0.060270  \n",
       "mlr_rf_mupluslambda_8        0.067832  \n",
       "mlr_rf_mupluslambda_9        0.064271  \n",
       "mlr_rf_random_search_0       0.047345  \n",
       "mlr_rf_random_search_1       0.057654  \n",
       "mlr_rf_random_search_2       0.038818  \n",
       "mlr_rf_random_search_3       0.050892  \n",
       "mlr_rf_random_search_4       0.045462  \n",
       "mlr_rf_random_search_5       0.046300  \n",
       "mlr_rf_random_search_6       0.045167  \n",
       "mlr_rf_random_search_7       0.070079  \n",
       "mlr_rf_random_search_8       0.035646  \n",
       "mlr_rf_random_search_9       0.037975  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = pd.DataFrame([])\n",
    "for log, trace in traces.items():\n",
    "    m = trace.d_scores.mean().rename(log)\n",
    "    means = means.append(m)\n",
    "means[[c for c in medians.columns if 'd_' in c and c != 'd_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
